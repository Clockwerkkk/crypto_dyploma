{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "6mhtfFejRRBC"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from einops import rearrange\n",
        "from torch.utils.data import Subset\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –Ω–∞—à–∏ –¥–∞–Ω–Ω—ã–µ –ø–µ—Ä–µ–¥ –ø–æ–¥–∞—á–µ–π –≤ –º–æ–¥–µ–ª—å"
      ],
      "metadata": {
        "id": "Ov70kXdwSVuX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CryptoDataset(Dataset):\n",
        "    def __init__(self, dfs: dict, window_size=196, predict_steps=24):\n",
        "        self.window_size = window_size\n",
        "        self.predict_steps = predict_steps\n",
        "        self.sequences, self.targets, self.coin_ids = [], [], []\n",
        "        self.scalers = {}\n",
        "        self.label_encoder = LabelEncoder()\n",
        "        coin_names = list(dfs.keys())\n",
        "        self.label_encoder.fit(coin_names)\n",
        "\n",
        "        for coin in coin_names:\n",
        "            df = dfs[coin].copy()\n",
        "            df = df.drop(columns=[\"timestamp\"])\n",
        "            self.scalers[coin] = StandardScaler()\n",
        "            scaled = self.scalers[coin].fit_transform(df.drop(columns=[\"close\"]))\n",
        "            close = df[\"close\"].values\n",
        "\n",
        "            for i in range(len(scaled) - window_size - predict_steps):\n",
        "                x = scaled[i:i+window_size]\n",
        "                y = close[i+window_size:i+window_size+predict_steps]\n",
        "                self.sequences.append(x)\n",
        "                self.targets.append(y)\n",
        "                self.coin_ids.append(self.label_encoder.transform([coin])[0])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sequences)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x = torch.tensor(self.sequences[idx], dtype=torch.float32)\n",
        "        coin_id = torch.tensor(self.coin_ids[idx], dtype=torch.long)\n",
        "        y = torch.tensor(self.targets[idx], dtype=torch.float32)\n",
        "        return x, coin_id, y"
      ],
      "metadata": {
        "id": "2VoVgqkyRRyv"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_splits(dataset: Dataset, val_size=0.1, test_size=0.1, seed=42):\n",
        "    indices = np.arange(len(dataset))\n",
        "    train_val_idx, test_idx = train_test_split(indices, test_size=test_size, random_state=seed, shuffle=False)\n",
        "    train_idx, val_idx = train_test_split(train_val_idx, test_size=val_size / (1 - test_size), random_state=seed, shuffle=False)\n",
        "    return Subset(dataset, train_idx), Subset(dataset, val_idx), Subset(dataset, test_idx)"
      ],
      "metadata": {
        "id": "YqKDohtyTamc"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PerformerBlock(nn.Module):\n",
        "    def __init__(self, dim, heads=4, dropout=0.1):\n",
        "        super().__init__()\n",
        "        assert dim % heads == 0, f\"dim={dim} must be divisible by heads={heads}\"\n",
        "        self.heads = heads\n",
        "        self.qkv = nn.Linear(dim, dim * 3)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.proj = nn.Linear(dim, dim)\n",
        "\n",
        "    def forward(self, x):  # x: [B, T, D]\n",
        "        B, T, D = x.shape\n",
        "        H = self.heads\n",
        "\n",
        "        # –ü–æ–ª—É—á–µ–Ω–∏–µ q, k, v\n",
        "        qkv = self.qkv(x).chunk(3, dim=-1)  # –∫–∞–∂–¥–∞—è [B, T, D]\n",
        "        q, k, v = map(lambda t: rearrange(t, 'b t (h d) -> b h t d', h=H), qkv)  # [B, H, T, D_h]\n",
        "\n",
        "        q = torch.nn.functional.elu(q) + 1\n",
        "        k = torch.nn.functional.elu(k) + 1\n",
        "\n",
        "        kv = torch.einsum('bhnd,bhne->bhde', k, v)  # [B, H, D, D]\n",
        "        k_sum = k.sum(dim=2, keepdim=True)         # [B, H, 1, D]\n",
        "        z = 1 / (torch.einsum('bhnd,bhnd->bhn', q, k_sum.expand_as(q)) + 1e-6).unsqueeze(-1)  # [B, H, T, 1]\n",
        "        out = torch.einsum('bhnd,bhde->bhne', q, kv) * z  # [B, H, T, D]\n",
        "\n",
        "        out = rearrange(out, 'b h t d -> b t (h d)')  # [B, T, D]\n",
        "        return self.proj(self.dropout(out))\n"
      ],
      "metadata": {
        "id": "6JfNcC4yRxJ1"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class HybridModel(nn.Module):\n",
        "    def __init__(self, input_dim, coin_count, hidden_dim=64, heads=4, predict_steps=24):\n",
        "        super().__init__()\n",
        "        self.predict_steps = predict_steps\n",
        "        self.coin_embedding = nn.Embedding(coin_count, input_dim)\n",
        "        self.performer = PerformerBlock(dim=input_dim, heads=heads)\n",
        "        self.bilstm = nn.LSTM(input_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
        "        self.regressor = nn.Sequential(\n",
        "            nn.Linear(hidden_dim * 2, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, predict_steps)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, coin_id):\n",
        "        emb = self.coin_embedding(coin_id).unsqueeze(1).expand_as(x)\n",
        "        x = x + emb\n",
        "        x = self.performer(x)\n",
        "        out, _ = self.bilstm(x)\n",
        "        out = out[:, -1, :]\n",
        "        return self.regressor(out)"
      ],
      "metadata": {
        "id": "4u3qSE7CRxHt"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HAqJc3hdRxFN"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_loader, val_loader, epochs=20, lr=1e-3):\n",
        "    model.to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    loss_fn = nn.MSELoss()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_train_loss = 0\n",
        "        for x, coin_id, y in train_loader:\n",
        "            x = x.to(device)\n",
        "            coin_id = coin_id.to(device)\n",
        "            y = y.to(device)\n",
        "\n",
        "            pred = model(x, coin_id)\n",
        "            loss = loss_fn(pred, y)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_train_loss += loss.item()\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        total_val_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for x, coin_id, y in val_loader:\n",
        "                x = x.to(device)\n",
        "                coin_id = coin_id.to(device)\n",
        "                y = y.to(device)\n",
        "\n",
        "                pred = model(x, coin_id)\n",
        "                val_loss = loss_fn(pred, y)\n",
        "                total_val_loss += val_loss.item()\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{epochs} | Train Loss: {total_train_loss / len(train_loader):.4f} | Val Loss: {total_val_loss / len(val_loader):.4f}\")\n"
      ],
      "metadata": {
        "id": "qkEGQL0FRxC_"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, dataset_subset: Dataset, parent_dataset: CryptoDataset):\n",
        "    model.eval()\n",
        "    preds, trues, coins = [], [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i in range(len(dataset_subset)):\n",
        "            x, coin_id, y = dataset_subset[i]\n",
        "            x = x.unsqueeze(0).to(device)\n",
        "            coin_id = coin_id.unsqueeze(0).to(device)\n",
        "\n",
        "            pred = model(x, coin_id).squeeze().cpu().numpy()\n",
        "            preds.append(pred)\n",
        "            trues.append(y.numpy())\n",
        "            coins.append(coin_id.cpu().item())\n",
        "\n",
        "    preds, trues = np.array(preds), np.array(trues)\n",
        "    label_decoder = parent_dataset.label_encoder.inverse_transform(coins)\n",
        "    df_all = pd.DataFrame({'coin': label_decoder})\n",
        "    metrics = {}\n",
        "\n",
        "    for step in range(preds.shape[1]):\n",
        "        df_all[f\"pred_{step}\"] = preds[:, step]\n",
        "        df_all[f\"true_{step}\"] = trues[:, step]\n",
        "\n",
        "    for coin in df_all['coin'].unique():\n",
        "        df_coin = df_all[df_all['coin'] == coin]\n",
        "        p, t = [], []\n",
        "        for step in range(preds.shape[1]):\n",
        "            p += df_coin[f\"pred_{step}\"].tolist()\n",
        "            t += df_coin[f\"true_{step}\"].tolist()\n",
        "\n",
        "        p, t = np.array(p), np.array(t)\n",
        "        ret = np.diff(p) / p[:-1]\n",
        "        true_ret = np.diff(t) / t[:-1]\n",
        "\n",
        "        sharpe = np.mean(ret - true_ret) / (np.std(ret - true_ret) + 1e-8)\n",
        "        downside = ret[ret < 0]\n",
        "        sortino = np.mean(ret - true_ret) / (np.std(downside) + 1e-8) if len(downside) > 0 else 0\n",
        "        da = np.mean(np.sign(ret) == np.sign(true_ret))\n",
        "        dd = max_drawdown(t)\n",
        "\n",
        "        metrics[coin] = {\n",
        "            'MAE': mean_absolute_error(t, p),\n",
        "            'RMSE': mean_squared_error(t, p) ** 0.5 ,\n",
        "            'MAPE (%)': np.mean(np.abs((t - p) / t)) * 100,\n",
        "            'Directional Accuracy': da,\n",
        "            'Sharpe Ratio': sharpe,\n",
        "            'Sortino Ratio': sortino,\n",
        "            'Max Drawdown (%)': dd\n",
        "        }\n",
        "\n",
        "    return df_all, metrics\n",
        "\n",
        "\n",
        "def max_drawdown(prices):\n",
        "    prices = np.array(prices)\n",
        "    cum_max = np.maximum.accumulate(prices)\n",
        "    dd = (cum_max - prices) / cum_max\n",
        "    return np.max(dd) * 100"
      ],
      "metadata": {
        "id": "1eBC-gB1RxAk"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfs = {\n",
        "    'BTC': pd.read_csv(\"BTC_USDT.csv\"),\n",
        "    'ETH': pd.read_csv(\"ETH_USDT.csv\"),\n",
        "    'SOL': pd.read_csv(\"SOL_USDT.csv\"),\n",
        "    'XRP': pd.read_csv(\"XRP_USDT.csv\"),\n",
        "    'TRX': pd.read_csv(\"TRX_USDT.csv\"),\n",
        "}\n",
        "\n",
        "# –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞: —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –∏ –æ–±–Ω—É–ª–µ–Ω–∏–µ NaN\n",
        "for coin in dfs:\n",
        "    dfs[coin] = dfs[coin].sort_values(\"timestamp\").fillna(method=\"ffill\").fillna(method=\"bfill\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13iVqQC6Rw-I",
        "outputId": "dd30727d-18bb-47f5-95a4-0def9fcc97c0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-6d8a007e7ddb>:11: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  dfs[coin] = dfs[coin].sort_values(\"timestamp\").fillna(method=\"ffill\").fillna(method=\"bfill\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "WINDOW_SIZE = 196\n",
        "PREDICT_STEPS = 24\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 20\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "EQtblBcSTphw"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = CryptoDataset(dfs, window_size=WINDOW_SIZE, predict_steps=PREDICT_STEPS)\n",
        "\n",
        "# –î–µ–ª–∏–º –Ω–∞ train/val/test\n",
        "train_set, val_set, test_set = create_splits(dataset, val_size=0.1, test_size=0.1)\n",
        "\n",
        "# DataLoaders\n",
        "train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader = DataLoader(val_set, batch_size=BATCH_SIZE, shuffle=False)\n",
        "test_loader = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏\n",
        "model = HybridModel(\n",
        "    input_dim=dataset[0][0].shape[1],\n",
        "    coin_count=len(dfs),\n",
        "    predict_steps=PREDICT_STEPS\n",
        ").to(device)\n",
        "\n",
        "# –û–±—É—á–µ–Ω–∏–µ —Å –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π\n",
        "train_model(model, train_loader, val_loader, epochs=EPOCHS)\n",
        "\n",
        "# –§–∏–Ω–∞–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞\n",
        "df_eval, metrics = evaluate_model(model, test_set)\n",
        "\n",
        "print(\"\\nüìä Test Metrics per Coin:\")\n",
        "for coin, met in metrics.items():\n",
        "    print(f\"{coin}:\")\n",
        "    for k, v in met.items():\n",
        "        print(f\"  {k}: {v:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 720
        },
        "id": "PyM7j0DnRw7p",
        "outputId": "d825d594-871f-4900-c594-bb75dfc909d2"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20 | Train Loss: 263306377.4105 | Val Loss: 885968.1819\n",
            "Epoch 2/20 | Train Loss: 17215527.0103 | Val Loss: 1520905.3644\n",
            "Epoch 3/20 | Train Loss: 1116070.9445 | Val Loss: 26506.7100\n",
            "Epoch 4/20 | Train Loss: 855580.9440 | Val Loss: 4949.3232\n",
            "Epoch 5/20 | Train Loss: 699525.2274 | Val Loss: 2498.2128\n",
            "Epoch 6/20 | Train Loss: 669496.7005 | Val Loss: 2530.9342\n",
            "Epoch 7/20 | Train Loss: 648623.0835 | Val Loss: 3308.1640\n",
            "Epoch 8/20 | Train Loss: 641665.0240 | Val Loss: 2458.9328\n",
            "Epoch 9/20 | Train Loss: 621155.8278 | Val Loss: 1981.3857\n",
            "Epoch 10/20 | Train Loss: 552376.9575 | Val Loss: 968.1539\n",
            "Epoch 11/20 | Train Loss: 502786.2149 | Val Loss: 738.7449\n",
            "Epoch 12/20 | Train Loss: 447039.6878 | Val Loss: 231.3269\n",
            "Epoch 13/20 | Train Loss: 448420.0735 | Val Loss: 2398.7109\n",
            "Epoch 14/20 | Train Loss: 394637.7741 | Val Loss: 1133.3978\n",
            "Epoch 15/20 | Train Loss: 405928.4475 | Val Loss: 1062.5809\n",
            "Epoch 16/20 | Train Loss: 377992.8859 | Val Loss: 359.0260\n",
            "Epoch 17/20 | Train Loss: 382031.5242 | Val Loss: 428.3569\n",
            "Epoch 18/20 | Train Loss: 354379.7346 | Val Loss: 385.4209\n",
            "Epoch 19/20 | Train Loss: 370558.7887 | Val Loss: 15.2079\n",
            "Epoch 20/20 | Train Loss: 343517.7349 | Val Loss: 77.4570\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'Subset' object has no attribute 'label_encoder'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-6d44c9c510f6>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# –§–∏–Ω–∞–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mdf_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nüìä Test Metrics per Coin:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-67185a8a2ece>\u001b[0m in \u001b[0;36mevaluate_model\u001b[0;34m(model, dataset)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mlabel_decoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mdf_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'coin'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlabel_decoder\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Subset' object has no attribute 'label_encoder'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_eval, metrics = evaluate_model(model, test_set, dataset)\n",
        "\n",
        "print(\"\\nüìä Test Metrics per Coin:\")\n",
        "for coin, met in metrics.items():\n",
        "    print(f\"{coin}:\")\n",
        "    for k, v in met.items():\n",
        "        print(f\"  {k}: {v:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E4nqfgqJS5ad",
        "outputId": "33d62e8c-595b-4dc5-ae8e-f5c80caea9a9"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìä Test Metrics per Coin:\n",
            "TRX:\n",
            "  MAE: 17.5171\n",
            "  RMSE: 33.8819\n",
            "  MAPE (%): 12209.8860\n",
            "  Directional Accuracy: 0.4864\n",
            "  Sharpe Ratio: -0.0025\n",
            "  Sortino Ratio: -0.0018\n",
            "  Max Drawdown (%): 89.3263\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for coin, met in metrics.items():\n",
        "    print(f\"{coin}:\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BUdj41UMS5Qh",
        "outputId": "6ddae88c-143b-4efb-f848-386cda38e525"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TRX:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "g3mFzjt8S5FY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}