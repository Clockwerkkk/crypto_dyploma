{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ub4q1qjvgcl"
      },
      "outputs": [],
      "source": [
        "#import getpass"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import os\n",
        "import time\n",
        "from datetime import datetime\n",
        "import lightgbm as lgb"
      ],
      "metadata": {
        "id": "URSFSqPN4OuM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Feature Engineering"
      ],
      "metadata": {
        "id": "9Zwh9i2DM9nG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os"
      ],
      "metadata": {
        "id": "HWeMC3p-I6fn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_all_from_csv(folder='crypto_csv'):\n",
        "    data_dict = {}\n",
        "    for fname in os.listdir(folder):\n",
        "        if fname.endswith(\".csv\"):\n",
        "            symbol = fname.replace(\".csv\", \"\").replace(\"_\", \"/\")\n",
        "            df = pd.read_csv(os.path.join(folder, fname), parse_dates=['timestamp'])\n",
        "            data_dict[symbol] = df[['timestamp', 'open', 'high', 'low', 'close', 'volume']]\n",
        "    return data_dict"
      ],
      "metadata": {
        "id": "ysvasarxlUL_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_h = load_all_from_csv('crypto_csv_hourly')"
      ],
      "metadata": {
        "id": "WlNX7JSalUIg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_h['BTC/USDT']"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "buu5id9Mqzpk",
        "outputId": "2a0736c9-e69e-43f5-9d99-a19956d3a189"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                timestamp       open       high        low      close  \\\n",
              "0     2019-01-01 00:00:00    3701.23    3713.00    3689.88    3700.31   \n",
              "1     2019-01-01 01:00:00    3700.20    3702.73    3684.22    3689.69   \n",
              "2     2019-01-01 02:00:00    3689.67    3695.95    3675.04    3690.00   \n",
              "3     2019-01-01 03:00:00    3690.00    3699.77    3685.78    3693.13   \n",
              "4     2019-01-01 04:00:00    3692.32    3720.00    3685.94    3692.71   \n",
              "...                   ...        ...        ...        ...        ...   \n",
              "55626 2025-05-09 06:00:00  102979.35  103261.71  102928.77  103230.11   \n",
              "55627 2025-05-09 07:00:00  103230.11  104361.30  103127.76  103628.77   \n",
              "55628 2025-05-09 08:00:00  103628.76  103930.00  102652.33  102968.25   \n",
              "55629 2025-05-09 09:00:00  102968.25  103285.72  102421.00  102915.58   \n",
              "55630 2025-05-09 10:00:00  102915.58  102915.58  102888.00  102888.01   \n",
              "\n",
              "            volume  \n",
              "0       686.367420  \n",
              "1       613.539115  \n",
              "2       895.302181  \n",
              "3       796.714818  \n",
              "4      1317.452909  \n",
              "...            ...  \n",
              "55626  1025.817990  \n",
              "55627  3530.711920  \n",
              "55628  3123.084800  \n",
              "55629  1946.173750  \n",
              "55630     4.679830  \n",
              "\n",
              "[55631 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7334195c-bf2a-4abf-8a93-073b20da8979\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>timestamp</th>\n",
              "      <th>open</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>close</th>\n",
              "      <th>volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2019-01-01 00:00:00</td>\n",
              "      <td>3701.23</td>\n",
              "      <td>3713.00</td>\n",
              "      <td>3689.88</td>\n",
              "      <td>3700.31</td>\n",
              "      <td>686.367420</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2019-01-01 01:00:00</td>\n",
              "      <td>3700.20</td>\n",
              "      <td>3702.73</td>\n",
              "      <td>3684.22</td>\n",
              "      <td>3689.69</td>\n",
              "      <td>613.539115</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2019-01-01 02:00:00</td>\n",
              "      <td>3689.67</td>\n",
              "      <td>3695.95</td>\n",
              "      <td>3675.04</td>\n",
              "      <td>3690.00</td>\n",
              "      <td>895.302181</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2019-01-01 03:00:00</td>\n",
              "      <td>3690.00</td>\n",
              "      <td>3699.77</td>\n",
              "      <td>3685.78</td>\n",
              "      <td>3693.13</td>\n",
              "      <td>796.714818</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2019-01-01 04:00:00</td>\n",
              "      <td>3692.32</td>\n",
              "      <td>3720.00</td>\n",
              "      <td>3685.94</td>\n",
              "      <td>3692.71</td>\n",
              "      <td>1317.452909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55626</th>\n",
              "      <td>2025-05-09 06:00:00</td>\n",
              "      <td>102979.35</td>\n",
              "      <td>103261.71</td>\n",
              "      <td>102928.77</td>\n",
              "      <td>103230.11</td>\n",
              "      <td>1025.817990</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55627</th>\n",
              "      <td>2025-05-09 07:00:00</td>\n",
              "      <td>103230.11</td>\n",
              "      <td>104361.30</td>\n",
              "      <td>103127.76</td>\n",
              "      <td>103628.77</td>\n",
              "      <td>3530.711920</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55628</th>\n",
              "      <td>2025-05-09 08:00:00</td>\n",
              "      <td>103628.76</td>\n",
              "      <td>103930.00</td>\n",
              "      <td>102652.33</td>\n",
              "      <td>102968.25</td>\n",
              "      <td>3123.084800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55629</th>\n",
              "      <td>2025-05-09 09:00:00</td>\n",
              "      <td>102968.25</td>\n",
              "      <td>103285.72</td>\n",
              "      <td>102421.00</td>\n",
              "      <td>102915.58</td>\n",
              "      <td>1946.173750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55630</th>\n",
              "      <td>2025-05-09 10:00:00</td>\n",
              "      <td>102915.58</td>\n",
              "      <td>102915.58</td>\n",
              "      <td>102888.00</td>\n",
              "      <td>102888.01</td>\n",
              "      <td>4.679830</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>55631 rows × 6 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7334195c-bf2a-4abf-8a93-073b20da8979')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7334195c-bf2a-4abf-8a93-073b20da8979 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7334195c-bf2a-4abf-8a93-073b20da8979');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-56bb8023-0d3d-4212-9dc3-40e9f71a7cd4\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-56bb8023-0d3d-4212-9dc3-40e9f71a7cd4')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-56bb8023-0d3d-4212-9dc3-40e9f71a7cd4 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"data_h['BTC/USDT']\",\n  \"rows\": 55631,\n  \"fields\": [\n    {\n      \"column\": \"timestamp\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2019-01-01 00:00:00\",\n        \"max\": \"2025-05-09 10:00:00\",\n        \"num_unique_values\": 55631,\n        \"samples\": [\n          \"2022-06-22 08:00:00\",\n          \"2022-05-14 01:00:00\",\n          \"2023-05-06 04:00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"open\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 25618.11049591001,\n        \"min\": 3366.63,\n        \"max\": 108320.0,\n        \"num_unique_values\": 54873,\n        \"samples\": [\n          23206.4,\n          57393.19,\n          23933.09\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"high\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 25720.06480785775,\n        \"min\": 3386.97,\n        \"max\": 109588.0,\n        \"num_unique_values\": 51193,\n        \"samples\": [\n          35290.97,\n          3409.54,\n          8332.9\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"low\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 25514.523884866867,\n        \"min\": 3349.92,\n        \"max\": 107780.51,\n        \"num_unique_values\": 51603,\n        \"samples\": [\n          3432.02,\n          61025.42,\n          59163.16\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"close\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 25619.39922294327,\n        \"min\": 3366.41,\n        \"max\": 108320.01,\n        \"num_unique_values\": 54882,\n        \"samples\": [\n          26702.64,\n          18732.18,\n          31172.49\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"volume\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4340.112683255605,\n        \"min\": 0.0,\n        \"max\": 137207.1886,\n        \"num_unique_values\": 55628,\n        \"samples\": [\n          8526.58092,\n          2001.406171,\n          1304.379583\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ta"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Baz2v_pbNT4n",
        "outputId": "45b68345-5984-4e43-a81b-40470cf174e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ta\n",
            "  Downloading ta-0.11.0.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from ta) (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from ta) (2.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->ta) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->ta) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->ta) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->ta) (1.17.0)\n",
            "Building wheels for collected packages: ta\n",
            "  Building wheel for ta (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ta: filename=ta-0.11.0-py3-none-any.whl size=29412 sha256=38e8167162716bdc406700bc3279685deaf298c9d775ca6a2038860fc0a970a4\n",
            "  Stored in directory: /root/.cache/pip/wheels/a1/d7/29/7781cc5eb9a3659d032d7d15bdd0f49d07d2b24fec29f44bc4\n",
            "Successfully built ta\n",
            "Installing collected packages: ta\n",
            "Successfully installed ta-0.11.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)"
      ],
      "metadata": {
        "id": "mQYfm2P7Q03b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import ta\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error"
      ],
      "metadata": {
        "id": "4rAmP-IANRmt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def add_technical_indicators(df):\n",
        "    # Скользящие средние\n",
        "    df['SMA_7'] = ta.trend.sma_indicator(df['close'], window=7)\n",
        "    df['SMA_21'] = ta.trend.sma_indicator(df['close'], window=21)\n",
        "    df['EMA_7'] = ta.trend.ema_indicator(df['close'], window=7)\n",
        "    df['EMA_21'] = ta.trend.ema_indicator(df['close'], window=21)\n",
        "\n",
        "    # MACD\n",
        "    df['MACD'] = ta.trend.macd(df['close'])\n",
        "    df['MACD_signal'] = ta.trend.macd_signal(df['close'])\n",
        "    df['MACD_diff'] = ta.trend.macd_diff(df['close'])\n",
        "\n",
        "    # RSI\n",
        "    df['RSI_14'] = ta.momentum.rsi(df['close'], window=14)\n",
        "\n",
        "    # Bollinger Bands\n",
        "    bb_indicator = ta.volatility.BollingerBands(close=df['close'], window=20, window_dev=2)\n",
        "    df['BB_upper'] = bb_indicator.bollinger_hband()\n",
        "    df['BB_middle'] = bb_indicator.bollinger_mavg()\n",
        "    df['BB_lower'] = bb_indicator.bollinger_lband()\n",
        "\n",
        "    # ATR (волатильность)\n",
        "    df['ATR_14'] = ta.volatility.average_true_range(df['high'], df['low'], df['close'], window=14)\n",
        "\n",
        "    # Стохастик\n",
        "    stoch = ta.momentum.StochasticOscillator(high=df['high'], low=df['low'], close=df['close'], window=14, smooth_window=3)\n",
        "    df['STOCH_slowk'] = stoch.stoch()\n",
        "    df['STOCH_slowd'] = stoch.stoch_signal()\n",
        "\n",
        "    # OBV (объем)\n",
        "    df['OBV'] = ta.volume.on_balance_volume(df['close'], df['volume'])\n",
        "\n",
        "    # Добавляем CCI (Commodity Channel Index)\n",
        "    # Рассчитаем Typical Price\n",
        "    df['TP'] = (df['high'] + df['low'] + df['close']) / 3\n",
        "    # SMA от Typical Price\n",
        "    n = 20\n",
        "    df['TP_SMA'] = df['TP'].rolling(window=n).mean()\n",
        "    # Среднее абсолютное отклонение (MAD)\n",
        "    df['TP_MAD'] = df['TP'].rolling(window=n).apply(lambda x: np.mean(np.abs(x - np.mean(x))), raw=True)\n",
        "    # CCI\n",
        "    df['CCI_20'] = (df['TP'] - df['TP_SMA']) / (0.015 * df['TP_MAD'])\n",
        "\n",
        "    # Производные признаки\n",
        "    df['return_1h'] = df['close'].pct_change()\n",
        "    df['log_return'] = np.log(df['close'] / df['close'].shift(1))\n",
        "    df['range'] = df['high'] - df['low']\n",
        "    df['close_open_diff'] = df['close'] - df['open']\n",
        "\n",
        "    # Временные признаки\n",
        "    df['hour'] = df['timestamp'].dt.hour\n",
        "    df['dayofweek'] = df['timestamp'].dt.dayofweek\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "gdq7SGT8NLrj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import RFE\n",
        "\n",
        "def feature_selection_rfe(df, target_col='log_return', n_features_to_select=10):\n",
        "    df = df.dropna()\n",
        "    df['target'] = df[target_col].shift(-1)\n",
        "    df = df.dropna()\n",
        "\n",
        "    X = df.drop(columns=['target', 'timestamp'])\n",
        "    y = df['target']\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
        "\n",
        "    model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "    selector = RFE(model, n_features_to_select=n_features_to_select, step=1)\n",
        "    selector = selector.fit(X_train, y_train)\n",
        "\n",
        "    selected_features = X.columns[selector.support_].tolist()\n",
        "    print(f\"Selected features by RFE ({len(selected_features)}): {selected_features}\")\n",
        "\n",
        "    # Обучаем модель на выбранных признаках\n",
        "    model.fit(X_train[selected_features], y_train)\n",
        "    preds = model.predict(X_test[selected_features])\n",
        "    print(f\"RMSE on test set: {mean_squared_error(y_test, preds, squared=False):.6f}\")\n",
        "\n",
        "    return df[selected_features + ['target']]\n"
      ],
      "metadata": {
        "id": "DFgjHaXgTnYb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LassoCV\n",
        "\n",
        "def feature_selection_lasso(df, target_col='log_return', alpha=0.001):\n",
        "    df = df.dropna()\n",
        "    df['target'] = df[target_col].shift(-1)\n",
        "    df = df.dropna()\n",
        "\n",
        "    X = df.drop(columns=['target', 'timestamp'])\n",
        "    y = df['target']\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
        "\n",
        "    model = LassoCV(alphas=[alpha], cv=5, random_state=42)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    coef = pd.Series(model.coef_, index=X.columns)\n",
        "    selected_features = coef[coef != 0].index.tolist()\n",
        "    print(f\"Selected features by Lasso ({len(selected_features)}): {selected_features}\")\n",
        "\n",
        "    preds = model.predict(X_test[selected_features])\n",
        "    print(f\"RMSE on test set: {mean_squared_error(y_test, preds, squared=False):.6f}\")\n",
        "\n",
        "    return df[selected_features + ['target']]\n"
      ],
      "metadata": {
        "id": "UFSmCyMITpjE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install shap"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dIF9OnD0TtEY",
        "outputId": "7a68c3e2-5b24-40f3-e3db-da4f996b0dbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: shap in /usr/local/lib/python3.11/dist-packages (0.47.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from shap) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from shap) (1.15.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from shap) (1.6.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from shap) (2.2.2)\n",
            "Requirement already satisfied: tqdm>=4.27.0 in /usr/local/lib/python3.11/dist-packages (from shap) (4.67.1)\n",
            "Requirement already satisfied: packaging>20.9 in /usr/local/lib/python3.11/dist-packages (from shap) (24.2)\n",
            "Requirement already satisfied: slicer==0.0.8 in /usr/local/lib/python3.11/dist-packages (from shap) (0.0.8)\n",
            "Requirement already satisfied: numba>=0.54 in /usr/local/lib/python3.11/dist-packages (from shap) (0.60.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from shap) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from shap) (4.13.2)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.54->shap) (0.43.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->shap) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->shap) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->shap) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->shap) (1.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->shap) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->shap) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shap\n",
        "\n",
        "def feature_selection_shap(df, target_col='log_return', top_n=10):\n",
        "    df = df.dropna()\n",
        "    df['target'] = df[target_col].shift(-1)\n",
        "    df = df.dropna()\n",
        "\n",
        "    X = df.drop(columns=['target', 'timestamp'])\n",
        "    y = df['target']\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
        "\n",
        "    model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    explainer = shap.TreeExplainer(model)\n",
        "    shap_values = explainer.shap_values(X_train)\n",
        "\n",
        "    shap_importance = np.abs(shap_values).mean(axis=0)\n",
        "    feature_importances = pd.Series(shap_importance, index=X.columns)\n",
        "    feature_importances = feature_importances.sort_values(ascending=False)\n",
        "\n",
        "    selected_features = feature_importances.head(top_n).index.tolist()\n",
        "    print(f\"Selected top {top_n} features by SHAP: {selected_features}\")\n",
        "\n",
        "    preds = model.predict(X_test[selected_features])\n",
        "    print(f\"RMSE on test set: {mean_squared_error(y_test, preds, squared=False):.6f}\")\n",
        "\n",
        "    return df[selected_features + ['target']]\n"
      ],
      "metadata": {
        "id": "nP9FJvJGTsVe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def feature_selection(df, target_col='log_return'):\n",
        "    df = df.dropna()\n",
        "    df['target'] = df[target_col].shift(-1)\n",
        "    df = df.dropna()\n",
        "\n",
        "    X = df.drop(columns=['target', 'timestamp'])\n",
        "    y = df['target']\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
        "\n",
        "    model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    preds = model.predict(X_test)\n",
        "    print(f\"RMSE on test set: {mean_squared_error(y_test, preds) ** 0.5 :.6f}\")\n",
        "\n",
        "    feature_importances = pd.Series(model.feature_importances_, index=X.columns)\n",
        "    feature_importances = feature_importances.sort_values(ascending=False)\n",
        "\n",
        "    threshold = feature_importances.mean()\n",
        "    selected_features = feature_importances[feature_importances > threshold].index.tolist()\n",
        "\n",
        "    print(\"Selected features based on importance:\")\n",
        "    print(selected_features)\n",
        "\n",
        "    return df[selected_features + ['target']]"
      ],
      "metadata": {
        "id": "2y_6wI0FNLpO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.linear_model import LassoCV"
      ],
      "metadata": {
        "id": "NRwuspGAaWpR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def feature_selection(df, target_col='log_return', rfe_features=10, lasso_alpha=0.001):\n",
        "    df = df.dropna()\n",
        "    df['target'] = df[target_col].shift(-1)\n",
        "    df = df.dropna()\n",
        "\n",
        "    X = df.drop(columns=['target', 'timestamp'])\n",
        "    y = df['target']\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
        "\n",
        "    results = {}\n",
        "\n",
        "    # 1. LightGBM feature importance\n",
        "    lgb_train = lgb.Dataset(X_train, label=y_train)\n",
        "    params = {\n",
        "        'objective': 'regression',\n",
        "        'metric': 'rmse',\n",
        "        'verbosity': -1,\n",
        "        'boosting_type': 'gbdt',\n",
        "        'n_jobs': -1,\n",
        "        'seed': 42\n",
        "    }\n",
        "    lgb_model = lgb.train(params, lgb_train, num_boost_round=100)\n",
        "    lgb_importance = pd.Series(lgb_model.feature_importance(importance_type='gain'), index=X.columns)\n",
        "    lgb_importance = lgb_importance.sort_values(ascending=False)\n",
        "    lgb_selected = lgb_importance[lgb_importance > lgb_importance.mean()].index.tolist()\n",
        "\n",
        "    lgb_preds = lgb_model.predict(X_test)\n",
        "    lgb_rmse = mean_squared_error(y_test, lgb_preds) ** 0.5\n",
        "    results['LightGBM_Importance'] = {'features': lgb_selected, 'rmse': lgb_rmse}\n",
        "    print(f\"[LightGBM Importance] RMSE: {lgb_rmse:.6f}\")\n",
        "    print(f\"[LightGBM Importance] Selected features ({len(lgb_selected)}): {lgb_selected}\\n\")\n",
        "\n",
        "    # 2. RFE с LightGBM\n",
        "    lgb_estimator = lgb.LGBMRegressor(n_estimators=100, n_jobs=-1, random_state=42)\n",
        "    rfe_selector = RFE(estimator=lgb_estimator, n_features_to_select=rfe_features, step=5, verbose=1)\n",
        "    rfe_selector = rfe_selector.fit(X_train, y_train)\n",
        "    rfe_selected = X.columns[rfe_selector.support_].tolist()\n",
        "\n",
        "    rfe_estimator = lgb.LGBMRegressor(n_estimators=100, n_jobs=-1, random_state=42)\n",
        "    rfe_estimator.fit(X_train[rfe_selected], y_train)\n",
        "    rfe_preds = rfe_estimator.predict(X_test[rfe_selected])\n",
        "    rfe_rmse = mean_squared_error(y_test, rfe_preds) ** 0.5\n",
        "    results['RFE_LightGBM'] = {'features': rfe_selected, 'rmse': rfe_rmse}\n",
        "    print(f\"[RFE LightGBM] RMSE: {rfe_rmse:.6f}\")\n",
        "    print(f\"[RFE LightGBM] Selected features ({len(rfe_selected)}): {rfe_selected}\\n\")\n",
        "\n",
        "    # 3. LassoCV\n",
        "    lasso_model = LassoCV(alphas=[lasso_alpha], cv=5, random_state=42, max_iter=10000)\n",
        "    lasso_model.fit(X_train, y_train)\n",
        "    coef = pd.Series(lasso_model.coef_, index=X.columns)\n",
        "    lasso_selected = coef[coef != 0].index.tolist()\n",
        "\n",
        "    lasso_preds = lasso_model.predict(X_test)\n",
        "    lasso_rmse = mean_squared_error(y_test, lasso_preds) ** 0.5\n",
        "    results['LassoCV'] = {'features': lasso_selected, 'rmse': lasso_rmse}\n",
        "    print(f\"[LassoCV] RMSE: {lasso_rmse:.6f}\")\n",
        "    print(f\"[LassoCV] Selected features ({len(lasso_selected)}): {lasso_selected}\\n\")\n",
        "\n",
        "    return results, df"
      ],
      "metadata": {
        "id": "MmtkkEyMVB9i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_pair(df_pair):\n",
        "    df_pair['timestamp'] = pd.to_datetime(df_pair['timestamp'])\n",
        "    df_pair = add_technical_indicators(df_pair)\n",
        "    df_selected = feature_selection(df_pair, target_col='log_return')\n",
        "    return df_selected"
      ],
      "metadata": {
        "id": "wgvlRYAXNLnA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "selected_data = {}\n",
        "\n",
        "for pair, df_pair in data_h.items():\n",
        "    print(f\"Processing {pair}...\")\n",
        "    try:\n",
        "        selected_df = process_pair(df_pair)\n",
        "        selected_data[pair] = selected_df\n",
        "        print(f\"Finished processing {pair}. Selected features shape: {selected_df.shape}\\n\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {pair}: {e}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8p32JSjJNLkp",
        "outputId": "9fdb6b32-7884-475c-8c62-3e0305122b7a",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing XRP/USDT...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-b4e74f513004>:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['target'] = df[target_col].shift(-1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM Importance] RMSE: 0.011538\n",
            "[LightGBM Importance] Selected features (15): ['volume', 'OBV', 'return_1h', 'STOCH_slowd', 'STOCH_slowk', 'range', 'TP_MAD', 'RSI_14', 'hour', 'MACD_signal', 'CCI_20', 'ATR_14', 'MACD', 'MACD_diff', 'close_open_diff']\n",
            "\n",
            "Fitting estimator with 30 features.\n",
            "Fitting estimator with 25 features.\n",
            "Fitting estimator with 20 features.\n",
            "Fitting estimator with 15 features.\n",
            "[RFE LightGBM] RMSE: 0.011230\n",
            "[RFE LightGBM] Selected features (10): ['volume', 'MACD_diff', 'RSI_14', 'ATR_14', 'STOCH_slowk', 'STOCH_slowd', 'OBV', 'TP_MAD', 'return_1h', 'range']\n",
            "\n",
            "[LassoCV] RMSE: 0.010370\n",
            "[LassoCV] Selected features (3): ['volume', 'OBV', 'CCI_20']\n",
            "\n",
            "Error processing XRP/USDT: 'tuple' object has no attribute 'shape'\n",
            "\n",
            "Processing TRX/USDT...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-b4e74f513004>:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['target'] = df[target_col].shift(-1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM Importance] RMSE: 0.007609\n",
            "[LightGBM Importance] Selected features (15): ['volume', 'range', 'MACD_signal', 'STOCH_slowk', 'MACD_diff', 'ATR_14', 'OBV', 'return_1h', 'STOCH_slowd', 'CCI_20', 'TP_MAD', 'RSI_14', 'close_open_diff', 'hour', 'MACD']\n",
            "\n",
            "Fitting estimator with 30 features.\n",
            "Fitting estimator with 25 features.\n",
            "Fitting estimator with 20 features.\n",
            "Fitting estimator with 15 features.\n",
            "[RFE LightGBM] RMSE: 0.006480\n",
            "[RFE LightGBM] Selected features (10): ['volume', 'MACD_signal', 'MACD_diff', 'BB_lower', 'ATR_14', 'STOCH_slowd', 'OBV', 'CCI_20', 'return_1h', 'range']\n",
            "\n",
            "[LassoCV] RMSE: 0.005827\n",
            "[LassoCV] Selected features (3): ['volume', 'STOCH_slowd', 'OBV']\n",
            "\n",
            "Error processing TRX/USDT: 'tuple' object has no attribute 'shape'\n",
            "\n",
            "Processing BTC/USDT...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-b4e74f513004>:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['target'] = df[target_col].shift(-1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM Importance] RMSE: 0.005924\n",
            "[LightGBM Importance] Selected features (14): ['ATR_14', 'TP_MAD', 'OBV', 'volume', 'STOCH_slowk', 'range', 'MACD', 'STOCH_slowd', 'CCI_20', 'return_1h', 'MACD_diff', 'RSI_14', 'MACD_signal', 'hour']\n",
            "\n",
            "Fitting estimator with 30 features.\n",
            "Fitting estimator with 25 features.\n",
            "Fitting estimator with 20 features.\n",
            "Fitting estimator with 15 features.\n",
            "[RFE LightGBM] RMSE: 0.005896\n",
            "[RFE LightGBM] Selected features (10): ['volume', 'MACD_diff', 'RSI_14', 'ATR_14', 'STOCH_slowk', 'STOCH_slowd', 'OBV', 'TP_MAD', 'CCI_20', 'return_1h']\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.9347373668696118, tolerance: 0.0001912103521750576\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.8232565453843257, tolerance: 0.0001717423545617122\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.79932306577481, tolerance: 0.00016798446714739809\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.9529651380700292, tolerance: 0.00019488226586628744\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.0535056839528423, tolerance: 0.00021661494546773225\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.140e+00, tolerance: 2.356e-04\n",
            "  model = cd_fast.enet_coordinate_descent(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LassoCV] RMSE: 0.005662\n",
            "[LassoCV] Selected features (20): ['open', 'high', 'close', 'volume', 'SMA_7', 'SMA_21', 'EMA_7', 'EMA_21', 'MACD', 'MACD_diff', 'BB_upper', 'BB_middle', 'BB_lower', 'OBV', 'TP', 'TP_SMA', 'TP_MAD', 'CCI_20', 'range', 'close_open_diff']\n",
            "\n",
            "Error processing BTC/USDT: 'tuple' object has no attribute 'shape'\n",
            "\n",
            "Processing SOL/USDT...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-b4e74f513004>:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['target'] = df[target_col].shift(-1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM Importance] RMSE: 0.009925\n",
            "[LightGBM Importance] Selected features (14): ['volume', 'OBV', 'return_1h', 'ATR_14', 'RSI_14', 'MACD_diff', 'MACD_signal', 'STOCH_slowd', 'STOCH_slowk', 'TP_MAD', 'MACD', 'CCI_20', 'hour', 'range']\n",
            "\n",
            "Fitting estimator with 30 features.\n",
            "Fitting estimator with 25 features.\n",
            "Fitting estimator with 20 features.\n",
            "Fitting estimator with 15 features.\n",
            "[RFE LightGBM] RMSE: 0.009945\n",
            "[RFE LightGBM] Selected features (10): ['volume', 'MACD_diff', 'RSI_14', 'BB_lower', 'STOCH_slowk', 'STOCH_slowd', 'OBV', 'TP_MAD', 'CCI_20', 'return_1h']\n",
            "\n",
            "[LassoCV] RMSE: 0.009762\n",
            "[LassoCV] Selected features (5): ['close', 'volume', 'STOCH_slowd', 'OBV', 'CCI_20']\n",
            "\n",
            "Error processing SOL/USDT: 'tuple' object has no attribute 'shape'\n",
            "\n",
            "Processing ETH/USDT...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-b4e74f513004>:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['target'] = df[target_col].shift(-1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM Importance] RMSE: 0.007711\n",
            "[LightGBM Importance] Selected features (14): ['volume', 'STOCH_slowd', 'ATR_14', 'STOCH_slowk', 'OBV', 'MACD_signal', 'RSI_14', 'range', 'hour', 'CCI_20', 'return_1h', 'MACD_diff', 'TP_MAD', 'MACD']\n",
            "\n",
            "Fitting estimator with 30 features.\n",
            "Fitting estimator with 25 features.\n",
            "Fitting estimator with 20 features.\n",
            "Fitting estimator with 15 features.\n",
            "[RFE LightGBM] RMSE: 0.007722\n",
            "[RFE LightGBM] Selected features (10): ['volume', 'MACD_diff', 'BB_lower', 'ATR_14', 'STOCH_slowk', 'STOCH_slowd', 'OBV', 'CCI_20', 'return_1h', 'hour']\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.5045121362358174, tolerance: 0.00030188923075903765\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.3340011713038529, tolerance: 0.00026762205562831664\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.3491499740128121, tolerance: 0.00029185125174041896\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.704308836598657, tolerance: 0.0003426374788327422\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LassoCV] RMSE: 0.007496\n",
            "[LassoCV] Selected features (8): ['open', 'volume', 'SMA_7', 'OBV', 'TP', 'CCI_20', 'range', 'hour']\n",
            "\n",
            "Error processing ETH/USDT: 'tuple' object has no attribute 'shape'\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.810e+00, tolerance: 3.647e-04\n",
            "  model = cd_fast.enet_coordinate_descent(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Новая попытка создать рабочую модель (от 17.05 16:20)"
      ],
      "metadata": {
        "id": "rAW1poezZYet"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## test"
      ],
      "metadata": {
        "id": "RnGDkwVWMc8i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import lightgbm as lgb\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.linear_model import LassoCV\n",
        "import torch.nn as nn\n",
        "from torch.optim import Adam"
      ],
      "metadata": {
        "id": "1-5EXxEwZvZm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class BiLSTMModel(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim=64, num_layers=2, dropout=0.2):\n",
        "        super(BiLSTMModel, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers=num_layers,\n",
        "                            batch_first=True, bidirectional=True, dropout=dropout)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.fc = nn.Linear(hidden_dim * 2, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.lstm(x)\n",
        "        out = out[:, -1, :]\n",
        "        out = self.dropout(out)\n",
        "        out = self.fc(out)\n",
        "        return out.squeeze()"
      ],
      "metadata": {
        "id": "zthqlkZMNLfz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CryptoDataset(Dataset):\n",
        "    def __init__(self, df, feature_cols, target_col='log_return', seq_len=24):\n",
        "        self.seq_len = seq_len\n",
        "        df = df.dropna(subset=feature_cols + [target_col]).reset_index(drop=True)\n",
        "        self.scaler = StandardScaler()\n",
        "        features = df[feature_cols].values\n",
        "        self.features = self.scaler.fit_transform(features)\n",
        "        self.targets = df[target_col].values\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.targets) - self.seq_len\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x = self.features[idx:idx+self.seq_len]\n",
        "        y = self.targets[idx + self.seq_len]\n",
        "        return torch.tensor(x, dtype=torch.float32), torch.tensor(y, dtype=torch.float32)"
      ],
      "metadata": {
        "id": "HVe9J4jqNLdL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim import Adam\n",
        "from sklearn.metrics import mean_squared_error"
      ],
      "metadata": {
        "id": "5JgS-_kalUFs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def inverse_transform(scaler, data_scaled, feature_index=0):\n",
        "    \"\"\"\n",
        "    Обратное преобразование стандартизованных данных для одного признака.\n",
        "    scaler: объект StandardScaler\n",
        "    data_scaled: np.array или список значений в стандартизованном виде\n",
        "    feature_index: индекс признака в scaler.mean_ и scaler.scale_\n",
        "    \"\"\"\n",
        "    mean = scaler.mean_[feature_index]\n",
        "    scale = scaler.scale_[feature_index]\n",
        "    return data_scaled * scale + mean\n",
        "\n",
        "\n",
        "def compute_financial_metrics(y_true_scaled, y_pred_scaled, scaler, target_feature_index=0):\n",
        "    y_true = inverse_transform(scaler, y_true_scaled, target_feature_index)\n",
        "    y_pred = inverse_transform(scaler, y_pred_scaled, target_feature_index)\n",
        "\n",
        "    returns_true = np.diff(y_true) / y_true[:-1]\n",
        "    returns_pred = np.diff(y_pred) / y_pred[:-1]\n",
        "    directional_accuracy = np.mean(np.sign(returns_true) == np.sign(returns_pred))\n",
        "    hit_ratio = directional_accuracy\n",
        "\n",
        "    excess_returns = returns_pred\n",
        "    sharpe_ratio = np.mean(excess_returns) / (np.std(excess_returns) + 1e-9) * np.sqrt(365*24)\n",
        "\n",
        "    rmse = np.sqrt(np.mean((y_true - y_pred)**2))\n",
        "\n",
        "    return {\n",
        "        'Directional Accuracy': directional_accuracy,\n",
        "        'Hit Ratio': hit_ratio,\n",
        "        'Sharpe Ratio': sharpe_ratio,\n",
        "        'RMSE': rmse\n",
        "    }"
      ],
      "metadata": {
        "id": "NiBOld1TfQSg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_loader, val_loader, epochs=50, lr=1e-3, device='cuda'):\n",
        "    model.to(device)\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = Adam(model.parameters(), lr=lr)\n",
        "    best_val_loss = float('inf')\n",
        "    patience = 10\n",
        "    trigger_times = 0\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        train_losses = []\n",
        "        for x_batch, y_batch in train_loader:\n",
        "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            preds = model(x_batch)\n",
        "            loss = criterion(preds, y_batch)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_losses.append(loss.item())\n",
        "\n",
        "        model.eval()\n",
        "        val_losses = []\n",
        "        val_preds, val_targets = [], []\n",
        "        with torch.no_grad():\n",
        "            for x_val, y_val in val_loader:\n",
        "                x_val, y_val = x_val.to(device), y_val.to(device)\n",
        "                preds = model(x_val)\n",
        "                loss = criterion(preds, y_val)\n",
        "                val_losses.append(loss.item())\n",
        "                val_preds.extend(preds.cpu().numpy())\n",
        "                val_targets.extend(y_val.cpu().numpy())\n",
        "\n",
        "        avg_train_loss = np.mean(train_losses)\n",
        "        avg_val_loss = np.mean(val_losses)\n",
        "        val_rmse = np.sqrt(mean_squared_error(val_targets, val_preds))\n",
        "\n",
        "        print(f\"Epoch {epoch+1}: Train Loss={avg_train_loss:.6f}, Val Loss={avg_val_loss:.6f}, Val RMSE={val_rmse:.6f}\")\n",
        "\n",
        "        if avg_val_loss < best_val_loss:\n",
        "            best_val_loss = avg_val_loss\n",
        "            trigger_times = 0\n",
        "            torch.save(model.state_dict(), 'best_bilstm_model.pth')\n",
        "        else:\n",
        "            trigger_times += 1\n",
        "            if trigger_times >= patience:\n",
        "                print(\"Early stopping triggered\")\n",
        "                break"
      ],
      "metadata": {
        "id": "xFPD4i69Z3MA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model_with_metrics(model, test_loader, dataset, feature_index=0, device='cuda'):\n",
        "    model.load_state_dict(torch.load('best_bilstm_model.pth'))\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    preds, targets = [], []\n",
        "    with torch.no_grad():\n",
        "        for x_test, y_test in test_loader:\n",
        "            x_test, y_test = x_test.to(device), y_test.to(device)\n",
        "            pred = model(x_test)\n",
        "            preds.extend(pred.cpu().numpy())\n",
        "            targets.extend(y_test.cpu().numpy())\n",
        "\n",
        "    preds = np.array(preds)\n",
        "    targets = np.array(targets)\n",
        "\n",
        "    scaler = dataset.scaler\n",
        "\n",
        "    metrics = compute_financial_metrics(targets, preds, scaler, target_feature_index=feature_index)\n",
        "    print(\"Evaluation metrics on denormalized data:\")\n",
        "    for k, v in metrics.items():\n",
        "        print(f\"{k}: {v:.6f}\")\n",
        "\n",
        "    return metrics"
      ],
      "metadata": {
        "id": "dg3QGSyvZ3J5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ensure_close_feature(features, mandatory_feature='close'):\n",
        "    if mandatory_feature not in features:\n",
        "        features.append(mandatory_feature)\n",
        "    return features\n",
        "# --- Feature selection methods ---\n",
        "def feature_selection_methods(df, target_col='log_return'):\n",
        "    df = df.dropna()\n",
        "    df['target'] = df[target_col].shift(-1)\n",
        "    df = df.dropna()\n",
        "    X = df.drop(columns=['target', 'timestamp'])\n",
        "    y = df['target']\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
        "\n",
        "    results = {}\n",
        "\n",
        "    # 1. LightGBM Importance\n",
        "    lgb_train = lgb.Dataset(X_train, label=y_train)\n",
        "    params = {'objective': 'regression', 'metric': 'rmse', 'verbosity': -1, 'boosting_type': 'gbdt', 'n_jobs': -1, 'seed': 42}\n",
        "    lgb_model = lgb.train(params, lgb_train, num_boost_round=100)\n",
        "    lgb_importance = pd.Series(lgb_model.feature_importance(importance_type='gain'), index=X.columns).sort_values(ascending=False)\n",
        "    lgb_selected = lgb_importance[lgb_importance > lgb_importance.mean()].index.tolist()\n",
        "    lgb_selected = ensure_close_feature(lgb_selected)\n",
        "    results['LightGBM_Importance'] = lgb_selected\n",
        "\n",
        "    # 2. RFE с LightGBM\n",
        "    lgb_estimator = lgb.LGBMRegressor(n_estimators=100, n_jobs=-1, random_state=42)\n",
        "    rfe_selector = RFE(estimator=lgb_estimator, n_features_to_select=min(10, len(X.columns)), step=5, verbose=0)\n",
        "    rfe_selector = rfe_selector.fit(X_train, y_train)\n",
        "    rfe_selected = X.columns[rfe_selector.support_].tolist()\n",
        "    rfe_selected = ensure_close_feature(rfe_selected)\n",
        "    results['RFE_LightGBM'] = rfe_selected\n",
        "\n",
        "    # 3. LassoCV\n",
        "    lasso_model = LassoCV(cv=5, random_state=42, max_iter=10000)\n",
        "    lasso_model.fit(X_train, y_train)\n",
        "    coef = pd.Series(lasso_model.coef_, index=X.columns)\n",
        "    lasso_selected = coef[coef != 0].index.tolist()\n",
        "    lasso_selected = ensure_close_feature(lasso_selected)\n",
        "    results['LassoCV'] = lasso_selected\n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "id": "lU4vUOIPZ3He"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_pipeline(data_dict, seq_len=24, batch_size=64, device='cuda'):\n",
        "    for coin, df in data_dict.items():\n",
        "        print(f\"\\n=== Processing {coin} ===\")\n",
        "        feature_sets = feature_selection_methods(df)\n",
        "        for method_name, features in feature_sets.items():\n",
        "            print(f\"\\nMethod: {method_name}, selected features count: {len(features)}\")\n",
        "            if len(features) == 0:\n",
        "                print(\"No features selected, skipping...\")\n",
        "                continue\n",
        "\n",
        "            dataset = CryptoDataset(df, feature_cols=features, target_col='log_return', seq_len=seq_len)\n",
        "            train_size = int(len(dataset) * 0.7)\n",
        "            val_size = int(len(dataset) * 0.15)\n",
        "            test_size = len(dataset) - train_size - val_size\n",
        "\n",
        "            train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, val_size, test_size])\n",
        "\n",
        "            train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
        "            val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "            test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "            model = BiLSTMModel(input_dim=len(features)).to(device)\n",
        "            print(f\"Training BiLSTM on {coin} with features from {method_name}...\")\n",
        "            train_model(model, train_loader, val_loader, epochs=25, lr=1e-4, device=device)\n",
        "            metrics = evaluate_model_with_metrics(model, test_loader, test_dataset.dataset, feature_index=features.index('close'), device=device)\n",
        "            print(f\"Final metrics for {coin} with {method_name}: {metrics}\")"
      ],
      "metadata": {
        "id": "3bCUvcBwZ3FM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Эксперименты с BiLSTM"
      ],
      "metadata": {
        "id": "vtZ9VvD8rxfW"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Dyxse8HPcKzu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_pipeline(data_h, seq_len=96, batch_size=128, device='cuda')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AEz2qfcRZ3C5",
        "outputId": "b2c39866-267f-4893-bb62-f54686a6aa63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-27-212b939d4a93>:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['target'] = df[target_col].shift(-1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Processing XRP/USDT ===\n",
            "\n",
            "Method: LightGBM_Importance, selected features count: 16\n",
            "Training BiLSTM on XRP/USDT with features from LightGBM_Importance...\n",
            "Epoch 1: Train Loss=0.000454, Val Loss=0.000120, Val RMSE=0.011032\n",
            "Epoch 2: Train Loss=0.000260, Val Loss=0.000116, Val RMSE=0.010824\n",
            "Epoch 3: Train Loss=0.000205, Val Loss=0.000115, Val RMSE=0.010781\n",
            "Epoch 4: Train Loss=0.000186, Val Loss=0.000114, Val RMSE=0.010769\n",
            "Epoch 5: Train Loss=0.000168, Val Loss=0.000115, Val RMSE=0.010780\n",
            "Epoch 6: Train Loss=0.000158, Val Loss=0.000114, Val RMSE=0.010747\n",
            "Epoch 7: Train Loss=0.000152, Val Loss=0.000114, Val RMSE=0.010771\n",
            "Epoch 8: Train Loss=0.000148, Val Loss=0.000114, Val RMSE=0.010767\n",
            "Epoch 9: Train Loss=0.000145, Val Loss=0.000114, Val RMSE=0.010753\n",
            "Epoch 10: Train Loss=0.000141, Val Loss=0.000114, Val RMSE=0.010760\n",
            "Epoch 11: Train Loss=0.000139, Val Loss=0.000114, Val RMSE=0.010763\n",
            "Epoch 12: Train Loss=0.000138, Val Loss=0.000114, Val RMSE=0.010756\n",
            "Epoch 13: Train Loss=0.000137, Val Loss=0.000114, Val RMSE=0.010762\n",
            "Epoch 14: Train Loss=0.000134, Val Loss=0.000114, Val RMSE=0.010734\n",
            "Epoch 15: Train Loss=0.000134, Val Loss=0.000114, Val RMSE=0.010758\n",
            "Epoch 16: Train Loss=0.000133, Val Loss=0.000114, Val RMSE=0.010741\n",
            "Epoch 17: Train Loss=0.000132, Val Loss=0.000114, Val RMSE=0.010747\n",
            "Epoch 18: Train Loss=0.000131, Val Loss=0.000114, Val RMSE=0.010740\n",
            "Epoch 19: Train Loss=0.000130, Val Loss=0.000114, Val RMSE=0.010730\n",
            "Epoch 20: Train Loss=0.000130, Val Loss=0.000114, Val RMSE=0.010730\n",
            "Epoch 21: Train Loss=0.000129, Val Loss=0.000114, Val RMSE=0.010727\n",
            "Epoch 22: Train Loss=0.000129, Val Loss=0.000114, Val RMSE=0.010730\n",
            "Epoch 23: Train Loss=0.000128, Val Loss=0.000113, Val RMSE=0.010724\n",
            "Epoch 24: Train Loss=0.000127, Val Loss=0.000114, Val RMSE=0.010738\n",
            "Epoch 25: Train Loss=0.000127, Val Loss=0.000114, Val RMSE=0.010730\n",
            "Evaluation metrics on denormalized data:\n",
            "Directional Accuracy: 0.497057\n",
            "Hit Ratio: 0.497057\n",
            "Sharpe Ratio: 0.006967\n",
            "RMSE: 0.005789\n",
            "Final metrics for XRP/USDT with LightGBM_Importance: {'Directional Accuracy': np.float64(0.49705705705705705), 'Hit Ratio': np.float64(0.49705705705705705), 'Sharpe Ratio': np.float64(0.0069665698493669905), 'RMSE': np.float64(0.005789166309580278)}\n",
            "\n",
            "Method: RFE_LightGBM, selected features count: 11\n",
            "Training BiLSTM on XRP/USDT with features from RFE_LightGBM...\n",
            "Epoch 1: Train Loss=0.000835, Val Loss=0.000125, Val RMSE=0.011228\n",
            "Epoch 2: Train Loss=0.000275, Val Loss=0.000122, Val RMSE=0.011108\n",
            "Epoch 3: Train Loss=0.000226, Val Loss=0.000120, Val RMSE=0.011028\n",
            "Epoch 4: Train Loss=0.000196, Val Loss=0.000120, Val RMSE=0.011030\n",
            "Epoch 5: Train Loss=0.000173, Val Loss=0.000119, Val RMSE=0.010980\n",
            "Epoch 6: Train Loss=0.000159, Val Loss=0.000119, Val RMSE=0.010985\n",
            "Epoch 7: Train Loss=0.000151, Val Loss=0.000119, Val RMSE=0.010965\n",
            "Epoch 8: Train Loss=0.000147, Val Loss=0.000119, Val RMSE=0.010964\n",
            "Epoch 9: Train Loss=0.000141, Val Loss=0.000119, Val RMSE=0.010952\n",
            "Epoch 10: Train Loss=0.000138, Val Loss=0.000119, Val RMSE=0.010960\n",
            "Epoch 11: Train Loss=0.000134, Val Loss=0.000119, Val RMSE=0.010955\n",
            "Epoch 12: Train Loss=0.000133, Val Loss=0.000119, Val RMSE=0.010969\n",
            "Epoch 13: Train Loss=0.000131, Val Loss=0.000119, Val RMSE=0.010951\n",
            "Epoch 14: Train Loss=0.000129, Val Loss=0.000119, Val RMSE=0.010956\n",
            "Epoch 15: Train Loss=0.000128, Val Loss=0.000119, Val RMSE=0.010946\n",
            "Epoch 16: Train Loss=0.000127, Val Loss=0.000119, Val RMSE=0.010964\n",
            "Epoch 17: Train Loss=0.000126, Val Loss=0.000119, Val RMSE=0.010959\n",
            "Epoch 18: Train Loss=0.000125, Val Loss=0.000119, Val RMSE=0.010954\n",
            "Epoch 19: Train Loss=0.000124, Val Loss=0.000119, Val RMSE=0.010955\n",
            "Epoch 20: Train Loss=0.000124, Val Loss=0.000119, Val RMSE=0.010972\n",
            "Epoch 21: Train Loss=0.000123, Val Loss=0.000119, Val RMSE=0.010945\n",
            "Epoch 22: Train Loss=0.000123, Val Loss=0.000119, Val RMSE=0.010946\n",
            "Epoch 23: Train Loss=0.000122, Val Loss=0.000119, Val RMSE=0.010947\n",
            "Epoch 24: Train Loss=0.000123, Val Loss=0.000118, Val RMSE=0.010943\n",
            "Epoch 25: Train Loss=0.000122, Val Loss=0.000118, Val RMSE=0.010938\n",
            "Evaluation metrics on denormalized data:\n",
            "Directional Accuracy: 0.509069\n",
            "Hit Ratio: 0.509069\n",
            "Sharpe Ratio: 0.011463\n",
            "RMSE: 0.006480\n",
            "Final metrics for XRP/USDT with RFE_LightGBM: {'Directional Accuracy': np.float64(0.5090690690690691), 'Hit Ratio': np.float64(0.5090690690690691), 'Sharpe Ratio': np.float64(0.01146272453221702), 'RMSE': np.float64(0.006479675798401882)}\n",
            "\n",
            "Method: LassoCV, selected features count: 2\n",
            "Training BiLSTM on XRP/USDT with features from LassoCV...\n",
            "Epoch 1: Train Loss=0.000218, Val Loss=0.000114, Val RMSE=0.010714\n",
            "Epoch 2: Train Loss=0.000151, Val Loss=0.000114, Val RMSE=0.010715\n",
            "Epoch 3: Train Loss=0.000138, Val Loss=0.000114, Val RMSE=0.010715\n",
            "Epoch 4: Train Loss=0.000133, Val Loss=0.000114, Val RMSE=0.010718\n",
            "Epoch 5: Train Loss=0.000130, Val Loss=0.000114, Val RMSE=0.010714\n",
            "Epoch 6: Train Loss=0.000129, Val Loss=0.000114, Val RMSE=0.010715\n",
            "Epoch 7: Train Loss=0.000127, Val Loss=0.000114, Val RMSE=0.010716\n",
            "Epoch 8: Train Loss=0.000127, Val Loss=0.000114, Val RMSE=0.010715\n",
            "Epoch 9: Train Loss=0.000127, Val Loss=0.000114, Val RMSE=0.010715\n",
            "Epoch 10: Train Loss=0.000126, Val Loss=0.000114, Val RMSE=0.010715\n",
            "Epoch 11: Train Loss=0.000126, Val Loss=0.000114, Val RMSE=0.010712\n",
            "Epoch 12: Train Loss=0.000126, Val Loss=0.000114, Val RMSE=0.010711\n",
            "Epoch 13: Train Loss=0.000126, Val Loss=0.000114, Val RMSE=0.010712\n",
            "Epoch 14: Train Loss=0.000125, Val Loss=0.000114, Val RMSE=0.010713\n",
            "Epoch 15: Train Loss=0.000125, Val Loss=0.000114, Val RMSE=0.010712\n",
            "Epoch 16: Train Loss=0.000125, Val Loss=0.000114, Val RMSE=0.010712\n",
            "Epoch 17: Train Loss=0.000125, Val Loss=0.000114, Val RMSE=0.010712\n",
            "Epoch 18: Train Loss=0.000125, Val Loss=0.000114, Val RMSE=0.010712\n",
            "Epoch 19: Train Loss=0.000125, Val Loss=0.000114, Val RMSE=0.010711\n",
            "Epoch 20: Train Loss=0.000125, Val Loss=0.000114, Val RMSE=0.010712\n",
            "Epoch 21: Train Loss=0.000125, Val Loss=0.000114, Val RMSE=0.010713\n",
            "Epoch 22: Train Loss=0.000125, Val Loss=0.000114, Val RMSE=0.010713\n",
            "Early stopping triggered\n",
            "Evaluation metrics on denormalized data:\n",
            "Directional Accuracy: 0.492917\n",
            "Hit Ratio: 0.492917\n",
            "Sharpe Ratio: 0.000982\n",
            "RMSE: 0.006036\n",
            "Final metrics for XRP/USDT with LassoCV: {'Directional Accuracy': np.float64(0.4929171668667467), 'Hit Ratio': np.float64(0.4929171668667467), 'Sharpe Ratio': np.float64(0.000982201765734869), 'RMSE': np.float64(0.006035843711532247)}\n",
            "\n",
            "=== Processing TRX/USDT ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-27-212b939d4a93>:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['target'] = df[target_col].shift(-1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Method: LightGBM_Importance, selected features count: 16\n",
            "Training BiLSTM on TRX/USDT with features from LightGBM_Importance...\n",
            "Epoch 1: Train Loss=0.000430, Val Loss=0.000094, Val RMSE=0.009751\n",
            "Epoch 2: Train Loss=0.000229, Val Loss=0.000089, Val RMSE=0.009495\n",
            "Epoch 3: Train Loss=0.000174, Val Loss=0.000089, Val RMSE=0.009471\n",
            "Epoch 4: Train Loss=0.000144, Val Loss=0.000088, Val RMSE=0.009450\n",
            "Epoch 5: Train Loss=0.000128, Val Loss=0.000089, Val RMSE=0.009463\n",
            "Epoch 6: Train Loss=0.000118, Val Loss=0.000088, Val RMSE=0.009436\n",
            "Epoch 7: Train Loss=0.000112, Val Loss=0.000089, Val RMSE=0.009463\n",
            "Epoch 8: Train Loss=0.000108, Val Loss=0.000088, Val RMSE=0.009434\n",
            "Epoch 9: Train Loss=0.000103, Val Loss=0.000089, Val RMSE=0.009462\n",
            "Epoch 10: Train Loss=0.000101, Val Loss=0.000088, Val RMSE=0.009447\n",
            "Epoch 11: Train Loss=0.000099, Val Loss=0.000088, Val RMSE=0.009443\n",
            "Epoch 12: Train Loss=0.000097, Val Loss=0.000088, Val RMSE=0.009432\n",
            "Epoch 13: Train Loss=0.000096, Val Loss=0.000088, Val RMSE=0.009441\n",
            "Epoch 14: Train Loss=0.000095, Val Loss=0.000088, Val RMSE=0.009450\n",
            "Epoch 15: Train Loss=0.000093, Val Loss=0.000088, Val RMSE=0.009448\n",
            "Epoch 16: Train Loss=0.000093, Val Loss=0.000089, Val RMSE=0.009471\n",
            "Epoch 17: Train Loss=0.000092, Val Loss=0.000088, Val RMSE=0.009455\n",
            "Epoch 18: Train Loss=0.000092, Val Loss=0.000089, Val RMSE=0.009470\n",
            "Early stopping triggered\n",
            "Evaluation metrics on denormalized data:\n",
            "Directional Accuracy: 0.502823\n",
            "Hit Ratio: 0.502823\n",
            "Sharpe Ratio: 0.005346\n",
            "RMSE: 0.000561\n",
            "Final metrics for TRX/USDT with LightGBM_Importance: {'Directional Accuracy': np.float64(0.5028228228228229), 'Hit Ratio': np.float64(0.5028228228228229), 'Sharpe Ratio': np.float64(0.005345726351958688), 'RMSE': np.float64(0.0005609144708641869)}\n",
            "\n",
            "Method: RFE_LightGBM, selected features count: 11\n",
            "Training BiLSTM on TRX/USDT with features from RFE_LightGBM...\n",
            "Epoch 1: Train Loss=0.001048, Val Loss=0.000100, Val RMSE=0.010080\n",
            "Epoch 2: Train Loss=0.000263, Val Loss=0.000093, Val RMSE=0.009686\n",
            "Epoch 3: Train Loss=0.000209, Val Loss=0.000092, Val RMSE=0.009663\n",
            "Epoch 4: Train Loss=0.000179, Val Loss=0.000091, Val RMSE=0.009585\n",
            "Epoch 5: Train Loss=0.000156, Val Loss=0.000090, Val RMSE=0.009552\n",
            "Epoch 6: Train Loss=0.000140, Val Loss=0.000090, Val RMSE=0.009548\n",
            "Epoch 7: Train Loss=0.000129, Val Loss=0.000090, Val RMSE=0.009530\n",
            "Epoch 8: Train Loss=0.000121, Val Loss=0.000090, Val RMSE=0.009517\n",
            "Epoch 9: Train Loss=0.000115, Val Loss=0.000090, Val RMSE=0.009553\n",
            "Epoch 10: Train Loss=0.000111, Val Loss=0.000090, Val RMSE=0.009522\n",
            "Epoch 11: Train Loss=0.000107, Val Loss=0.000089, Val RMSE=0.009508\n",
            "Epoch 12: Train Loss=0.000104, Val Loss=0.000089, Val RMSE=0.009501\n",
            "Epoch 13: Train Loss=0.000102, Val Loss=0.000090, Val RMSE=0.009514\n",
            "Epoch 14: Train Loss=0.000100, Val Loss=0.000089, Val RMSE=0.009501\n",
            "Epoch 15: Train Loss=0.000099, Val Loss=0.000089, Val RMSE=0.009506\n",
            "Epoch 16: Train Loss=0.000098, Val Loss=0.000089, Val RMSE=0.009510\n",
            "Epoch 17: Train Loss=0.000096, Val Loss=0.000089, Val RMSE=0.009499\n",
            "Epoch 18: Train Loss=0.000095, Val Loss=0.000089, Val RMSE=0.009503\n",
            "Epoch 19: Train Loss=0.000094, Val Loss=0.000089, Val RMSE=0.009505\n",
            "Epoch 20: Train Loss=0.000093, Val Loss=0.000089, Val RMSE=0.009502\n",
            "Epoch 21: Train Loss=0.000093, Val Loss=0.000089, Val RMSE=0.009498\n",
            "Epoch 22: Train Loss=0.000092, Val Loss=0.000089, Val RMSE=0.009494\n",
            "Epoch 23: Train Loss=0.000092, Val Loss=0.000089, Val RMSE=0.009498\n",
            "Epoch 24: Train Loss=0.000091, Val Loss=0.000089, Val RMSE=0.009484\n",
            "Epoch 25: Train Loss=0.000090, Val Loss=0.000089, Val RMSE=0.009487\n",
            "Evaluation metrics on denormalized data:\n",
            "Directional Accuracy: 0.510030\n",
            "Hit Ratio: 0.510030\n",
            "Sharpe Ratio: 0.005304\n",
            "RMSE: 0.000574\n",
            "Final metrics for TRX/USDT with RFE_LightGBM: {'Directional Accuracy': np.float64(0.51003003003003), 'Hit Ratio': np.float64(0.51003003003003), 'Sharpe Ratio': np.float64(0.0053038481872153586), 'RMSE': np.float64(0.0005742725164565622)}\n",
            "\n",
            "Method: LassoCV, selected features count: 2\n",
            "Training BiLSTM on TRX/USDT with features from LassoCV...\n",
            "Epoch 1: Train Loss=0.000326, Val Loss=0.000091, Val RMSE=0.009602\n",
            "Epoch 2: Train Loss=0.000170, Val Loss=0.000092, Val RMSE=0.009614\n",
            "Epoch 3: Train Loss=0.000134, Val Loss=0.000092, Val RMSE=0.009617\n",
            "Epoch 4: Train Loss=0.000118, Val Loss=0.000093, Val RMSE=0.009672\n",
            "Epoch 5: Train Loss=0.000110, Val Loss=0.000092, Val RMSE=0.009620\n",
            "Epoch 6: Train Loss=0.000105, Val Loss=0.000092, Val RMSE=0.009617\n",
            "Epoch 7: Train Loss=0.000103, Val Loss=0.000092, Val RMSE=0.009629\n",
            "Epoch 8: Train Loss=0.000100, Val Loss=0.000092, Val RMSE=0.009622\n",
            "Epoch 9: Train Loss=0.000099, Val Loss=0.000092, Val RMSE=0.009621\n",
            "Epoch 10: Train Loss=0.000098, Val Loss=0.000092, Val RMSE=0.009607\n",
            "Epoch 11: Train Loss=0.000096, Val Loss=0.000092, Val RMSE=0.009609\n",
            "Early stopping triggered\n",
            "Evaluation metrics on denormalized data:\n",
            "Directional Accuracy: 0.499160\n",
            "Hit Ratio: 0.499160\n",
            "Sharpe Ratio: 0.006373\n",
            "RMSE: 0.000553\n",
            "Final metrics for TRX/USDT with LassoCV: {'Directional Accuracy': np.float64(0.4991596638655462), 'Hit Ratio': np.float64(0.4991596638655462), 'Sharpe Ratio': np.float64(0.006373193905108366), 'RMSE': np.float64(0.0005533470134553007)}\n",
            "\n",
            "=== Processing BTC/USDT ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-27-212b939d4a93>:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['target'] = df[target_col].shift(-1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.0012118049515905671, tolerance: 0.0001912103521750576\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.00510590856051496, tolerance: 0.0001912103521750576\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.0004105221000392234, tolerance: 0.0001717423545617122\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.0005013893753667009, tolerance: 0.0001717423545617122\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.0002846141072010422, tolerance: 0.00019488226586628744\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.0007336717271362314, tolerance: 0.00019488226586628744\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.0020401718350830933, tolerance: 0.00019488226586628744\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.0006701373705038094, tolerance: 0.00021661494546773225\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.0007054981603884514, tolerance: 0.00021661494546773225\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.0009723207699696701, tolerance: 0.00021661494546773225\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.00271421669409877, tolerance: 0.00021661494546773225\n",
            "  model = cd_fast.enet_coordinate_descent_gram(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Method: LightGBM_Importance, selected features count: 15\n",
            "Training BiLSTM on BTC/USDT with features from LightGBM_Importance...\n",
            "Epoch 1: Train Loss=0.000268, Val Loss=0.000056, Val RMSE=0.007516\n",
            "Epoch 2: Train Loss=0.000127, Val Loss=0.000053, Val RMSE=0.007319\n",
            "Epoch 3: Train Loss=0.000091, Val Loss=0.000053, Val RMSE=0.007283\n",
            "Epoch 4: Train Loss=0.000073, Val Loss=0.000053, Val RMSE=0.007299\n",
            "Epoch 5: Train Loss=0.000065, Val Loss=0.000052, Val RMSE=0.007265\n",
            "Epoch 6: Train Loss=0.000060, Val Loss=0.000052, Val RMSE=0.007271\n",
            "Epoch 7: Train Loss=0.000057, Val Loss=0.000052, Val RMSE=0.007271\n",
            "Epoch 8: Train Loss=0.000055, Val Loss=0.000052, Val RMSE=0.007263\n",
            "Epoch 9: Train Loss=0.000054, Val Loss=0.000052, Val RMSE=0.007270\n",
            "Epoch 10: Train Loss=0.000053, Val Loss=0.000052, Val RMSE=0.007268\n",
            "Epoch 11: Train Loss=0.000052, Val Loss=0.000052, Val RMSE=0.007261\n",
            "Epoch 12: Train Loss=0.000051, Val Loss=0.000052, Val RMSE=0.007256\n",
            "Epoch 13: Train Loss=0.000050, Val Loss=0.000052, Val RMSE=0.007263\n",
            "Epoch 14: Train Loss=0.000050, Val Loss=0.000052, Val RMSE=0.007265\n",
            "Epoch 15: Train Loss=0.000050, Val Loss=0.000052, Val RMSE=0.007258\n",
            "Epoch 16: Train Loss=0.000049, Val Loss=0.000052, Val RMSE=0.007255\n",
            "Epoch 17: Train Loss=0.000049, Val Loss=0.000052, Val RMSE=0.007258\n",
            "Epoch 18: Train Loss=0.000049, Val Loss=0.000052, Val RMSE=0.007259\n",
            "Epoch 19: Train Loss=0.000049, Val Loss=0.000052, Val RMSE=0.007258\n",
            "Epoch 20: Train Loss=0.000049, Val Loss=0.000052, Val RMSE=0.007256\n",
            "Epoch 21: Train Loss=0.000048, Val Loss=0.000052, Val RMSE=0.007258\n",
            "Epoch 22: Train Loss=0.000048, Val Loss=0.000052, Val RMSE=0.007254\n",
            "Epoch 23: Train Loss=0.000048, Val Loss=0.000052, Val RMSE=0.007254\n",
            "Epoch 24: Train Loss=0.000048, Val Loss=0.000052, Val RMSE=0.007255\n",
            "Epoch 25: Train Loss=0.000048, Val Loss=0.000052, Val RMSE=0.007256\n",
            "Evaluation metrics on denormalized data:\n",
            "Directional Accuracy: 0.504264\n",
            "Hit Ratio: 0.504264\n",
            "Sharpe Ratio: 0.004269\n",
            "RMSE: 181.039206\n",
            "Final metrics for BTC/USDT with LightGBM_Importance: {'Directional Accuracy': np.float64(0.5042642642642643), 'Hit Ratio': np.float64(0.5042642642642643), 'Sharpe Ratio': np.float64(0.004269254294057116), 'RMSE': np.float64(181.0392060269376)}\n",
            "\n",
            "Method: RFE_LightGBM, selected features count: 11\n",
            "Training BiLSTM on BTC/USDT with features from RFE_LightGBM...\n",
            "Epoch 1: Train Loss=0.000437, Val Loss=0.000051, Val RMSE=0.007143\n",
            "Epoch 2: Train Loss=0.000170, Val Loss=0.000049, Val RMSE=0.007013\n",
            "Epoch 3: Train Loss=0.000127, Val Loss=0.000048, Val RMSE=0.006973\n",
            "Epoch 4: Train Loss=0.000101, Val Loss=0.000048, Val RMSE=0.006971\n",
            "Epoch 5: Train Loss=0.000086, Val Loss=0.000048, Val RMSE=0.006949\n",
            "Epoch 6: Train Loss=0.000077, Val Loss=0.000048, Val RMSE=0.006931\n",
            "Epoch 7: Train Loss=0.000068, Val Loss=0.000048, Val RMSE=0.006934\n",
            "Epoch 8: Train Loss=0.000065, Val Loss=0.000048, Val RMSE=0.006924\n",
            "Epoch 9: Train Loss=0.000061, Val Loss=0.000048, Val RMSE=0.006925\n",
            "Epoch 10: Train Loss=0.000060, Val Loss=0.000048, Val RMSE=0.006928\n",
            "Epoch 11: Train Loss=0.000057, Val Loss=0.000048, Val RMSE=0.006922\n",
            "Epoch 12: Train Loss=0.000056, Val Loss=0.000048, Val RMSE=0.006921\n",
            "Epoch 13: Train Loss=0.000055, Val Loss=0.000048, Val RMSE=0.006926\n",
            "Epoch 14: Train Loss=0.000054, Val Loss=0.000048, Val RMSE=0.006925\n",
            "Epoch 15: Train Loss=0.000053, Val Loss=0.000048, Val RMSE=0.006934\n",
            "Epoch 16: Train Loss=0.000053, Val Loss=0.000048, Val RMSE=0.006926\n",
            "Epoch 17: Train Loss=0.000052, Val Loss=0.000048, Val RMSE=0.006941\n",
            "Epoch 18: Train Loss=0.000052, Val Loss=0.000048, Val RMSE=0.006919\n",
            "Epoch 19: Train Loss=0.000052, Val Loss=0.000048, Val RMSE=0.006920\n",
            "Epoch 20: Train Loss=0.000051, Val Loss=0.000048, Val RMSE=0.006921\n",
            "Epoch 21: Train Loss=0.000051, Val Loss=0.000048, Val RMSE=0.006919\n",
            "Epoch 22: Train Loss=0.000050, Val Loss=0.000048, Val RMSE=0.006920\n",
            "Epoch 23: Train Loss=0.000050, Val Loss=0.000048, Val RMSE=0.006918\n",
            "Epoch 24: Train Loss=0.000050, Val Loss=0.000047, Val RMSE=0.006914\n",
            "Epoch 25: Train Loss=0.000050, Val Loss=0.000048, Val RMSE=0.006916\n",
            "Evaluation metrics on denormalized data:\n",
            "Directional Accuracy: 0.504024\n",
            "Hit Ratio: 0.504024\n",
            "Sharpe Ratio: 0.000158\n",
            "RMSE: 183.046878\n",
            "Final metrics for BTC/USDT with RFE_LightGBM: {'Directional Accuracy': np.float64(0.504024024024024), 'Hit Ratio': np.float64(0.504024024024024), 'Sharpe Ratio': np.float64(0.0001579167785303936), 'RMSE': np.float64(183.0468784268626)}\n",
            "\n",
            "Method: LassoCV, selected features count: 2\n",
            "Training BiLSTM on BTC/USDT with features from LassoCV...\n",
            "Epoch 1: Train Loss=0.000317, Val Loss=0.000044, Val RMSE=0.006619\n",
            "Epoch 2: Train Loss=0.000141, Val Loss=0.000043, Val RMSE=0.006609\n",
            "Epoch 3: Train Loss=0.000096, Val Loss=0.000044, Val RMSE=0.006625\n",
            "Epoch 4: Train Loss=0.000077, Val Loss=0.000044, Val RMSE=0.006619\n",
            "Epoch 5: Train Loss=0.000069, Val Loss=0.000043, Val RMSE=0.006600\n",
            "Epoch 6: Train Loss=0.000064, Val Loss=0.000043, Val RMSE=0.006603\n",
            "Epoch 7: Train Loss=0.000062, Val Loss=0.000043, Val RMSE=0.006606\n",
            "Epoch 8: Train Loss=0.000060, Val Loss=0.000044, Val RMSE=0.006643\n",
            "Epoch 9: Train Loss=0.000058, Val Loss=0.000043, Val RMSE=0.006601\n",
            "Epoch 10: Train Loss=0.000057, Val Loss=0.000043, Val RMSE=0.006610\n",
            "Epoch 11: Train Loss=0.000056, Val Loss=0.000043, Val RMSE=0.006612\n",
            "Epoch 12: Train Loss=0.000055, Val Loss=0.000044, Val RMSE=0.006621\n",
            "Epoch 13: Train Loss=0.000055, Val Loss=0.000043, Val RMSE=0.006605\n",
            "Epoch 14: Train Loss=0.000054, Val Loss=0.000043, Val RMSE=0.006599\n",
            "Epoch 15: Train Loss=0.000054, Val Loss=0.000043, Val RMSE=0.006611\n",
            "Early stopping triggered\n",
            "Evaluation metrics on denormalized data:\n",
            "Directional Accuracy: 0.489316\n",
            "Hit Ratio: 0.489316\n",
            "Sharpe Ratio: 0.003768\n",
            "RMSE: 177.383126\n",
            "Final metrics for BTC/USDT with LassoCV: {'Directional Accuracy': np.float64(0.48931572629051623), 'Hit Ratio': np.float64(0.48931572629051623), 'Sharpe Ratio': np.float64(0.0037679180157870443), 'RMSE': np.float64(177.38312553633)}\n",
            "\n",
            "=== Processing SOL/USDT ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-27-212b939d4a93>:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['target'] = df[target_col].shift(-1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Method: LightGBM_Importance, selected features count: 15\n",
            "Training BiLSTM on SOL/USDT with features from LightGBM_Importance...\n",
            "Epoch 1: Train Loss=0.000591, Val Loss=0.000192, Val RMSE=0.013887\n",
            "Epoch 2: Train Loss=0.000392, Val Loss=0.000188, Val RMSE=0.013720\n",
            "Epoch 3: Train Loss=0.000317, Val Loss=0.000188, Val RMSE=0.013713\n",
            "Epoch 4: Train Loss=0.000287, Val Loss=0.000186, Val RMSE=0.013644\n",
            "Epoch 5: Train Loss=0.000263, Val Loss=0.000185, Val RMSE=0.013623\n",
            "Epoch 6: Train Loss=0.000246, Val Loss=0.000185, Val RMSE=0.013633\n",
            "Epoch 7: Train Loss=0.000237, Val Loss=0.000186, Val RMSE=0.013653\n",
            "Epoch 8: Train Loss=0.000228, Val Loss=0.000186, Val RMSE=0.013642\n",
            "Epoch 9: Train Loss=0.000223, Val Loss=0.000185, Val RMSE=0.013623\n",
            "Epoch 10: Train Loss=0.000221, Val Loss=0.000185, Val RMSE=0.013620\n",
            "Epoch 11: Train Loss=0.000216, Val Loss=0.000185, Val RMSE=0.013623\n",
            "Epoch 12: Train Loss=0.000214, Val Loss=0.000185, Val RMSE=0.013615\n",
            "Epoch 13: Train Loss=0.000212, Val Loss=0.000184, Val RMSE=0.013600\n",
            "Epoch 14: Train Loss=0.000209, Val Loss=0.000185, Val RMSE=0.013613\n",
            "Epoch 15: Train Loss=0.000208, Val Loss=0.000185, Val RMSE=0.013616\n",
            "Epoch 16: Train Loss=0.000207, Val Loss=0.000184, Val RMSE=0.013602\n",
            "Epoch 17: Train Loss=0.000206, Val Loss=0.000185, Val RMSE=0.013615\n",
            "Epoch 18: Train Loss=0.000205, Val Loss=0.000185, Val RMSE=0.013626\n",
            "Epoch 19: Train Loss=0.000204, Val Loss=0.000185, Val RMSE=0.013612\n",
            "Epoch 20: Train Loss=0.000203, Val Loss=0.000185, Val RMSE=0.013611\n",
            "Epoch 21: Train Loss=0.000202, Val Loss=0.000185, Val RMSE=0.013608\n",
            "Epoch 22: Train Loss=0.000201, Val Loss=0.000185, Val RMSE=0.013604\n",
            "Epoch 23: Train Loss=0.000201, Val Loss=0.000185, Val RMSE=0.013604\n",
            "Early stopping triggered\n",
            "Evaluation metrics on denormalized data:\n",
            "Directional Accuracy: 0.503379\n",
            "Hit Ratio: 0.503379\n",
            "Sharpe Ratio: 0.009603\n",
            "RMSE: 0.966709\n",
            "Final metrics for SOL/USDT with LightGBM_Importance: {'Directional Accuracy': np.float64(0.503379465722562), 'Hit Ratio': np.float64(0.503379465722562), 'Sharpe Ratio': np.float64(0.009603282034032564), 'RMSE': np.float64(0.9667090552823969)}\n",
            "\n",
            "Method: RFE_LightGBM, selected features count: 11\n",
            "Training BiLSTM on SOL/USDT with features from RFE_LightGBM...\n",
            "Epoch 1: Train Loss=0.000574, Val Loss=0.000191, Val RMSE=0.013802\n",
            "Epoch 2: Train Loss=0.000354, Val Loss=0.000188, Val RMSE=0.013708\n",
            "Epoch 3: Train Loss=0.000296, Val Loss=0.000187, Val RMSE=0.013663\n",
            "Epoch 4: Train Loss=0.000264, Val Loss=0.000187, Val RMSE=0.013677\n",
            "Epoch 5: Train Loss=0.000242, Val Loss=0.000186, Val RMSE=0.013652\n",
            "Epoch 6: Train Loss=0.000231, Val Loss=0.000187, Val RMSE=0.013680\n",
            "Epoch 7: Train Loss=0.000221, Val Loss=0.000186, Val RMSE=0.013653\n",
            "Epoch 8: Train Loss=0.000218, Val Loss=0.000186, Val RMSE=0.013650\n",
            "Epoch 9: Train Loss=0.000212, Val Loss=0.000187, Val RMSE=0.013661\n",
            "Epoch 10: Train Loss=0.000209, Val Loss=0.000186, Val RMSE=0.013648\n",
            "Epoch 11: Train Loss=0.000207, Val Loss=0.000186, Val RMSE=0.013650\n",
            "Epoch 12: Train Loss=0.000204, Val Loss=0.000186, Val RMSE=0.013644\n",
            "Epoch 13: Train Loss=0.000203, Val Loss=0.000186, Val RMSE=0.013648\n",
            "Epoch 14: Train Loss=0.000202, Val Loss=0.000186, Val RMSE=0.013643\n",
            "Epoch 15: Train Loss=0.000199, Val Loss=0.000186, Val RMSE=0.013644\n",
            "Epoch 16: Train Loss=0.000199, Val Loss=0.000186, Val RMSE=0.013650\n",
            "Epoch 17: Train Loss=0.000198, Val Loss=0.000186, Val RMSE=0.013648\n",
            "Epoch 18: Train Loss=0.000198, Val Loss=0.000186, Val RMSE=0.013648\n",
            "Epoch 19: Train Loss=0.000197, Val Loss=0.000186, Val RMSE=0.013651\n",
            "Epoch 20: Train Loss=0.000197, Val Loss=0.000186, Val RMSE=0.013643\n",
            "Epoch 21: Train Loss=0.000197, Val Loss=0.000186, Val RMSE=0.013644\n",
            "Epoch 22: Train Loss=0.000196, Val Loss=0.000186, Val RMSE=0.013646\n",
            "Epoch 23: Train Loss=0.000196, Val Loss=0.000186, Val RMSE=0.013646\n",
            "Epoch 24: Train Loss=0.000195, Val Loss=0.000186, Val RMSE=0.013650\n",
            "Epoch 25: Train Loss=0.000195, Val Loss=0.000186, Val RMSE=0.013651\n",
            "Evaluation metrics on denormalized data:\n",
            "Directional Accuracy: 0.505954\n",
            "Hit Ratio: 0.505954\n",
            "Sharpe Ratio: 0.008515\n",
            "RMSE: 0.998674\n",
            "Final metrics for SOL/USDT with RFE_LightGBM: {'Directional Accuracy': np.float64(0.5059542967492758), 'Hit Ratio': np.float64(0.5059542967492758), 'Sharpe Ratio': np.float64(0.008514867260712959), 'RMSE': np.float64(0.9986741485522865)}\n",
            "\n",
            "Method: LassoCV, selected features count: 2\n",
            "Training BiLSTM on SOL/USDT with features from LassoCV...\n",
            "Epoch 1: Train Loss=0.000327, Val Loss=0.000187, Val RMSE=0.013657\n",
            "Epoch 2: Train Loss=0.000243, Val Loss=0.000188, Val RMSE=0.013673\n",
            "Epoch 3: Train Loss=0.000220, Val Loss=0.000187, Val RMSE=0.013657\n",
            "Epoch 4: Train Loss=0.000211, Val Loss=0.000187, Val RMSE=0.013666\n",
            "Epoch 5: Train Loss=0.000205, Val Loss=0.000188, Val RMSE=0.013686\n",
            "Epoch 6: Train Loss=0.000201, Val Loss=0.000187, Val RMSE=0.013664\n",
            "Epoch 7: Train Loss=0.000199, Val Loss=0.000187, Val RMSE=0.013666\n",
            "Epoch 8: Train Loss=0.000197, Val Loss=0.000187, Val RMSE=0.013657\n",
            "Epoch 9: Train Loss=0.000197, Val Loss=0.000187, Val RMSE=0.013659\n",
            "Epoch 10: Train Loss=0.000196, Val Loss=0.000187, Val RMSE=0.013666\n",
            "Epoch 11: Train Loss=0.000195, Val Loss=0.000187, Val RMSE=0.013664\n",
            "Epoch 12: Train Loss=0.000195, Val Loss=0.000187, Val RMSE=0.013660\n",
            "Epoch 13: Train Loss=0.000194, Val Loss=0.000188, Val RMSE=0.013669\n",
            "Epoch 14: Train Loss=0.000193, Val Loss=0.000187, Val RMSE=0.013659\n",
            "Epoch 15: Train Loss=0.000193, Val Loss=0.000187, Val RMSE=0.013657\n",
            "Epoch 16: Train Loss=0.000193, Val Loss=0.000187, Val RMSE=0.013655\n",
            "Epoch 17: Train Loss=0.000192, Val Loss=0.000187, Val RMSE=0.013659\n",
            "Epoch 18: Train Loss=0.000193, Val Loss=0.000187, Val RMSE=0.013655\n",
            "Epoch 19: Train Loss=0.000193, Val Loss=0.000187, Val RMSE=0.013655\n",
            "Epoch 20: Train Loss=0.000192, Val Loss=0.000187, Val RMSE=0.013657\n",
            "Epoch 21: Train Loss=0.000192, Val Loss=0.000187, Val RMSE=0.013655\n",
            "Epoch 22: Train Loss=0.000192, Val Loss=0.000187, Val RMSE=0.013655\n",
            "Epoch 23: Train Loss=0.000192, Val Loss=0.000187, Val RMSE=0.013656\n",
            "Epoch 24: Train Loss=0.000191, Val Loss=0.000187, Val RMSE=0.013654\n",
            "Epoch 25: Train Loss=0.000192, Val Loss=0.000187, Val RMSE=0.013655\n",
            "Evaluation metrics on denormalized data:\n",
            "Directional Accuracy: 0.493406\n",
            "Hit Ratio: 0.493406\n",
            "Sharpe Ratio: 0.001996\n",
            "RMSE: 1.033695\n",
            "Final metrics for SOL/USDT with LassoCV: {'Directional Accuracy': np.float64(0.4934062399485365), 'Hit Ratio': np.float64(0.4934062399485365), 'Sharpe Ratio': np.float64(0.0019962455078599583), 'RMSE': np.float64(1.0336952730508735)}\n",
            "\n",
            "=== Processing ETH/USDT ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-27-212b939d4a93>:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['target'] = df[target_col].shift(-1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Method: LightGBM_Importance, selected features count: 15\n",
            "Training BiLSTM on ETH/USDT with features from LightGBM_Importance...\n",
            "Epoch 1: Train Loss=0.000362, Val Loss=0.000081, Val RMSE=0.008916\n",
            "Epoch 2: Train Loss=0.000195, Val Loss=0.000079, Val RMSE=0.008777\n",
            "Epoch 3: Train Loss=0.000147, Val Loss=0.000079, Val RMSE=0.008787\n",
            "Epoch 4: Train Loss=0.000122, Val Loss=0.000078, Val RMSE=0.008751\n",
            "Epoch 5: Train Loss=0.000106, Val Loss=0.000078, Val RMSE=0.008723\n",
            "Epoch 6: Train Loss=0.000098, Val Loss=0.000078, Val RMSE=0.008737\n",
            "Epoch 7: Train Loss=0.000093, Val Loss=0.000078, Val RMSE=0.008711\n",
            "Epoch 8: Train Loss=0.000089, Val Loss=0.000078, Val RMSE=0.008721\n",
            "Epoch 9: Train Loss=0.000085, Val Loss=0.000078, Val RMSE=0.008710\n",
            "Epoch 10: Train Loss=0.000084, Val Loss=0.000078, Val RMSE=0.008714\n",
            "Epoch 11: Train Loss=0.000083, Val Loss=0.000078, Val RMSE=0.008705\n",
            "Epoch 12: Train Loss=0.000082, Val Loss=0.000078, Val RMSE=0.008714\n",
            "Epoch 13: Train Loss=0.000081, Val Loss=0.000078, Val RMSE=0.008701\n",
            "Epoch 14: Train Loss=0.000081, Val Loss=0.000078, Val RMSE=0.008703\n",
            "Epoch 15: Train Loss=0.000080, Val Loss=0.000078, Val RMSE=0.008698\n",
            "Epoch 16: Train Loss=0.000080, Val Loss=0.000078, Val RMSE=0.008699\n",
            "Epoch 17: Train Loss=0.000079, Val Loss=0.000078, Val RMSE=0.008699\n",
            "Epoch 18: Train Loss=0.000079, Val Loss=0.000078, Val RMSE=0.008701\n",
            "Epoch 19: Train Loss=0.000079, Val Loss=0.000078, Val RMSE=0.008701\n",
            "Epoch 20: Train Loss=0.000079, Val Loss=0.000078, Val RMSE=0.008700\n",
            "Epoch 21: Train Loss=0.000078, Val Loss=0.000078, Val RMSE=0.008706\n",
            "Epoch 22: Train Loss=0.000078, Val Loss=0.000078, Val RMSE=0.008706\n",
            "Epoch 23: Train Loss=0.000078, Val Loss=0.000078, Val RMSE=0.008703\n",
            "Epoch 24: Train Loss=0.000078, Val Loss=0.000078, Val RMSE=0.008708\n",
            "Epoch 25: Train Loss=0.000078, Val Loss=0.000078, Val RMSE=0.008703\n",
            "Evaluation metrics on denormalized data:\n",
            "Directional Accuracy: 0.510030\n",
            "Hit Ratio: 0.510030\n",
            "Sharpe Ratio: 0.003481\n",
            "RMSE: 10.680271\n",
            "Final metrics for ETH/USDT with LightGBM_Importance: {'Directional Accuracy': np.float64(0.51003003003003), 'Hit Ratio': np.float64(0.51003003003003), 'Sharpe Ratio': np.float64(0.003480783419850076), 'RMSE': np.float64(10.68027086528846)}\n",
            "\n",
            "Method: RFE_LightGBM, selected features count: 11\n",
            "Training BiLSTM on ETH/USDT with features from RFE_LightGBM...\n",
            "Epoch 1: Train Loss=0.000329, Val Loss=0.000092, Val RMSE=0.009656\n",
            "Epoch 2: Train Loss=0.000159, Val Loss=0.000091, Val RMSE=0.009580\n",
            "Epoch 3: Train Loss=0.000121, Val Loss=0.000090, Val RMSE=0.009546\n",
            "Epoch 4: Train Loss=0.000106, Val Loss=0.000090, Val RMSE=0.009533\n",
            "Epoch 5: Train Loss=0.000097, Val Loss=0.000090, Val RMSE=0.009526\n",
            "Epoch 6: Train Loss=0.000091, Val Loss=0.000090, Val RMSE=0.009529\n",
            "Epoch 7: Train Loss=0.000087, Val Loss=0.000090, Val RMSE=0.009537\n",
            "Epoch 8: Train Loss=0.000085, Val Loss=0.000090, Val RMSE=0.009526\n",
            "Epoch 9: Train Loss=0.000083, Val Loss=0.000090, Val RMSE=0.009529\n",
            "Epoch 10: Train Loss=0.000081, Val Loss=0.000090, Val RMSE=0.009535\n",
            "Epoch 11: Train Loss=0.000080, Val Loss=0.000090, Val RMSE=0.009528\n",
            "Epoch 12: Train Loss=0.000079, Val Loss=0.000090, Val RMSE=0.009532\n",
            "Epoch 13: Train Loss=0.000078, Val Loss=0.000090, Val RMSE=0.009532\n",
            "Epoch 14: Train Loss=0.000078, Val Loss=0.000090, Val RMSE=0.009533\n",
            "Epoch 15: Train Loss=0.000078, Val Loss=0.000090, Val RMSE=0.009531\n",
            "Early stopping triggered\n",
            "Evaluation metrics on denormalized data:\n",
            "Directional Accuracy: 0.515676\n",
            "Hit Ratio: 0.515676\n",
            "Sharpe Ratio: 0.005866\n",
            "RMSE: 10.567209\n",
            "Final metrics for ETH/USDT with RFE_LightGBM: {'Directional Accuracy': np.float64(0.5156756756756756), 'Hit Ratio': np.float64(0.5156756756756756), 'Sharpe Ratio': np.float64(0.00586558118712225), 'RMSE': np.float64(10.567208525644068)}\n",
            "\n",
            "Method: LassoCV, selected features count: 3\n",
            "Training BiLSTM on ETH/USDT with features from LassoCV...\n",
            "Epoch 1: Train Loss=0.000273, Val Loss=0.000075, Val RMSE=0.008625\n",
            "Epoch 2: Train Loss=0.000146, Val Loss=0.000074, Val RMSE=0.008610\n",
            "Epoch 3: Train Loss=0.000108, Val Loss=0.000075, Val RMSE=0.008618\n",
            "Epoch 4: Train Loss=0.000094, Val Loss=0.000075, Val RMSE=0.008621\n",
            "Epoch 5: Train Loss=0.000089, Val Loss=0.000075, Val RMSE=0.008620\n",
            "Epoch 6: Train Loss=0.000085, Val Loss=0.000075, Val RMSE=0.008618\n",
            "Epoch 7: Train Loss=0.000082, Val Loss=0.000075, Val RMSE=0.008618\n",
            "Epoch 8: Train Loss=0.000081, Val Loss=0.000075, Val RMSE=0.008624\n",
            "Epoch 9: Train Loss=0.000080, Val Loss=0.000075, Val RMSE=0.008618\n",
            "Epoch 10: Train Loss=0.000080, Val Loss=0.000075, Val RMSE=0.008620\n",
            "Epoch 11: Train Loss=0.000080, Val Loss=0.000075, Val RMSE=0.008614\n",
            "Epoch 12: Train Loss=0.000079, Val Loss=0.000075, Val RMSE=0.008615\n",
            "Early stopping triggered\n",
            "Evaluation metrics on denormalized data:\n",
            "Directional Accuracy: 0.491837\n",
            "Hit Ratio: 0.491837\n",
            "Sharpe Ratio: 0.002798\n",
            "RMSE: 11.318372\n",
            "Final metrics for ETH/USDT with LassoCV: {'Directional Accuracy': np.float64(0.49183673469387756), 'Hit Ratio': np.float64(0.49183673469387756), 'Sharpe Ratio': np.float64(0.0027983673702926147), 'RMSE': np.float64(11.318371936789445)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nYq31DsebiV2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Теперь собираем гибрид"
      ],
      "metadata": {
        "id": "FbMtt6WGr15o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install performer-pytorch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "xinpU_KJr4rY",
        "outputId": "ceaf7ba8-100c-4af2-e61a-a3fcc79f79ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting performer-pytorch\n",
            "  Downloading performer_pytorch-1.1.4-py3-none-any.whl.metadata (763 bytes)\n",
            "Requirement already satisfied: einops>=0.3 in /usr/local/lib/python3.11/dist-packages (from performer-pytorch) (0.8.1)\n",
            "Collecting local-attention>=1.1.1 (from performer-pytorch)\n",
            "  Downloading local_attention-1.11.1-py3-none-any.whl.metadata (907 bytes)\n",
            "Requirement already satisfied: torch>=1.6 in /usr/local/lib/python3.11/dist-packages (from performer-pytorch) (2.6.0+cu124)\n",
            "Collecting axial-positional-embedding>=0.1.0 (from performer-pytorch)\n",
            "  Downloading axial_positional_embedding-0.3.12-py3-none-any.whl.metadata (4.3 kB)\n",
            "Collecting hyper-connections>=0.1.8 (from local-attention>=1.1.1->performer-pytorch)\n",
            "  Downloading hyper_connections-0.1.15-py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.6->performer-pytorch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6->performer-pytorch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.6->performer-pytorch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6->performer-pytorch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.6->performer-pytorch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.6->performer-pytorch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.6->performer-pytorch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.6->performer-pytorch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.6->performer-pytorch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.6->performer-pytorch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.6->performer-pytorch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.6->performer-pytorch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.6->performer-pytorch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.6->performer-pytorch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6->performer-pytorch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6->performer-pytorch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6->performer-pytorch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.6->performer-pytorch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6->performer-pytorch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6->performer-pytorch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.6->performer-pytorch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.6->performer-pytorch) (3.0.2)\n",
            "Downloading performer_pytorch-1.1.4-py3-none-any.whl (13 kB)\n",
            "Downloading axial_positional_embedding-0.3.12-py3-none-any.whl (6.7 kB)\n",
            "Downloading local_attention-1.11.1-py3-none-any.whl (9.4 kB)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m110.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m95.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m63.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m110.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hyper_connections-0.1.15-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, hyper-connections, axial-positional-embedding, local-attention, performer-pytorch\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed axial-positional-embedding-0.3.12 hyper-connections-0.1.15 local-attention-1.11.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 performer-pytorch-1.1.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from performer_pytorch import Performer\n",
        "\n",
        "class BiLSTMPerformerHybrid(nn.Module):\n",
        "    def __init__(self, input_dim, lstm_hidden=64, lstm_layers=2, performer_dim=128,\n",
        "                 performer_depth=3, performer_heads=4, dropout=0.1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.bilstm = nn.LSTM(input_dim, lstm_hidden, num_layers=lstm_layers,\n",
        "                              batch_first=True, bidirectional=True, dropout=dropout)\n",
        "\n",
        "        self.project = nn.Linear(lstm_hidden * 2, performer_dim)\n",
        "\n",
        "        self.performer = Performer(\n",
        "            dim=performer_dim,\n",
        "            depth=performer_depth,\n",
        "            heads=performer_heads,\n",
        "            causal=False,\n",
        "            nb_features=256,\n",
        "            dropout=dropout\n",
        "        )\n",
        "\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.LayerNorm(performer_dim),\n",
        "            nn.Linear(performer_dim, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        lstm_out, _ = self.bilstm(x)  # (batch, seq_len, lstm_hidden*2)\n",
        "\n",
        "        proj = self.project(lstm_out)  # (batch, seq_len, performer_dim)\n",
        "\n",
        "        performer_out = self.performer(proj)  # (batch, seq_len, performer_dim)\n",
        "\n",
        "        last_hidden = performer_out[:, -1, :]  # (batch, performer_dim)\n",
        "\n",
        "        out = self.fc(last_hidden).squeeze(-1)  # (batch,)\n",
        "        return out"
      ],
      "metadata": {
        "id": "IQoa-xk-r4os"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import lightgbm as lgb\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.linear_model import LassoCV\n",
        "import torch.nn as nn\n",
        "from torch.optim import Adam\n",
        "from performer_pytorch import Performer  # pip install performer-pytorch\n",
        "\n",
        "class CryptoDataset(Dataset):\n",
        "    def __init__(self, df, feature_cols, target_col='log_return', seq_len=24):\n",
        "        self.seq_len = seq_len\n",
        "        df = df.dropna(subset=feature_cols + [target_col]).reset_index(drop=True)\n",
        "        self.scaler = StandardScaler()\n",
        "        features = df[feature_cols].values\n",
        "        self.features = self.scaler.fit_transform(features)\n",
        "        self.targets = df[target_col].values\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.targets) - self.seq_len\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x = self.features[idx:idx+self.seq_len]\n",
        "        y = self.targets[idx + self.seq_len]\n",
        "        return torch.tensor(x, dtype=torch.float32), torch.tensor(y, dtype=torch.float32)\n",
        "\n",
        "class BiLSTMModel(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim=64, num_layers=2, dropout=0.2):\n",
        "        super(BiLSTMModel, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers=num_layers,\n",
        "                            batch_first=True, bidirectional=True, dropout=dropout)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.fc = nn.Linear(hidden_dim * 2, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.lstm(x)\n",
        "        out = out[:, -1, :]\n",
        "        out = self.dropout(out)\n",
        "        out = self.fc(out)\n",
        "        return out.squeeze()\n",
        "\n",
        "class PerformerModel(nn.Module):\n",
        "    def __init__(self, input_dim, performer_dim=128, performer_depth=3, performer_heads=4, dim_head=32):\n",
        "        super(PerformerModel, self).__init__()\n",
        "        self.project = nn.Linear(input_dim, performer_dim)\n",
        "        self.performer = Performer(\n",
        "            dim=performer_dim,\n",
        "            depth=performer_depth,\n",
        "            heads=performer_heads,\n",
        "            dim_head=dim_head,\n",
        "            causal=False,\n",
        "            ff_dropout = 0.1,\n",
        "            attn_dropout = 0.1\n",
        "        )\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.LayerNorm(performer_dim),\n",
        "            nn.Linear(performer_dim, 1)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        x = self.project(x)\n",
        "        x = self.performer(x)\n",
        "        x = x[:, -1, :]\n",
        "        out = self.fc(x).squeeze(-1)\n",
        "        return out\n",
        "\n",
        "def train_model(model, train_loader, val_loader, epochs=50, lr=1e-3, device='cuda'):\n",
        "    model.to(device)\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = Adam(model.parameters(), lr=lr)\n",
        "    best_val_loss = float('inf')\n",
        "    patience = 10\n",
        "    trigger_times = 0\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        train_losses = []\n",
        "        for x_batch, y_batch in train_loader:\n",
        "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            preds = model(x_batch)\n",
        "            loss = criterion(preds, y_batch)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_losses.append(loss.item())\n",
        "\n",
        "        model.eval()\n",
        "        val_losses = []\n",
        "        val_preds, val_targets = [], []\n",
        "        with torch.no_grad():\n",
        "            for x_val, y_val in val_loader:\n",
        "                x_val, y_val = x_val.to(device), y_val.to(device)\n",
        "                preds = model(x_val)\n",
        "                loss = criterion(preds, y_val)\n",
        "                val_losses.append(loss.item())\n",
        "                val_preds.extend(preds.cpu().numpy())\n",
        "                val_targets.extend(y_val.cpu().numpy())\n",
        "\n",
        "        avg_train_loss = np.mean(train_losses)\n",
        "        avg_val_loss = np.mean(val_losses)\n",
        "        val_rmse = np.sqrt(mean_squared_error(val_targets, val_preds))\n",
        "\n",
        "        print(f\"Epoch {epoch+1}: Train Loss={avg_train_loss:.6f}, Val Loss={avg_val_loss:.6f}, Val RMSE={val_rmse:.6f}\")\n",
        "\n",
        "        if avg_val_loss < best_val_loss:\n",
        "            best_val_loss = avg_val_loss\n",
        "            trigger_times = 0\n",
        "            if isinstance(model, BiLSTMModel):\n",
        "                torch.save(model.state_dict(), f'best_bilstm.pth')\n",
        "            else:\n",
        "                torch.save(model.state_dict(), f'best_performer.pth')\n",
        "        else:\n",
        "            trigger_times += 1\n",
        "            if trigger_times >= patience:\n",
        "                print(\"Early stopping triggered\")\n",
        "                break\n",
        "\n",
        "def inverse_transform(scaler, data_scaled, feature_index=0):\n",
        "    mean = scaler.mean_[feature_index]\n",
        "    scale = scaler.scale_[feature_index]\n",
        "    return data_scaled * scale + mean\n",
        "\n",
        "def compute_financial_metrics(y_true_scaled, y_pred_scaled, scaler, target_feature_index=0):\n",
        "    y_true = inverse_transform(scaler, y_true_scaled, target_feature_index)\n",
        "    y_pred = inverse_transform(scaler, y_pred_scaled, target_feature_index)\n",
        "\n",
        "    returns_true = np.diff(y_true) / y_true[:-1]\n",
        "    returns_pred = np.diff(y_pred) / y_pred[:-1]\n",
        "\n",
        "    directional_accuracy = np.mean(np.sign(returns_true) == np.sign(returns_pred))\n",
        "    hit_ratio = directional_accuracy\n",
        "\n",
        "    sharpe_ratio = np.mean(returns_pred) / (np.std(returns_pred) + 1e-9) * np.sqrt(365*24)\n",
        "\n",
        "    rmse = np.sqrt(np.mean((y_true - y_pred)**2))\n",
        "\n",
        "    return {\n",
        "        'Directional Accuracy': directional_accuracy,\n",
        "        'Hit Ratio': hit_ratio,\n",
        "        'Sharpe Ratio': sharpe_ratio,\n",
        "        'RMSE': rmse\n",
        "    }\n",
        "\n",
        "def predict_model(model, model_type, data_loader, device='cuda'):\n",
        "    if model_type == 'bilstm':\n",
        "        path = f'best_bilstm.pth'\n",
        "    else:\n",
        "        path = f'best_performer.pth'\n",
        "\n",
        "    model.load_state_dict(torch.load(path))\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    preds, targets = [], []\n",
        "    with torch.no_grad():\n",
        "        for x, y in data_loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            pred = model(x)\n",
        "            preds.extend(pred.cpu().numpy())\n",
        "            targets.extend(y.cpu().numpy())\n",
        "    return np.array(preds), np.array(targets)\n",
        "\n",
        "# --- Feature selection with RFE ---\n",
        "def select_features_rfe(df, target_col='log_return', n_features=10):\n",
        "    df = df.dropna()\n",
        "    df['target'] = df[target_col].shift(-1)\n",
        "    df = df.dropna()\n",
        "    X = df.drop(columns=['target', 'timestamp'])\n",
        "    y = df['target']\n",
        "\n",
        "    X_train, _, y_train, _ = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
        "\n",
        "    lgb_estimator = lgb.LGBMRegressor(n_estimators=100, n_jobs=-1, random_state=42)\n",
        "    rfe_selector = RFE(estimator=lgb_estimator, n_features_to_select=n_features, step=5, verbose=0)\n",
        "    rfe_selector.fit(X_train, y_train)\n",
        "    selected_features = X.columns[rfe_selector.support_].tolist()\n",
        "\n",
        "    if 'close' not in selected_features:\n",
        "        selected_features.append('close')\n",
        "\n",
        "    return selected_features\n",
        "\n",
        "def run_hybrid_pipeline(data_dict, seq_len=24, batch_size=64, device='cuda'):\n",
        "    for coin, df in data_dict.items():\n",
        "        print(f\"\\n=== Processing {coin} ===\")\n",
        "\n",
        "        features = select_features_rfe(df, n_features=10)\n",
        "        print(f\"Selected features (RFE): {features}\")\n",
        "\n",
        "        dataset = CryptoDataset(df, feature_cols=features, target_col='log_return', seq_len=seq_len)\n",
        "        train_size = int(len(dataset) * 0.7)\n",
        "        val_size = int(len(dataset) * 0.15)\n",
        "        test_size = len(dataset) - train_size - val_size\n",
        "\n",
        "        train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, val_size, test_size])\n",
        "\n",
        "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
        "        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "        test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "        bilstm = BiLSTMModel(input_dim=len(features)).to(device)\n",
        "        print(\"Training BiLSTM...\")\n",
        "        train_model(bilstm, train_loader, val_loader, epochs=15, lr=1e-3, device=device)\n",
        "        preds_val_bilstm, y_val = preds_val_bilstm, y_val = predict_model(bilstm, 'bilstm', val_loader, device=device)\n",
        "\n",
        "        performer = PerformerModel(input_dim=len(features)).to(device)\n",
        "        print(\"Training Performer...\")\n",
        "        train_model(performer, train_loader, val_loader, epochs=15, lr=1e-3, device=device)\n",
        "        preds_val_performer, _ = predict_model(performer, 'performer', val_loader, device=device)\n",
        "\n",
        "        # Вычисляем оптимальный вес объединения на валидации\n",
        "        errors_bilstm = preds_val_bilstm - y_val\n",
        "        errors_performer = preds_val_performer - y_val\n",
        "\n",
        "        sigma1 = np.var(errors_bilstm)\n",
        "        sigma2 = np.var(errors_performer)\n",
        "        rho = np.corrcoef(errors_bilstm, errors_performer)[0,1]\n",
        "\n",
        "        w_opt = (sigma2 - rho * np.sqrt(sigma1) * np.sqrt(sigma2)) / (sigma1 + sigma2 - 2 * rho * np.sqrt(sigma1) * np.sqrt(sigma2))\n",
        "        w_opt = np.clip(w_opt, 0, 0.95)\n",
        "        print(f\"Optimal ensemble weight w: {w_opt:.4f}\")\n",
        "\n",
        "        preds_test_bilstm, y_test = predict_model(bilstm, 'bilstm', test_loader, device=device)\n",
        "        preds_test_performer, _ = predict_model(performer,'performer', test_loader, device=device)\n",
        "\n",
        "        combined_preds = w_opt * preds_test_bilstm + (1 - w_opt) * preds_test_performer\n",
        "\n",
        "        scaler = dataset.scaler\n",
        "        price_index = features.index('close')  # индекс для денормализации по цене\n",
        "        metrics = compute_financial_metrics(y_test, preds_test_bilstm, scaler, price_index)\n",
        "        print(f\"Final metrics for {coin} (BiLSTM model):\")\n",
        "        for k, v in metrics.items():\n",
        "            print(f\"{k}: {v:.6f}\")\n",
        "        metrics = compute_financial_metrics(y_test, preds_test_performer, scaler, price_index)\n",
        "        print(f\"Final metrics for {coin} (Performer model):\")\n",
        "        for k, v in metrics.items():\n",
        "            print(f\"{k}: {v:.6f}\")\n",
        "        metrics = compute_financial_metrics(y_test, combined_preds, scaler, price_index)\n",
        "        print(f\"Final metrics for {coin} (hybrid model):\")\n",
        "        for k, v in metrics.items():\n",
        "            print(f\"{k}: {v:.6f}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "-WOLMWmOr4lz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_hybrid_pipeline(data_h, seq_len=240, batch_size=128, device='cuda')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IUrvmDkGbiSy",
        "outputId": "c552bb7d-861a-4ecc-d75c-8d497fc10151"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Processing XRP/USDT ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-34-f0a9d52125d7>:176: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['target'] = df[target_col].shift(-1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected features (RFE): ['volume', 'MACD_diff', 'RSI_14', 'ATR_14', 'STOCH_slowk', 'STOCH_slowd', 'OBV', 'TP_MAD', 'return_1h', 'range', 'close']\n",
            "Training BiLSTM...\n",
            "Epoch 1: Train Loss=0.000172, Val Loss=0.000130, Val RMSE=0.011387\n",
            "Epoch 2: Train Loss=0.000127, Val Loss=0.000126, Val RMSE=0.011237\n",
            "Epoch 3: Train Loss=0.000123, Val Loss=0.000126, Val RMSE=0.011216\n",
            "Epoch 4: Train Loss=0.000122, Val Loss=0.000126, Val RMSE=0.011208\n",
            "Epoch 5: Train Loss=0.000122, Val Loss=0.000125, Val RMSE=0.011184\n",
            "Epoch 6: Train Loss=0.000121, Val Loss=0.000125, Val RMSE=0.011183\n",
            "Epoch 7: Train Loss=0.000121, Val Loss=0.000125, Val RMSE=0.011176\n",
            "Epoch 8: Train Loss=0.000121, Val Loss=0.000125, Val RMSE=0.011183\n",
            "Epoch 9: Train Loss=0.000121, Val Loss=0.000125, Val RMSE=0.011174\n",
            "Epoch 10: Train Loss=0.000121, Val Loss=0.000125, Val RMSE=0.011166\n",
            "Epoch 11: Train Loss=0.000121, Val Loss=0.000125, Val RMSE=0.011176\n",
            "Epoch 12: Train Loss=0.000121, Val Loss=0.000125, Val RMSE=0.011164\n",
            "Epoch 13: Train Loss=0.000121, Val Loss=0.000125, Val RMSE=0.011190\n",
            "Epoch 14: Train Loss=0.000120, Val Loss=0.000125, Val RMSE=0.011196\n",
            "Epoch 15: Train Loss=0.000121, Val Loss=0.000125, Val RMSE=0.011186\n",
            "Training Performer...\n",
            "Epoch 1: Train Loss=0.021394, Val Loss=0.000262, Val RMSE=0.016192\n",
            "Epoch 2: Train Loss=0.000991, Val Loss=0.000188, Val RMSE=0.013722\n",
            "Epoch 3: Train Loss=0.000564, Val Loss=0.000158, Val RMSE=0.012574\n",
            "Epoch 4: Train Loss=0.000391, Val Loss=0.000160, Val RMSE=0.012661\n",
            "Epoch 5: Train Loss=0.000310, Val Loss=0.000177, Val RMSE=0.013319\n",
            "Epoch 6: Train Loss=0.000274, Val Loss=0.000261, Val RMSE=0.016163\n",
            "Epoch 7: Train Loss=0.000245, Val Loss=0.000247, Val RMSE=0.015706\n",
            "Epoch 8: Train Loss=0.000227, Val Loss=0.000166, Val RMSE=0.012870\n",
            "Epoch 9: Train Loss=0.000220, Val Loss=0.000157, Val RMSE=0.012528\n",
            "Epoch 10: Train Loss=0.000210, Val Loss=0.000138, Val RMSE=0.011761\n",
            "Epoch 11: Train Loss=0.000203, Val Loss=0.000145, Val RMSE=0.012036\n",
            "Epoch 12: Train Loss=0.000195, Val Loss=0.000172, Val RMSE=0.013106\n",
            "Epoch 13: Train Loss=0.000199, Val Loss=0.000207, Val RMSE=0.014383\n",
            "Epoch 14: Train Loss=0.000188, Val Loss=0.000177, Val RMSE=0.013306\n",
            "Epoch 15: Train Loss=0.000183, Val Loss=0.000161, Val RMSE=0.012684\n",
            "Optimal ensemble weight w: 0.9500\n",
            "Final metrics for XRP/USDT (BiLSTM model):\n",
            "Directional Accuracy: 0.515294\n",
            "Hit Ratio: 0.515294\n",
            "Sharpe Ratio: 0.078946\n",
            "RMSE: 0.006203\n",
            "Final metrics for XRP/USDT (Performer model):\n",
            "Directional Accuracy: 0.501566\n",
            "Hit Ratio: 0.501566\n",
            "Sharpe Ratio: 0.200927\n",
            "RMSE: 0.006531\n",
            "Final metrics for XRP/USDT (hybrid model):\n",
            "Directional Accuracy: 0.515535\n",
            "Hit Ratio: 0.515535\n",
            "Sharpe Ratio: 0.079283\n",
            "RMSE: 0.006207\n",
            "\n",
            "=== Processing TRX/USDT ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-34-f0a9d52125d7>:176: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['target'] = df[target_col].shift(-1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected features (RFE): ['volume', 'MACD_signal', 'MACD_diff', 'BB_lower', 'ATR_14', 'STOCH_slowd', 'OBV', 'CCI_20', 'return_1h', 'range', 'close']\n",
            "Training BiLSTM...\n",
            "Epoch 1: Train Loss=0.000216, Val Loss=0.000106, Val RMSE=0.010278\n",
            "Epoch 2: Train Loss=0.000104, Val Loss=0.000104, Val RMSE=0.010224\n",
            "Epoch 3: Train Loss=0.000093, Val Loss=0.000104, Val RMSE=0.010187\n",
            "Epoch 4: Train Loss=0.000090, Val Loss=0.000103, Val RMSE=0.010170\n",
            "Epoch 5: Train Loss=0.000088, Val Loss=0.000103, Val RMSE=0.010143\n",
            "Epoch 6: Train Loss=0.000087, Val Loss=0.000103, Val RMSE=0.010149\n",
            "Epoch 7: Train Loss=0.000086, Val Loss=0.000103, Val RMSE=0.010134\n",
            "Epoch 8: Train Loss=0.000086, Val Loss=0.000103, Val RMSE=0.010138\n",
            "Epoch 9: Train Loss=0.000086, Val Loss=0.000103, Val RMSE=0.010153\n",
            "Epoch 10: Train Loss=0.000085, Val Loss=0.000103, Val RMSE=0.010155\n",
            "Epoch 11: Train Loss=0.000085, Val Loss=0.000103, Val RMSE=0.010157\n",
            "Epoch 12: Train Loss=0.000085, Val Loss=0.000102, Val RMSE=0.010128\n",
            "Epoch 13: Train Loss=0.000085, Val Loss=0.000102, Val RMSE=0.010122\n",
            "Epoch 14: Train Loss=0.000085, Val Loss=0.000103, Val RMSE=0.010160\n",
            "Epoch 15: Train Loss=0.000085, Val Loss=0.000102, Val RMSE=0.010092\n",
            "Training Performer...\n",
            "Epoch 1: Train Loss=0.027429, Val Loss=0.000277, Val RMSE=0.016650\n",
            "Epoch 2: Train Loss=0.000790, Val Loss=0.000250, Val RMSE=0.015820\n",
            "Epoch 3: Train Loss=0.000466, Val Loss=0.000161, Val RMSE=0.012709\n",
            "Epoch 4: Train Loss=0.000341, Val Loss=0.000149, Val RMSE=0.012216\n",
            "Epoch 5: Train Loss=0.000258, Val Loss=0.000170, Val RMSE=0.013051\n",
            "Epoch 6: Train Loss=0.000217, Val Loss=0.000127, Val RMSE=0.011277\n",
            "Epoch 7: Train Loss=0.000189, Val Loss=0.000156, Val RMSE=0.012516\n",
            "Epoch 8: Train Loss=0.000171, Val Loss=0.000212, Val RMSE=0.014567\n",
            "Epoch 9: Train Loss=0.000166, Val Loss=0.000124, Val RMSE=0.011160\n",
            "Epoch 10: Train Loss=0.000159, Val Loss=0.000127, Val RMSE=0.011257\n",
            "Epoch 11: Train Loss=0.000164, Val Loss=0.000125, Val RMSE=0.011189\n",
            "Epoch 12: Train Loss=0.000156, Val Loss=0.000137, Val RMSE=0.011723\n",
            "Epoch 13: Train Loss=0.000159, Val Loss=0.000174, Val RMSE=0.013206\n",
            "Epoch 14: Train Loss=0.000156, Val Loss=0.000127, Val RMSE=0.011288\n",
            "Epoch 15: Train Loss=0.000153, Val Loss=0.000116, Val RMSE=0.010758\n",
            "Optimal ensemble weight w: 0.9500\n",
            "Final metrics for TRX/USDT (BiLSTM model):\n",
            "Directional Accuracy: 0.501686\n",
            "Hit Ratio: 0.501686\n",
            "Sharpe Ratio: 0.042341\n",
            "RMSE: 0.000558\n",
            "Final metrics for TRX/USDT (Performer model):\n",
            "Directional Accuracy: 0.509032\n",
            "Hit Ratio: 0.509032\n",
            "Sharpe Ratio: 0.126090\n",
            "RMSE: 0.000593\n",
            "Final metrics for TRX/USDT (hybrid model):\n",
            "Directional Accuracy: 0.502649\n",
            "Hit Ratio: 0.502649\n",
            "Sharpe Ratio: 0.038571\n",
            "RMSE: 0.000558\n",
            "\n",
            "=== Processing BTC/USDT ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-34-f0a9d52125d7>:176: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['target'] = df[target_col].shift(-1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected features (RFE): ['volume', 'MACD_diff', 'RSI_14', 'ATR_14', 'STOCH_slowk', 'STOCH_slowd', 'OBV', 'TP_MAD', 'CCI_20', 'return_1h', 'close']\n",
            "Training BiLSTM...\n",
            "Epoch 1: Train Loss=0.000159, Val Loss=0.000050, Val RMSE=0.007090\n",
            "Epoch 2: Train Loss=0.000060, Val Loss=0.000050, Val RMSE=0.007064\n",
            "Epoch 3: Train Loss=0.000055, Val Loss=0.000050, Val RMSE=0.007057\n",
            "Epoch 4: Train Loss=0.000052, Val Loss=0.000050, Val RMSE=0.007057\n",
            "Epoch 5: Train Loss=0.000052, Val Loss=0.000050, Val RMSE=0.007042\n",
            "Epoch 6: Train Loss=0.000051, Val Loss=0.000050, Val RMSE=0.007044\n",
            "Epoch 7: Train Loss=0.000051, Val Loss=0.000050, Val RMSE=0.007036\n",
            "Epoch 8: Train Loss=0.000050, Val Loss=0.000049, Val RMSE=0.007034\n",
            "Epoch 9: Train Loss=0.000050, Val Loss=0.000049, Val RMSE=0.007032\n",
            "Epoch 10: Train Loss=0.000050, Val Loss=0.000049, Val RMSE=0.007034\n",
            "Epoch 11: Train Loss=0.000050, Val Loss=0.000049, Val RMSE=0.007029\n",
            "Epoch 12: Train Loss=0.000050, Val Loss=0.000049, Val RMSE=0.007028\n",
            "Epoch 13: Train Loss=0.000050, Val Loss=0.000049, Val RMSE=0.007024\n",
            "Epoch 14: Train Loss=0.000050, Val Loss=0.000049, Val RMSE=0.007031\n",
            "Epoch 15: Train Loss=0.000050, Val Loss=0.000049, Val RMSE=0.007028\n",
            "Training Performer...\n",
            "Epoch 1: Train Loss=0.025583, Val Loss=0.000131, Val RMSE=0.011457\n",
            "Epoch 2: Train Loss=0.000525, Val Loss=0.000076, Val RMSE=0.008721\n",
            "Epoch 3: Train Loss=0.000305, Val Loss=0.000064, Val RMSE=0.008016\n",
            "Epoch 4: Train Loss=0.000211, Val Loss=0.000070, Val RMSE=0.008370\n",
            "Epoch 5: Train Loss=0.000163, Val Loss=0.000054, Val RMSE=0.007379\n",
            "Epoch 6: Train Loss=0.000151, Val Loss=0.000063, Val RMSE=0.007919\n",
            "Epoch 7: Train Loss=0.000124, Val Loss=0.000069, Val RMSE=0.008305\n",
            "Epoch 8: Train Loss=0.000109, Val Loss=0.000177, Val RMSE=0.013298\n",
            "Epoch 9: Train Loss=0.000116, Val Loss=0.000068, Val RMSE=0.008252\n",
            "Epoch 10: Train Loss=0.000122, Val Loss=0.000294, Val RMSE=0.017143\n",
            "Epoch 11: Train Loss=0.000112, Val Loss=0.000096, Val RMSE=0.009791\n",
            "Epoch 12: Train Loss=0.000109, Val Loss=0.000057, Val RMSE=0.007525\n",
            "Epoch 13: Train Loss=0.000110, Val Loss=0.000075, Val RMSE=0.008664\n",
            "Epoch 14: Train Loss=0.000103, Val Loss=0.000097, Val RMSE=0.009850\n",
            "Epoch 15: Train Loss=0.000105, Val Loss=0.000052, Val RMSE=0.007189\n",
            "Optimal ensemble weight w: 0.9500\n",
            "Final metrics for BTC/USDT (BiLSTM model):\n",
            "Directional Accuracy: 0.513728\n",
            "Hit Ratio: 0.513728\n",
            "Sharpe Ratio: 0.016783\n",
            "RMSE: 173.969222\n",
            "Final metrics for BTC/USDT (Performer model):\n",
            "Directional Accuracy: 0.494099\n",
            "Hit Ratio: 0.494099\n",
            "Sharpe Ratio: 0.051641\n",
            "RMSE: 177.760934\n",
            "Final metrics for BTC/USDT (hybrid model):\n",
            "Directional Accuracy: 0.511320\n",
            "Hit Ratio: 0.511320\n",
            "Sharpe Ratio: 0.017540\n",
            "RMSE: 173.891210\n",
            "\n",
            "=== Processing SOL/USDT ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-34-f0a9d52125d7>:176: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['target'] = df[target_col].shift(-1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected features (RFE): ['volume', 'MACD_diff', 'RSI_14', 'BB_lower', 'STOCH_slowk', 'STOCH_slowd', 'OBV', 'TP_MAD', 'CCI_20', 'return_1h', 'close']\n",
            "Training BiLSTM...\n",
            "Epoch 1: Train Loss=0.000263, Val Loss=0.000216, Val RMSE=0.014671\n",
            "Epoch 2: Train Loss=0.000201, Val Loss=0.000206, Val RMSE=0.014340\n",
            "Epoch 3: Train Loss=0.000194, Val Loss=0.000206, Val RMSE=0.014325\n",
            "Epoch 4: Train Loss=0.000192, Val Loss=0.000205, Val RMSE=0.014301\n",
            "Epoch 5: Train Loss=0.000191, Val Loss=0.000205, Val RMSE=0.014301\n",
            "Epoch 6: Train Loss=0.000190, Val Loss=0.000205, Val RMSE=0.014297\n",
            "Epoch 7: Train Loss=0.000190, Val Loss=0.000205, Val RMSE=0.014288\n",
            "Epoch 8: Train Loss=0.000190, Val Loss=0.000205, Val RMSE=0.014276\n",
            "Epoch 9: Train Loss=0.000190, Val Loss=0.000205, Val RMSE=0.014276\n",
            "Epoch 10: Train Loss=0.000190, Val Loss=0.000205, Val RMSE=0.014271\n",
            "Epoch 11: Train Loss=0.000189, Val Loss=0.000205, Val RMSE=0.014275\n",
            "Epoch 12: Train Loss=0.000189, Val Loss=0.000205, Val RMSE=0.014280\n",
            "Epoch 13: Train Loss=0.000189, Val Loss=0.000205, Val RMSE=0.014267\n",
            "Epoch 14: Train Loss=0.000189, Val Loss=0.000205, Val RMSE=0.014284\n",
            "Epoch 15: Train Loss=0.000189, Val Loss=0.000205, Val RMSE=0.014268\n",
            "Training Performer...\n",
            "Epoch 1: Train Loss=0.049331, Val Loss=0.000265, Val RMSE=0.016286\n",
            "Epoch 2: Train Loss=0.001188, Val Loss=0.000268, Val RMSE=0.016419\n",
            "Epoch 3: Train Loss=0.000790, Val Loss=0.000238, Val RMSE=0.015408\n",
            "Epoch 4: Train Loss=0.000574, Val Loss=0.000222, Val RMSE=0.014898\n",
            "Epoch 5: Train Loss=0.000467, Val Loss=0.000352, Val RMSE=0.018791\n",
            "Epoch 6: Train Loss=0.000412, Val Loss=0.000399, Val RMSE=0.020013\n",
            "Epoch 7: Train Loss=0.000399, Val Loss=0.000242, Val RMSE=0.015580\n",
            "Epoch 8: Train Loss=0.000344, Val Loss=0.000214, Val RMSE=0.014598\n",
            "Epoch 9: Train Loss=0.000321, Val Loss=0.000229, Val RMSE=0.015112\n",
            "Epoch 10: Train Loss=0.000323, Val Loss=0.000221, Val RMSE=0.014843\n",
            "Epoch 11: Train Loss=0.000332, Val Loss=0.000217, Val RMSE=0.014724\n",
            "Epoch 12: Train Loss=0.000318, Val Loss=0.000246, Val RMSE=0.015638\n",
            "Epoch 13: Train Loss=0.000303, Val Loss=0.000269, Val RMSE=0.016405\n",
            "Epoch 14: Train Loss=0.000307, Val Loss=0.000226, Val RMSE=0.015005\n",
            "Epoch 15: Train Loss=0.000312, Val Loss=0.000213, Val RMSE=0.014595\n",
            "Optimal ensemble weight w: 0.9500\n",
            "Final metrics for SOL/USDT (BiLSTM model):\n",
            "Directional Accuracy: 0.500161\n",
            "Hit Ratio: 0.500161\n",
            "Sharpe Ratio: 0.051420\n",
            "RMSE: 0.984675\n",
            "Final metrics for SOL/USDT (Performer model):\n",
            "Directional Accuracy: 0.499193\n",
            "Hit Ratio: 0.499193\n",
            "Sharpe Ratio: 0.131203\n",
            "RMSE: 1.004867\n",
            "Final metrics for SOL/USDT (hybrid model):\n",
            "Directional Accuracy: 0.498062\n",
            "Hit Ratio: 0.498062\n",
            "Sharpe Ratio: 0.051636\n",
            "RMSE: 0.984392\n",
            "\n",
            "=== Processing ETH/USDT ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-34-f0a9d52125d7>:176: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['target'] = df[target_col].shift(-1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected features (RFE): ['volume', 'MACD_diff', 'BB_lower', 'ATR_14', 'STOCH_slowk', 'STOCH_slowd', 'OBV', 'CCI_20', 'return_1h', 'hour', 'close']\n",
            "Training BiLSTM...\n",
            "Epoch 1: Train Loss=0.000193, Val Loss=0.000073, Val RMSE=0.008546\n",
            "Epoch 2: Train Loss=0.000099, Val Loss=0.000071, Val RMSE=0.008453\n",
            "Epoch 3: Train Loss=0.000090, Val Loss=0.000072, Val RMSE=0.008493\n",
            "Epoch 4: Train Loss=0.000086, Val Loss=0.000072, Val RMSE=0.008462\n",
            "Epoch 5: Train Loss=0.000084, Val Loss=0.000072, Val RMSE=0.008458\n",
            "Epoch 6: Train Loss=0.000082, Val Loss=0.000071, Val RMSE=0.008404\n",
            "Epoch 7: Train Loss=0.000081, Val Loss=0.000071, Val RMSE=0.008412\n",
            "Epoch 8: Train Loss=0.000080, Val Loss=0.000071, Val RMSE=0.008409\n",
            "Epoch 9: Train Loss=0.000080, Val Loss=0.000071, Val RMSE=0.008400\n",
            "Epoch 10: Train Loss=0.000080, Val Loss=0.000071, Val RMSE=0.008401\n",
            "Epoch 11: Train Loss=0.000079, Val Loss=0.000071, Val RMSE=0.008406\n",
            "Epoch 12: Train Loss=0.000079, Val Loss=0.000071, Val RMSE=0.008401\n",
            "Epoch 13: Train Loss=0.000079, Val Loss=0.000071, Val RMSE=0.008409\n",
            "Epoch 14: Train Loss=0.000079, Val Loss=0.000071, Val RMSE=0.008415\n",
            "Epoch 15: Train Loss=0.000079, Val Loss=0.000071, Val RMSE=0.008403\n",
            "Training Performer...\n",
            "Epoch 1: Train Loss=0.023002, Val Loss=0.000124, Val RMSE=0.011137\n",
            "Epoch 2: Train Loss=0.000672, Val Loss=0.000144, Val RMSE=0.011998\n",
            "Epoch 3: Train Loss=0.000399, Val Loss=0.000086, Val RMSE=0.009254\n",
            "Epoch 4: Train Loss=0.000272, Val Loss=0.000107, Val RMSE=0.010337\n",
            "Epoch 5: Train Loss=0.000218, Val Loss=0.000077, Val RMSE=0.008770\n",
            "Epoch 6: Train Loss=0.000185, Val Loss=0.000106, Val RMSE=0.010274\n",
            "Epoch 7: Train Loss=0.000162, Val Loss=0.000082, Val RMSE=0.009073\n",
            "Epoch 8: Train Loss=0.000169, Val Loss=0.000077, Val RMSE=0.008750\n",
            "Epoch 9: Train Loss=0.000184, Val Loss=0.000242, Val RMSE=0.015570\n",
            "Epoch 10: Train Loss=0.000165, Val Loss=0.000093, Val RMSE=0.009635\n",
            "Epoch 11: Train Loss=0.000145, Val Loss=0.000074, Val RMSE=0.008612\n",
            "Epoch 12: Train Loss=0.000135, Val Loss=0.000115, Val RMSE=0.010699\n",
            "Epoch 13: Train Loss=0.000139, Val Loss=0.000074, Val RMSE=0.008585\n",
            "Epoch 14: Train Loss=0.000131, Val Loss=0.000075, Val RMSE=0.008671\n",
            "Epoch 15: Train Loss=0.000132, Val Loss=0.000073, Val RMSE=0.008538\n",
            "Optimal ensemble weight w: 0.9500\n",
            "Final metrics for ETH/USDT (BiLSTM model):\n",
            "Directional Accuracy: 0.498675\n",
            "Hit Ratio: 0.498675\n",
            "Sharpe Ratio: 0.043406\n",
            "RMSE: 10.499380\n",
            "Final metrics for ETH/USDT (Performer model):\n",
            "Directional Accuracy: 0.498916\n",
            "Hit Ratio: 0.498916\n",
            "Sharpe Ratio: 0.074450\n",
            "RMSE: 10.759448\n",
            "Final metrics for ETH/USDT (hybrid model):\n",
            "Directional Accuracy: 0.499157\n",
            "Hit Ratio: 0.499157\n",
            "Sharpe Ratio: 0.043627\n",
            "RMSE: 10.505727\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Учимся прогнозировать на 6 часов вперед"
      ],
      "metadata": {
        "id": "3GgIkQcMP9Yp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "def plot_training_curves(train_loss, val_loss, coin, output_dir='plots'):\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(train_loss, label='Training Loss')\n",
        "    plt.plot(val_loss, label='Validation Loss')\n",
        "    plt.title(f'{coin} Training/Validation Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('MSE Loss')\n",
        "    plt.legend()\n",
        "    plt.savefig(os.path.join(output_dir, f'{coin}_training_curves.png'))\n",
        "    plt.close()\n",
        "\n",
        "def plot_predictions_vs_actuals_full(true_prices, pred_prices, timestamps, coin, max_points=150, output_dir='plots'):\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    if len(true_prices) > max_points:\n",
        "        true_prices = true_prices[-max_points:]\n",
        "        pred_prices = pred_prices[-max_points:]\n",
        "        timestamps = timestamps[-max_points:]\n",
        "\n",
        "    plt.figure(figsize=(14, 7))\n",
        "    plt.plot(timestamps, true_prices, label='Реальная цена', linewidth=2)\n",
        "    plt.plot(timestamps, pred_prices, label='Прогноз цены', linestyle='--')\n",
        "\n",
        "    plt.xlabel('Время')\n",
        "    plt.ylabel('Цена')\n",
        "\n",
        "    ymin = min(min(true_prices), min(pred_prices)) * 0.95\n",
        "    ymax = max(max(true_prices), max(pred_prices)) * 1.05\n",
        "    plt.ylim(ymin, ymax)\n",
        "\n",
        "    plt.legend()\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(output_dir, f'{coin}_actual_vs_predicted.png'))\n",
        "    plt.close()"
      ],
      "metadata": {
        "id": "wSsGkjUU5o4C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_selection import RFE\n",
        "import lightgbm as lgb\n",
        "import torch.nn as nn\n",
        "from torch.optim import Adam\n",
        "from performer_pytorch import Performer"
      ],
      "metadata": {
        "id": "-Ap8fH1sNNgI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_multi_step_targets(df, target_col='log_return', horizon=6):\n",
        "    for i in range(1, horizon + 1):\n",
        "        df[f'target_t+{i}'] = df[target_col].shift(-i)\n",
        "    df = df.dropna().reset_index(drop=True)\n",
        "    return df\n",
        "\n",
        "def select_features_rfe(df, target_col='log_return', n_features=10):\n",
        "    df = df.dropna()\n",
        "    df['target'] = df[target_col].shift(-1)\n",
        "    df = df.dropna()\n",
        "    X = df.drop(columns=['target', 'timestamp'])\n",
        "    y = df['target']\n",
        "\n",
        "    X_train, _, y_train, _ = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
        "\n",
        "    lgb_estimator = lgb.LGBMRegressor(n_estimators=100, n_jobs=-1, random_state=42)\n",
        "    rfe_selector = RFE(estimator=lgb_estimator, n_features_to_select=n_features, step=5)\n",
        "    rfe_selector.fit(X_train, y_train)\n",
        "    selected_features = X.columns[rfe_selector.support_].tolist()\n",
        "\n",
        "    if 'close' not in selected_features:\n",
        "        selected_features.append('close')\n",
        "\n",
        "    return selected_features"
      ],
      "metadata": {
        "id": "cVjMi2_pNOOD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiStepDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, df, feature_cols, target_col, seq_len=120):\n",
        "        self.seq_len = seq_len\n",
        "        self.df = df.reset_index(drop=True)\n",
        "\n",
        "        # Отдельно обрабатываем close для правильного восстановления\n",
        "        self.close = df['close'].values\n",
        "        features = df[feature_cols].values\n",
        "\n",
        "        self.scaler = StandardScaler()\n",
        "        self.features = self.scaler.fit_transform(features)\n",
        "\n",
        "        self.targets = df[target_col].values\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x = self.features[idx:idx+self.seq_len]\n",
        "        y = self.targets[idx+self.seq_len]\n",
        "        close_price = self.close[idx+self.seq_len-1]  # Последняя цена в окне\n",
        "        return torch.tensor(x, dtype=torch.float32), torch.tensor(y, dtype=torch.float32), close_price\n"
      ],
      "metadata": {
        "id": "AIJV9AjaNOLa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class HybridPerformerBiLSTM(nn.Module):\n",
        "    def __init__(self, input_dim, horizon=6, lstm_hidden=64, lstm_layers=2,\n",
        "                 performer_dim=128, performer_depth=3, performer_heads=4, dim_head=32, dropout=0.1):\n",
        "        super().__init__()\n",
        "        # BiLSTM\n",
        "        self.bilstm = nn.LSTM(input_dim, lstm_hidden, num_layers=lstm_layers,\n",
        "                              batch_first=True, bidirectional=True, dropout=dropout)\n",
        "        self.bilstm_fc = nn.Linear(lstm_hidden * 2, horizon)\n",
        "\n",
        "        # Performer\n",
        "        self.project = nn.Linear(input_dim, performer_dim)\n",
        "        self.performer = Performer(\n",
        "            dim=performer_dim,\n",
        "            depth=performer_depth,\n",
        "            heads=performer_heads,\n",
        "            dim_head=dim_head,\n",
        "            causal=False,\n",
        "            ff_dropout = 0.1,\n",
        "            attn_dropout = 0.1\n",
        "        )\n",
        "        self.performer_fc = nn.Linear(performer_dim, horizon)\n",
        "\n",
        "        self.weight = nn.Parameter(torch.tensor(0.5))\n",
        "    def forward(self, x):\n",
        "        lstm_out, _ = self.bilstm(x)\n",
        "        lstm_last = lstm_out[:, -1, :]\n",
        "        lstm_pred = self.bilstm_fc(lstm_last)\n",
        "\n",
        "        proj = self.project(x)\n",
        "        performer_out = self.performer(proj)\n",
        "        performer_last = performer_out[:, -1, :]\n",
        "        performer_pred = self.performer_fc(performer_last)\n",
        "\n",
        "        w = torch.sigmoid(self.weight)\n",
        "        ц = np.clip(w, 0, 0.95)\n",
        "        out = w * lstm_pred + (1 - w) * performer_pred\n",
        "        return out"
      ],
      "metadata": {
        "id": "Paz3X0PENOIj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_loader, val_loader, epochs=5, lr=1e-4, device='cuda'):\n",
        "    import numpy as np\n",
        "    import torch\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    criterion = torch.nn.MSELoss()\n",
        "    model.to(device)\n",
        "\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        running_train_loss = 0.0\n",
        "        num_train_batches = 0\n",
        "\n",
        "        for x_batch, y_batch, *_ in train_loader:\n",
        "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output = model(x_batch)\n",
        "            loss = criterion(output, y_batch)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_train_loss += loss.item()\n",
        "            num_train_batches += 1\n",
        "\n",
        "        avg_train_loss = running_train_loss / num_train_batches\n",
        "        train_losses.append(avg_train_loss)\n",
        "\n",
        "        model.eval()\n",
        "        running_val_loss = 0.0\n",
        "        num_val_batches = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for x_val, y_val, *_ in val_loader:\n",
        "                x_val, y_val = x_val.to(device), y_val.to(device)\n",
        "                output = model(x_val)\n",
        "                loss = criterion(output, y_val)\n",
        "                running_val_loss += loss.item()\n",
        "                num_val_batches += 1\n",
        "\n",
        "        avg_val_loss = running_val_loss / num_val_batches\n",
        "        val_losses.append(avg_val_loss)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{epochs} Train Loss: {avg_train_loss:.6f} Val Loss: {avg_val_loss:.6f}\")\n",
        "\n",
        "    return train_losses, val_losses"
      ],
      "metadata": {
        "id": "QtNMe0pRNUj5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def inverse_transform(scaler, data_scaled, feature_index=0):\n",
        "    mean = scaler.mean_[feature_index]\n",
        "    scale = scaler.scale_[feature_index]\n",
        "    return data_scaled * scale + mean\n",
        "\n",
        "def sharpe_ratio(returns, risk_free_rate=0.0):\n",
        "    excess_returns = returns - risk_free_rate\n",
        "    mean_excess_return = np.mean(excess_returns)\n",
        "    std_excess_return = np.std(excess_returns) + 1e-9  # чтобы избежать деления на 0\n",
        "    return mean_excess_return / std_excess_return * np.sqrt(365*24)\n",
        "\n",
        "def compute_metrics_multistep(y_true_logr, y_pred_logr, initial_prices):\n",
        "    horizon = y_true_logr.shape[1]\n",
        "    metrics_per_step = []\n",
        "    for i in range(horizon):\n",
        "        y_true = initial_prices * np.exp(y_true_logr[:, i])\n",
        "        y_pred = initial_prices * np.exp(y_pred_logr[:, i])\n",
        "\n",
        "        rmse = np.sqrt(np.mean((y_true - y_pred) ** 2))\n",
        "        returns_true = (y_true - initial_prices) / initial_prices\n",
        "        returns_pred = (y_pred - initial_prices) / initial_prices\n",
        "\n",
        "        da = np.mean(np.sign(returns_true) == np.sign(returns_pred))\n",
        "        sr = sharpe_ratio(returns_pred)\n",
        "\n",
        "        metrics_per_step.append({\n",
        "            'step': i + 1,\n",
        "            'RMSE': rmse,\n",
        "            'Directional Accuracy': da,\n",
        "            'Sharpe Ratio': sr\n",
        "        })\n",
        "    return metrics_per_step"
      ],
      "metadata": {
        "id": "YjTdj6G9NUhR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, data_loader, dataset, df, coin, seq_len=120, device='cuda'):\n",
        "\n",
        "    model.eval()\n",
        "    preds, targets, last_prices = [], [], []\n",
        "    indices = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (x, y, close_price) in enumerate(data_loader):\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            pred = model(x)\n",
        "\n",
        "            preds.append(pred.cpu().numpy())\n",
        "            targets.append(y.cpu().numpy())\n",
        "            last_prices.append(close_price.numpy())\n",
        "\n",
        "            batch_start = len(train_dataset) + len(val_dataset) + i * x.shape[0]\n",
        "            indices.extend(list(range(batch_start, batch_start + x.shape[0])))\n",
        "\n",
        "    # horizon=1\n",
        "    preds = np.vstack(preds)[:, 0]\n",
        "    targets = np.vstack(targets)[:, 0]\n",
        "    last_prices = np.concatenate(last_prices)\n",
        "\n",
        "    true_prices = last_prices * np.exp(targets)\n",
        "    pred_prices = last_prices * np.exp(preds)\n",
        "\n",
        "    timestamps = df.iloc[indices]['timestamp'].values\n",
        "\n",
        "    min_len = min(len(true_prices), len(pred_prices), len(timestamps))\n",
        "    true_prices = true_prices[:min_len]\n",
        "    pred_prices = pred_prices[:min_len]\n",
        "    timestamps = timestamps[:min_len]\n",
        "\n",
        "    plot_predictions_vs_actuals_full(true_prices, pred_prices, timestamps, coin.replace('/', '_'))\n",
        "\n",
        "    return compute_metrics_multistep(targets[:, None], preds[:, None], last_prices)\n"
      ],
      "metadata": {
        "id": "k9vQV9soNUeo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_predictions_vs_actuals_full(true_prices, pred_prices, timestamps, coin, max_points=150, output_dir='plots'):\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    timestamps = pd.to_datetime(timestamps)\n",
        "\n",
        "    plot_df = pd.DataFrame({\n",
        "        'timestamp': timestamps,\n",
        "        'Actual': true_prices,\n",
        "        'Predicted': pred_prices\n",
        "    }).set_index('timestamp')\n",
        "\n",
        "    if len(plot_df) > max_points:\n",
        "        plot_df = plot_df.iloc[-max_points:]\n",
        "\n",
        "    plt.figure(figsize=(16, 8))\n",
        "\n",
        "    plt.plot(plot_df.index, plot_df['Actual'], label='Actual Price', linewidth=2, alpha=0.8)\n",
        "    plt.plot(plot_df.index, plot_df['Predicted'], label='Predicted Price', linestyle='--', linewidth=1.5)\n",
        "\n",
        "    plt.title(f'{coin} почасовые данные')\n",
        "    plt.xlabel('Время')\n",
        "    plt.ylabel('Цена ($)')\n",
        "\n",
        "    plt.gcf().autofmt_xdate()\n",
        "    plt.grid(True, which='both', linestyle='--', alpha=0.5)\n",
        "\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "\n",
        "    plt.savefig(os.path.join(output_dir, f'{coin}_actual_vs_predicted.png'), dpi=300)\n",
        "    plt.close()"
      ],
      "metadata": {
        "id": "Na-snC91NUcC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_pipeline_all_coins(data_dict, target_col='log_return', horizon=6, seq_len=120, batch_size=64, device='cuda'):\n",
        "    for coin, df in data_dict.items():\n",
        "        print(f\"\\n=== Processing {coin} ===\")\n",
        "\n",
        "        df = create_multi_step_targets(df, target_col=target_col, horizon=horizon)\n",
        "        target_cols = [f'target_t+{i}' for i in range(1, horizon+1)]\n",
        "        feature_cols = [col for col in df.columns if col not in target_cols]\n",
        "\n",
        "        features = select_features_rfe(df[feature_cols], target_col=target_col, n_features=10)\n",
        "        if 'close' not in features:\n",
        "            features.append('close')\n",
        "\n",
        "        dataset = MultiStepDataset(\n",
        "            df=df,\n",
        "            feature_cols=features,\n",
        "            target_col=target_cols,\n",
        "            seq_len=seq_len\n",
        "        )\n",
        "        train_size = int(len(dataset) * 0.7)\n",
        "        val_size = int(len(dataset) * 0.15)\n",
        "        test_size = len(dataset) - train_size - val_size\n",
        "\n",
        "        indices = np.arange(len(dataset))\n",
        "        train_indices = indices[:train_size]\n",
        "        val_indices = indices[train_size:train_size+val_size]\n",
        "        test_indices = indices[train_size+val_size:]\n",
        "\n",
        "        train_dataset = torch.utils.data.Subset(dataset, train_indices)\n",
        "        val_dataset = torch.utils.data.Subset(dataset, val_indices)\n",
        "        test_dataset = torch.utils.data.Subset(dataset, test_indices)\n",
        "\n",
        "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
        "        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "        test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "        model = HybridPerformerBiLSTM(\n",
        "            input_dim=len(features),\n",
        "            horizon=horizon\n",
        "        ).to(device)\n",
        "\n",
        "        train_loss, val_loss = train_model(\n",
        "            model=model,\n",
        "            train_loader=train_loader,\n",
        "            val_loader=val_loader,\n",
        "            epochs=15,\n",
        "            lr=1e-4,\n",
        "            device=device\n",
        "        )\n",
        "\n",
        "        plot_training_curves(train_loss, val_loss, coin.replace('/', '_'))\n",
        "\n",
        "        metrics = evaluate_model(\n",
        "            model=model,\n",
        "            data_loader=test_loader,\n",
        "            dataset=dataset,\n",
        "            df=df,\n",
        "            coin=coin,\n",
        "            seq_len=seq_len,\n",
        "            device=device\n",
        "        )\n",
        "\n",
        "        print(f\"\\nMetrics for {coin}:\")\n",
        "        for m in metrics:\n",
        "            print(f\"Step {m['step']}:\")\n",
        "            print(f\"  RMSE: {m['RMSE']:.4f}\")\n",
        "            print(f\"  DA: {m['Directional Accuracy']:.2%}\")\n",
        "            print(f\"  Sharpe: {m['Sharpe Ratio']:.2f}\\n\")"
      ],
      "metadata": {
        "id": "5xY337XLbiQB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs('plots', exist_ok=True)"
      ],
      "metadata": {
        "id": "SLTUqxQISW0z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)"
      ],
      "metadata": {
        "id": "vx7fp-1hQ5Pf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_pipeline_all_coins(data_h, target_col='log_return', horizon=1, seq_len=360, batch_size=64, device='cuda')"
      ],
      "metadata": {
        "id": "dHnlHgQsr1XH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uY64wAa53_FG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WYu_9KCl3_Cj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}