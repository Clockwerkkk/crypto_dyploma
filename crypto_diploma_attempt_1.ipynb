{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Ğ‘Ğ°Ğ·Ğ°, Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…\n"
      ],
      "metadata": {
        "id": "K1o6EXdiLvaE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass"
      ],
      "metadata": {
        "id": "r36ciuwcocYQ"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "JVVNPRB7YziM"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#BINANCE_API_KEY = getpass.getpass('BINANCE_API_KEY: ')\n",
        "#BINANCE_SECRET_KEY = getpass.getpass('BINANCE_SECRET_KEY: ')"
      ],
      "metadata": {
        "id": "G0_JGZFKol_h"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ğ’Ğ°Ğ¶Ğ½Ğ¾Ğµ ÑƒÑ‚Ğ¾Ñ‡Ğ½ĞµĞ½Ğ¸Ğµ, Ğ¿Ğ¾Ñ‡ĞµĞ¼Ñƒ Ğ½Ğ¸Ğ¶Ğµ Ğ²ÑĞµ Ğ·Ğ°ĞºĞ¾Ğ¼Ğ¼ĞµĞ½Ñ‡ĞµĞ½Ğ¾:\n",
        "Binance Ğ½Ğµ Ğ´Ğ°ĞµÑ‚ Ğ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚Ğ¸ ĞºĞ°Ñ‡Ğ°Ñ‚ÑŒ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ¿Ğ¾ API Ğ¸Ğ· Ğ»ÑĞ±Ğ¾Ğ³Ğ¾ Ğ¼ĞµÑÑ‚Ğ°, Ğ¸Ğ¼ĞµĞ½Ğ½Ğ¾ Ğ¿Ğ¾ÑÑ‚Ğ¾Ğ¼Ñƒ ĞºĞ¾Ğ»Ğ»Ğ°Ğ± Ğ¸Ğ½Ğ¾Ğ³Ğ´Ğ° Ğ¼Ğ¾Ğ¶ĞµÑ‚ Ğ¸Ñ… ÑĞºĞ°Ñ‡Ğ°Ñ‚ÑŒ, Ğ° Ğ¸Ğ½Ğ¾Ğ³Ğ´Ğ° - Ğ½ĞµÑ‚. Ğ˜Ğ·-Ğ·Ğ° ÑÑ‚Ğ¾Ğ³Ğ¾ Ğ² Ğ´Ğ°Ğ½Ğ½Ğ¾Ğ¼ Ñ„Ğ°Ğ¹Ğ»Ğµ Ğ¾Ğ½Ğ¾ Ğ·Ğ°ĞºĞ¾Ğ¼Ğ¼ĞµĞ½Ñ‡ĞµĞ½Ğ¾, Ğ² Ğ¸Ñ‚Ğ¾Ğ³Ğ¾Ğ²Ğ¾Ğ¼ ÑĞµÑ€Ğ²Ğ¸ÑĞµ Ñ Ñ€Ğ¾ÑÑĞ¸Ğ¹ÑĞºĞ¸Ğ¼ IP Ğ±ÑƒĞ´ĞµÑ‚ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ğ¾Ğ½Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ¿Ğ¾Ğ»Ğ½Ğ¾Ñ†ĞµĞ½Ğ½Ğ¾"
      ],
      "metadata": {
        "id": "kMO_xEjvgBJy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import ccxt\n",
        "import os\n",
        "import time\n",
        "from datetime import datetime\n",
        "from dotenv import load_dotenv\n",
        "'''\n",
        "load_dotenv()\n",
        "\n",
        "binance = ccxt.binance({\n",
        "    'apiKey': BINANCE_API_KEY ,\n",
        "    'secret': BINANCE_SECRET_KEY,\n",
        "    'enableRateLimit': True\n",
        "})\n",
        "\n",
        "def compute_indicators(df):\n",
        "    # EMA\n",
        "    df['EMA_10'] = df['close'].ewm(span=10, adjust=False).mean()\n",
        "    df['EMA_50'] = df['close'].ewm(span=50, adjust=False).mean()\n",
        "\n",
        "    # RSI\n",
        "    delta = df['close'].diff()\n",
        "    gain = np.where(delta > 0, delta, 0)\n",
        "    loss = np.where(delta < 0, -delta, 0)\n",
        "    avg_gain = pd.Series(gain).rolling(window=14).mean()\n",
        "    avg_loss = pd.Series(loss).rolling(window=14).mean()\n",
        "    rs = avg_gain / avg_loss\n",
        "    df['RSI_14'] = 100 - (100 / (1 + rs))\n",
        "\n",
        "    # MACD\n",
        "    ema12 = df['close'].ewm(span=12, adjust=False).mean()\n",
        "    ema26 = df['close'].ewm(span=26, adjust=False).mean()\n",
        "    df['MACD'] = ema12 - ema26\n",
        "    df['MACD_signal'] = df['MACD'].ewm(span=9, adjust=False).mean()\n",
        "\n",
        "    # Bollinger Bands\n",
        "    sma20 = df['close'].rolling(window=20).mean()\n",
        "    std20 = df['close'].rolling(window=20).std()\n",
        "    df['Bollinger_Upper'] = sma20 + (2 * std20)\n",
        "    df['Bollinger_Lower'] = sma20 - (2 * std20)\n",
        "\n",
        "    # ATR\n",
        "    high_low = df['high'] - df['low']\n",
        "    high_close = np.abs(df['high'] - df['close'].shift())\n",
        "    low_close = np.abs(df['low'] - df['close'].shift())\n",
        "    tr = pd.concat([high_low, high_close, low_close], axis=1).max(axis=1)\n",
        "    df['ATR_14'] = tr.rolling(window=14).mean()\n",
        "\n",
        "    return df\n",
        "\n",
        "# ĞŸĞ¾ÑˆĞ°Ğ³Ğ¾Ğ²Ğ°Ñ Ğ·Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ğ·Ğ° 5 Ğ»ĞµÑ‚\n",
        "def fetch_full_history(symbol, timeframe='1h', since=None, max_batches=1000, batch_limit=1500, sleep_sec=1):\n",
        "    all_ohlcv = []\n",
        "    since = since or binance.parse8601('2019-01-01T00:00:00Z')\n",
        "\n",
        "    for i in range(max_batches):\n",
        "        try:\n",
        "            print(f\"[{symbol}] Ğ‘Ğ°Ñ‚Ñ‡ {i + 1}, since = {datetime.utcfromtimestamp(since / 1000)}\")\n",
        "            ohlcv = binance.fetch_ohlcv(symbol, timeframe=timeframe, since=since, limit=batch_limit)\n",
        "            if not ohlcv:\n",
        "                break\n",
        "            all_ohlcv.extend(ohlcv)\n",
        "            since = ohlcv[-1][0] + 1\n",
        "            time.sleep(sleep_sec)\n",
        "        except Exception as e:\n",
        "            print(f\"ĞÑˆĞ¸Ğ±ĞºĞ°: {e}\")\n",
        "            break\n",
        "\n",
        "    df = pd.DataFrame(all_ohlcv, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])\n",
        "    df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')\n",
        "    return df\n",
        "\n",
        "# ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° Ğ²ÑĞµÑ… Ğ¼Ğ¾Ğ½ĞµÑ‚\n",
        "def fetch_all_symbols_full(symbols, timeframe='1h', max_batches=1000):\n",
        "    result = {}\n",
        "    for symbol in symbols:\n",
        "        try:\n",
        "            df = fetch_full_history(symbol, timeframe=timeframe, max_batches=max_batches)\n",
        "            df = compute_indicators(df)\n",
        "            result[symbol] = df\n",
        "        except Exception as e:\n",
        "            print(f\"ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ñ€Ğ¸ {symbol}: {e}\")\n",
        "    return result '''"
      ],
      "metadata": {
        "id": "eDi6pRhroMTH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "outputId": "1e3a996a-2e9e-43c0-fa53-77d70e866ea2"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nload_dotenv()\\n\\nbinance = ccxt.binance({\\n    \\'apiKey\\': BINANCE_API_KEY ,\\n    \\'secret\\': BINANCE_SECRET_KEY,\\n    \\'enableRateLimit\\': True\\n})\\n\\ndef compute_indicators(df):\\n    # EMA\\n    df[\\'EMA_10\\'] = df[\\'close\\'].ewm(span=10, adjust=False).mean()\\n    df[\\'EMA_50\\'] = df[\\'close\\'].ewm(span=50, adjust=False).mean()\\n\\n    # RSI\\n    delta = df[\\'close\\'].diff()\\n    gain = np.where(delta > 0, delta, 0)\\n    loss = np.where(delta < 0, -delta, 0)\\n    avg_gain = pd.Series(gain).rolling(window=14).mean()\\n    avg_loss = pd.Series(loss).rolling(window=14).mean()\\n    rs = avg_gain / avg_loss\\n    df[\\'RSI_14\\'] = 100 - (100 / (1 + rs))\\n\\n    # MACD\\n    ema12 = df[\\'close\\'].ewm(span=12, adjust=False).mean()\\n    ema26 = df[\\'close\\'].ewm(span=26, adjust=False).mean()\\n    df[\\'MACD\\'] = ema12 - ema26\\n    df[\\'MACD_signal\\'] = df[\\'MACD\\'].ewm(span=9, adjust=False).mean()\\n\\n    # Bollinger Bands\\n    sma20 = df[\\'close\\'].rolling(window=20).mean()\\n    std20 = df[\\'close\\'].rolling(window=20).std()\\n    df[\\'Bollinger_Upper\\'] = sma20 + (2 * std20)\\n    df[\\'Bollinger_Lower\\'] = sma20 - (2 * std20)\\n\\n    # ATR\\n    high_low = df[\\'high\\'] - df[\\'low\\']\\n    high_close = np.abs(df[\\'high\\'] - df[\\'close\\'].shift())\\n    low_close = np.abs(df[\\'low\\'] - df[\\'close\\'].shift())\\n    tr = pd.concat([high_low, high_close, low_close], axis=1).max(axis=1)\\n    df[\\'ATR_14\\'] = tr.rolling(window=14).mean()\\n\\n    return df\\n\\n# ĞŸĞ¾ÑˆĞ°Ğ³Ğ¾Ğ²Ğ°Ñ Ğ·Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ğ·Ğ° 5 Ğ»ĞµÑ‚\\ndef fetch_full_history(symbol, timeframe=\\'1h\\', since=None, max_batches=1000, batch_limit=1500, sleep_sec=1):\\n    all_ohlcv = []\\n    since = since or binance.parse8601(\\'2019-01-01T00:00:00Z\\')\\n\\n    for i in range(max_batches):\\n        try:\\n            print(f\"[{symbol}] Ğ‘Ğ°Ñ‚Ñ‡ {i + 1}, since = {datetime.utcfromtimestamp(since / 1000)}\")\\n            ohlcv = binance.fetch_ohlcv(symbol, timeframe=timeframe, since=since, limit=batch_limit)\\n            if not ohlcv:\\n                break\\n            all_ohlcv.extend(ohlcv)\\n            since = ohlcv[-1][0] + 1\\n            time.sleep(sleep_sec)\\n        except Exception as e:\\n            print(f\"ĞÑˆĞ¸Ğ±ĞºĞ°: {e}\")\\n            break\\n\\n    df = pd.DataFrame(all_ohlcv, columns=[\\'timestamp\\', \\'open\\', \\'high\\', \\'low\\', \\'close\\', \\'volume\\'])\\n    df[\\'timestamp\\'] = pd.to_datetime(df[\\'timestamp\\'], unit=\\'ms\\')\\n    return df\\n\\n# ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° Ğ²ÑĞµÑ… Ğ¼Ğ¾Ğ½ĞµÑ‚\\ndef fetch_all_symbols_full(symbols, timeframe=\\'1h\\', max_batches=1000):\\n    result = {}\\n    for symbol in symbols:\\n        try:\\n            df = fetch_full_history(symbol, timeframe=timeframe, max_batches=max_batches)\\n            df = compute_indicators(df)\\n            result[symbol] = df\\n        except Exception as e:\\n            print(f\"ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ñ€Ğ¸ {symbol}: {e}\")\\n    return result '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "symbols = ['BTC/USDT', 'ETH/USDT', 'SOL/USDT', 'XRP/USDT', 'TRX/USDT']\n",
        "#data = fetch_all_symbols_full(symbols, timeframe='1h', max_batches=70)  # 35 Ğ±Ğ°Ñ‚Ñ‡ĞµĞ¹ Ğ¿Ğ¾ 1500 = ~52 000 Ñ‡Ğ°ÑĞ¾Ğ² â‰ˆ 6 Ğ»ĞµÑ‚"
      ],
      "metadata": {
        "collapsed": true,
        "id": "9QfkQmx0oMVj"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#btc_df.timestamp.min()"
      ],
      "metadata": {
        "id": "SAjCG_Tzs3-p"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AXMzdQn-eUwo"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DadPKsIdjPZR"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_all_from_csv(folder='crypto_csv'):\n",
        "    data_dict = {}\n",
        "    for fname in os.listdir(folder):\n",
        "        if fname.endswith(\".csv\"):\n",
        "            symbol = fname.replace(\".csv\", \"\").replace(\"_\", \"/\")\n",
        "            df = pd.read_csv(os.path.join(folder, fname), parse_dates=['timestamp'])\n",
        "            data_dict[symbol] = df\n",
        "    return data_dict"
      ],
      "metadata": {
        "id": "kjm0qZA6jPXD"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = load_all_from_csv('crypto_csv_hourly')"
      ],
      "metadata": {
        "id": "eUV1zt4QjPUo"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['BTC/USDT'].columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52uzSJkMjPSc",
        "outputId": "d4f2bf3f-f7b8-4d02-cdf1-c123d62fff1b"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['timestamp', 'open', 'high', 'low', 'close', 'volume', 'EMA_10',\n",
              "       'EMA_50', 'RSI_14', 'MACD', 'MACD_signal', 'Bollinger_Upper',\n",
              "       'Bollinger_Lower', 'ATR_14'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def add_cci(df, window=20):\n",
        "    tp = (df['high'] + df['low'] + df['close']) / 3\n",
        "    ma = tp.rolling(window).mean()\n",
        "    md = tp.rolling(window).apply(lambda x: np.mean(np.abs(x - np.mean(x))), raw=True)\n",
        "    df['cci'] = (tp - ma) / (0.015 * (md + 1e-8))\n",
        "    return df\n",
        "\n",
        "# === ĞŸÑ€ĞµĞ¿Ñ€Ğ¾Ñ†ĞµÑÑĞ¸Ğ½Ğ³ ===\n",
        "def standardize_features(df, feature_cols):\n",
        "    df = df.copy()\n",
        "    scaler = StandardScaler()\n",
        "    df[feature_cols] = scaler.fit_transform(df[feature_cols].fillna(0))\n",
        "    return df\n",
        "\n",
        "def prepare_dataframe(df, feature_cols):\n",
        "    df = df.copy()\n",
        "    df = add_cci(df)\n",
        "    df = df.dropna()\n",
        "    df = standardize_features(df, feature_cols)\n",
        "    return df, feature_cols\n",
        "\n",
        "def create_multistep_dataset(df, feature_cols, target_col='close', window_size=96, horizon=48):\n",
        "    X, y = [], []\n",
        "    for i in range(len(df) - window_size - horizon):\n",
        "        window = df.iloc[i:i + window_size]\n",
        "        target_seq = df.iloc[i + window_size:i + window_size + horizon][target_col].values\n",
        "        if window[feature_cols].isnull().any().any() or np.isnan(target_seq).any():\n",
        "            continue\n",
        "        X.append(window[feature_cols].values)\n",
        "        y.append(target_seq)\n",
        "    return np.array(X), np.array(y)"
      ],
      "metadata": {
        "id": "ldatNrPRjPPx"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_cols = ['open', 'high', 'low', 'volume', 'EMA_10',\n",
        "       'EMA_50', 'RSI_14', 'MACD', 'MACD_signal', 'Bollinger_Upper',\n",
        "       'Bollinger_Lower', 'ATR_14']"
      ],
      "metadata": {
        "id": "pvhxqdqOkMG9"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_multistep_dataset_delta(df, feature_cols, target_col='close', window_size=168, horizon=48):\n",
        "    X, y, start_prices = [], [], []\n",
        "    close = df[target_col].values\n",
        "    for i in range(len(df) - window_size - horizon):\n",
        "        window = df.iloc[i:i + window_size]\n",
        "        start_price = close[i + window_size - 1]\n",
        "        future_price = close[i + window_size:i + window_size + horizon]\n",
        "        delta = future_price - start_price\n",
        "        if window[feature_cols].isnull().any().any() or np.isnan(delta).any():\n",
        "            continue\n",
        "        X.append(window[feature_cols].values)\n",
        "        y.append(delta)\n",
        "        start_prices.append(start_price)\n",
        "    return np.array(X), np.array(y), np.array(start_prices)\n"
      ],
      "metadata": {
        "id": "3stfTYJkPu_k"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#X, y, coin_ids = build_full_dataset(data, feature_cols, target_col='close', window_size=24, horizon=48)\n",
        "\n",
        "#print(\"Ğ“Ğ¾Ñ‚Ğ¾Ğ²Ğ¾! X.shape =\", X.shape, \", y.shape =\", y.shape)"
      ],
      "metadata": {
        "id": "lXtOC9KukEvx"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6YPfim1EkEtE"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ğ’ĞµÑ€ÑĞ¸Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ¸ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¾Ñ‚ 14.05"
      ],
      "metadata": {
        "id": "jYhd9mnvL7Pu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_dataframe_for_delta(df, window_size=96, horizon=48):\n",
        "    df = df.copy()\n",
        "    df['tp'] = (df['high'] + df['low'] + df['close']) / 3\n",
        "    df['cci'] = (df['tp'] - df['tp'].rolling(20).mean()) / (0.015 * df['tp'].rolling(20).std() + 1e-8)\n",
        "    df = df.dropna()\n",
        "\n",
        "    feature_cols = ['open', 'high', 'low', 'volume', 'rsi', 'macd', 'ema_10', 'obv', 'cci']\n",
        "    scaler = StandardScaler()\n",
        "    df[feature_cols] = scaler.fit_transform(df[feature_cols])\n",
        "\n",
        "    return df, feature_cols, scaler\n",
        "\n",
        "# === Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ Ğ¾ĞºĞ¾Ğ½ Ñ Ğ´ĞµĞ»ÑŒÑ‚Ğ¾Ğ¹ ===\n",
        "def create_delta_price_dataset(df, feature_cols, target_col='close', window_size=96, horizon=48):\n",
        "    X, y, start_prices = [], [], []\n",
        "    close = df[target_col].values\n",
        "    for i in range(len(df) - window_size - horizon):\n",
        "        window = df.iloc[i:i + window_size]\n",
        "        start_price = close[i + window_size - 1]\n",
        "        end_price = close[i + window_size + horizon - 1]\n",
        "        delta = end_price - start_price\n",
        "        if window[feature_cols].isnull().any().any() or np.isnan(delta):\n",
        "            continue\n",
        "        X.append(window[feature_cols].values)\n",
        "        y.append(delta)\n",
        "        start_prices.append(start_price)\n",
        "    return np.array(X), np.array(y), np.array(start_prices)"
      ],
      "metadata": {
        "id": "D3m85ucRMMFt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Performer block ===\n",
        "class SimplePerformerBlock(nn.Module):\n",
        "    def __init__(self, dim, heads=4, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.qkv = nn.Linear(dim, dim * 3)\n",
        "        self.out_proj = nn.Linear(dim, dim)\n",
        "        self.heads = heads\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.scale = (dim // heads) ** -0.5\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, T, D = x.shape\n",
        "        H = self.heads\n",
        "        qkv = self.qkv(x)\n",
        "        q, k, v = qkv.chunk(3, dim=-1)\n",
        "        q = q.view(B, T, H, D // H).transpose(1, 2)\n",
        "        k = k.view(B, T, H, D // H).transpose(1, 2)\n",
        "        v = v.view(B, T, H, D // H).transpose(1, 2)\n",
        "        attn = F.softmax((q @ k.transpose(-2, -1)) * self.scale, dim=-1)\n",
        "        out = attn @ v\n",
        "        out = out.transpose(1, 2).contiguous().view(B, T, D)\n",
        "        return self.out_proj(out)\n",
        "\n",
        "# === Ğ“Ğ¸Ğ±Ñ€Ğ¸Ğ´Ğ½Ğ°Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Performer + BiLSTM ===\n",
        "class HybridDeltaModel(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim=128):\n",
        "        super().__init__()\n",
        "        self.lstm = nn.LSTM(input_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
        "        self.performer_block = SimplePerformerBlock(dim=input_dim)\n",
        "        self.fusion = nn.Sequential(\n",
        "            nn.Linear(hidden_dim * 2 + input_dim, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(128, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        _, (h_n, _) = self.lstm(x)\n",
        "        h_bilstm = torch.cat((h_n[-2], h_n[-1]), dim=-1)  # (B, 2*hidden_dim)\n",
        "        h_perf = self.performer_block(x).mean(dim=1)  # mean pooling Ğ¿Ğ¾ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ¸\n",
        "        h = torch.cat([h_bilstm, h_perf], dim=-1)\n",
        "        return self.fusion(h).squeeze()\n",
        "\n"
      ],
      "metadata": {
        "id": "WeZFQdvEL752"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_delta_model(X, y, input_dim, epochs=10, batch_size=32, lr=1e-3):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = DeltaPredictor(input_dim=input_dim).to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    criterion = nn.MSELoss()\n",
        "\n",
        "    X_train = torch.tensor(X, dtype=torch.float32)\n",
        "    y_train = torch.tensor(y, dtype=torch.float32)\n",
        "\n",
        "    loader = DataLoader(TensorDataset(X_train, y_train), batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        epoch_loss = 0.0\n",
        "        for xb, yb in loader:\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            preds = model(xb)\n",
        "            loss = criterion(preds, yb)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            epoch_loss += loss.item()\n",
        "        print(f\"Epoch {epoch+1}/{epochs} â€” Loss: {epoch_loss/len(loader):.4f}\")\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "SvXnramPMMDn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df, feature_cols, scaler = prepare_dataframe_for_delta(df)\n",
        "X, y, start_prices = create_delta_price_dataset(df, feature_cols)"
      ],
      "metadata": {
        "id": "fq_7HM8zMMBS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_X, all_y, all_start_prices = [], [], []\n",
        "all_scalers = {}\n",
        "feature_cols = None"
      ],
      "metadata": {
        "id": "TINKjVRpML_E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for symbol, df in data_dict.items():\n",
        "    print(f\"ğŸ”§ ĞŸĞ¾Ğ´Ğ³Ğ¾Ñ‚Ğ¾Ğ²ĞºĞ° Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ´Ğ»Ñ {symbol}\")\n",
        "    df_prepared, features, scaler = prepare_dataframe_for_delta(df, window_size, horizon)\n",
        "    feature_cols = features  # Ğ´Ğ»Ñ ÑĞ¾Ğ²Ğ¼ĞµÑÑ‚Ğ¸Ğ¼Ğ¾ÑÑ‚Ğ¸\n",
        "    X, y, starts = create_delta_price_dataset(df_prepared, feature_cols, window_size=window_size, horizon=horizon)\n",
        "    if len(X) == 0:\n",
        "        continue\n",
        "    all_X.append(X)\n",
        "    all_y.append(y)\n",
        "    all_start_prices.append(starts)\n",
        "    all_scalers[symbol] = scaler"
      ],
      "metadata": {
        "id": "QNFb2D6_ML8v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_all = np.concatenate(all_X, axis=0)\n",
        "y_all = np.concatenate(all_y, axis=0)\n",
        "start_all = np.concatenate(all_start_prices, axis=0)"
      ],
      "metadata": {
        "id": "24IyB0reOHkj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test, start_train, start_test = train_test_split(\n",
        "        X_all, y_all, start_all, test_size=0.1, random_state=42\n",
        "    )"
      ],
      "metadata": {
        "id": "HfGsOnhdOKSM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(\n",
        "        TensorDataset(torch.tensor(X_train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.float32)),\n",
        "        batch_size=batch_size, shuffle=True\n",
        "    )"
      ],
      "metadata": {
        "id": "jjDa3l7BOOYK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = HybridDeltaModel(input_dim=X_all.shape[-1]).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "criterion = torch.nn.MSELoss()"
      ],
      "metadata": {
        "id": "1Z0cNIQJOQ0x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(10):\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    for xb, yb in train_loader:\n",
        "        xb, yb = xb.to(device), yb.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        preds = model(xb)\n",
        "        loss = criterion(preds, yb)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "    print(f\"Epoch {epoch+1}/{10} â€” Train Loss: {epoch_loss / len(train_loader):.4f}\")\n"
      ],
      "metadata": {
        "id": "_rbwI2F_OT3a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Ğ¢ĞµÑÑ‚Ğ¾Ğ²Ñ‹Ğ¹ Ğ±Ğ»Ğ¾Ğº Ñ Ğ²Ğ¾ÑÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸ĞµĞ¼ Ñ†ĞµĞ½ ===\n",
        "def test_model(model, X_test, y_test, start_prices):\n",
        "    model.eval()\n",
        "    device = next(model.parameters()).device\n",
        "    loader = DataLoader(TensorDataset(torch.tensor(X_test, dtype=torch.float32),\n",
        "                                      torch.tensor(y_test, dtype=torch.float32)),\n",
        "                        batch_size=32)\n",
        "\n",
        "    all_preds = []\n",
        "    with torch.no_grad():\n",
        "        for xb, _ in loader:\n",
        "            xb = xb.to(device)\n",
        "            preds = model(xb).cpu().numpy()\n",
        "            all_preds.extend(preds)\n",
        "\n",
        "    y_pred = np.array(all_preds)\n",
        "    y_true = y_test\n",
        "    predicted_prices = start_prices + y_pred\n",
        "    actual_prices = start_prices + y_true\n",
        "\n",
        "    returns = predicted_prices - start_prices\n",
        "    true_returns = actual_prices - start_prices\n",
        "    direction_match = np.sign(returns) == np.sign(true_returns)\n",
        "\n",
        "    da = np.mean(direction_match)\n",
        "    mean_return = returns.mean()\n",
        "    sharpe = mean_return / (returns.std() + 1e-8)\n",
        "    equity = np.cumsum(returns)\n",
        "    max_drawdown = np.max(np.maximum.accumulate(equity) - equity)\n",
        "\n",
        "    print(f\"Directional Accuracy: {da:.3f}\")\n",
        "    print(f\"Mean Return: {mean_return:.2f}\")\n",
        "    print(f\"Sharpe Ratio: {sharpe:.2f}\")\n",
        "    print(f\"Max Drawdown: {max_drawdown:.2f}\")\n",
        "\n",
        "    return {\n",
        "        \"DA\": da,\n",
        "        \"Mean Return\": mean_return,\n",
        "        \"Sharpe\": sharpe,\n",
        "        \"MDD\": max_drawdown\n",
        "    }\n"
      ],
      "metadata": {
        "id": "fKWSvGe6MEHk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_model(model, X_test, y_test, start_test)"
      ],
      "metadata": {
        "id": "XRR6yitTOeTo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ĞœĞ¾Ğ´ĞµĞ»Ğ¸ Ğ¸ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¿Ğ¾Ğ´ ĞºĞ¾Ğ½ĞºÑ€ĞµÑ‚Ğ½Ñ‹Ğ¹ ÑĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚(Ğ¿Ğ¾ĞºĞ° Ñ‡Ñ‚Ğ¾ ĞµĞ´Ğ¸Ğ½ÑÑ‚Ğ²ĞµĞ½Ğ½Ñ‹Ğ¹ Ñ€Ğ°Ğ±Ğ¾Ñ‡Ğ¸Ğ¹)\n"
      ],
      "metadata": {
        "id": "bgmiZdnQL0P_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BiLSTMTemporalModel(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim=128, num_layers=2, dropout=0.1, output_dim=128):\n",
        "        super().__init__()\n",
        "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers=num_layers, batch_first=True,\n",
        "                            bidirectional=True, dropout=dropout if num_layers > 1 else 0.0)\n",
        "        self.output_proj = nn.Linear(hidden_dim * 2, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        _, (h_n, _) = self.lstm(x)\n",
        "        h_forward, h_backward = h_n[-2], h_n[-1]\n",
        "        h_combined = torch.cat([h_forward, h_backward], dim=-1)\n",
        "        return self.output_proj(h_combined)\n"
      ],
      "metadata": {
        "id": "w22YvoYWY7Y5"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimplePerformerBlock(nn.Module):\n",
        "    def __init__(self, dim, heads=4, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.qkv = nn.Linear(dim, dim * 3)\n",
        "        self.out_proj = nn.Linear(dim, dim)\n",
        "        self.heads = heads\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.scale = (dim // heads) ** -0.5\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, T, D = x.shape\n",
        "        H = self.heads\n",
        "        qkv = self.qkv(x)\n",
        "        q, k, v = qkv.chunk(3, dim=-1)\n",
        "        q = q.view(B, T, H, D // H).transpose(1, 2)\n",
        "        k = k.view(B, T, H, D // H).transpose(1, 2)\n",
        "        v = v.view(B, T, H, D // H).transpose(1, 2)\n",
        "        attn_weights = F.softmax((q @ k.transpose(-2, -1)) * self.scale, dim=-1)\n",
        "        attn_output = attn_weights @ v\n",
        "        attn_output = attn_output.transpose(1, 2).contiguous().view(B, T, D)\n",
        "        return self.out_proj(attn_output)\n",
        "\n",
        "\n",
        "class PerformerTemporalModel(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim=128, heads=4, depth=2, dropout=0.1, output_dim=128):\n",
        "        super().__init__()\n",
        "        self.input_proj = nn.Linear(input_dim, hidden_dim)\n",
        "        self.blocks = nn.ModuleList([\n",
        "            nn.Sequential(\n",
        "                SimplePerformerBlock(hidden_dim, heads, dropout),\n",
        "                nn.LayerNorm(hidden_dim),\n",
        "                nn.Sequential(\n",
        "                    nn.Linear(hidden_dim, hidden_dim * 4),\n",
        "                    nn.GELU(),\n",
        "                    nn.Dropout(dropout),\n",
        "                    nn.Linear(hidden_dim * 4, hidden_dim)\n",
        "                ),\n",
        "                nn.LayerNorm(hidden_dim)\n",
        "            )\n",
        "            for _ in range(depth)\n",
        "        ])\n",
        "        self.cls_token = nn.Parameter(torch.randn(1, 1, hidden_dim))\n",
        "        self.output_proj = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, T, _ = x.shape\n",
        "        x = self.input_proj(x)\n",
        "        cls_tokens = self.cls_token.expand(B, -1, -1)\n",
        "        x = torch.cat((cls_tokens, x), dim=1)\n",
        "        for block in self.blocks:\n",
        "            x = x + block(x)\n",
        "        cls_output = x[:, 0, :]\n",
        "        return self.output_proj(cls_output)\n"
      ],
      "metadata": {
        "id": "p1mndqwDUipt"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6fiIG3R3tTOM"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiStepHybridModel(nn.Module):\n",
        "    def __init__(self, input_dim, temporal_dim=128, fusion_dim=256, output_horizon=48):\n",
        "        super().__init__()\n",
        "        self.bilstm = BiLSTMTemporalModel(input_dim, hidden_dim=temporal_dim, output_dim=temporal_dim)\n",
        "        self.performer = PerformerTemporalModel(input_dim, hidden_dim=temporal_dim, output_dim=temporal_dim)\n",
        "        self.fusion = nn.Sequential(\n",
        "            nn.Linear(temporal_dim * 2, fusion_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(fusion_dim, output_horizon)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        h_bilstm = self.bilstm(x)\n",
        "        h_perf = self.performer(x)\n",
        "        h = torch.cat([h_bilstm, h_perf], dim=-1)\n",
        "        return self.fusion(h)"
      ],
      "metadata": {
        "id": "HcD5NL1wUinU"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_dataloader(X, y, coin_ids, batch_size=32, shuffle=True):\n",
        "    X_tensor = torch.tensor(X, dtype=torch.float32)\n",
        "    y_tensor = torch.tensor(y, dtype=torch.float32)\n",
        "    id_tensor = torch.tensor(coin_ids, dtype=torch.long)\n",
        "    dataset = torch.utils.data.TensorDataset(X_tensor, y_tensor, id_tensor)\n",
        "    return torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)"
      ],
      "metadata": {
        "id": "6DFBBLLXPkFR"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "split_data = {}\n",
        "\n",
        "for symbol, df in data.items():\n",
        "    df_prepared, feature_cols = prepare_dataframe(df, feature_cols)\n",
        "    X, y, start_prices = create_multistep_dataset_delta(df_prepared, feature_cols)\n",
        "\n",
        "    if len(X) == 0:\n",
        "        continue\n",
        "\n",
        "    n = len(X)\n",
        "    train_end = int(n * 0.75)\n",
        "    val_end = int(n * 0.90)\n",
        "\n",
        "    split_data[symbol] = {\n",
        "        \"X_train\": X[:train_end],\n",
        "        \"y_train\": y[:train_end],\n",
        "        \"X_val\": X[train_end:val_end],\n",
        "        \"y_val\": y[train_end:val_end],\n",
        "        \"X_test\": X[val_end:],\n",
        "        \"y_test\": y[val_end:],\n",
        "        \"start_prices\": start_prices[val_end:],  # Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ñ‚ĞµÑÑ‚Ğ¾Ğ²Ñ‹Ğµ ÑÑ‚Ğ°Ñ€Ñ‚Ğ¾Ğ²Ñ‹Ğµ Ñ†ĞµĞ½Ñ‹\n",
        "        \"feature_cols\": feature_cols\n",
        "    }"
      ],
      "metadata": {
        "id": "GHHTsryBv5nW"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yO48Z4F2v5ev"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2h97SziZwgaw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OiNDGRuDwgWr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "model = MultiStepHybridModel(input_dim=len(feature_cols)).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "criterion = nn.MSELoss()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P8RzJXxRwgUC",
        "outputId": "6ecd3b8b-87e3-4f2c-c742-abf251ed6c61"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "for symbol, data in split_data.items():\n",
        "    print(f\"\\n--- ĞĞ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ½Ğ° Ğ¼Ğ¾Ğ½ĞµÑ‚Ğµ {symbol} ---\")\n",
        "\n",
        "    # Ğ”Ğ°Ñ‚Ğ°Ğ»Ğ¾Ğ°Ğ´ĞµÑ€Ñ‹\n",
        "    def get_loader(x, y):\n",
        "        ds = torch.utils.data.TensorDataset(torch.tensor(x, dtype=torch.float32), torch.tensor(y, dtype=torch.float32))\n",
        "        return torch.utils.data.DataLoader(ds, batch_size=32, shuffle=True)\n",
        "\n",
        "    train_loader = get_loader(data['X_train'], data['y_train'])\n",
        "    val_loader = get_loader(data['X_val'], data['y_val'])\n",
        "\n",
        "    for epoch in range(10):\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        for xb, yb in train_loader:\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            preds = model(xb)\n",
        "            loss = criterion(preds, yb)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item()\n",
        "\n",
        "        # Ğ’Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ñ\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for xb, yb in val_loader:\n",
        "                xb, yb = xb.to(device), yb.to(device)\n",
        "                val_loss += criterion(model(xb), yb).item()\n",
        "\n",
        "        print(f\"{symbol} â€” Epoch {epoch+1}: Train Loss={train_loss/len(train_loader):.6f}, Val Loss={val_loss/len(val_loader):.6f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sXgmFjESwgRe",
        "outputId": "d5aef7ea-7937-4129-81ed-315ccc7646c6"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- ĞĞ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ½Ğ° Ğ¼Ğ¾Ğ½ĞµÑ‚Ğµ BTC/USDT ---\n",
            "BTC/USDT â€” Epoch 1: Train Loss=1125264.141431, Val Loss=2324771.358654\n",
            "BTC/USDT â€” Epoch 2: Train Loss=1103847.727194, Val Loss=2409590.117548\n",
            "BTC/USDT â€” Epoch 3: Train Loss=1095179.058759, Val Loss=2445786.024279\n",
            "BTC/USDT â€” Epoch 4: Train Loss=1076358.822436, Val Loss=2477835.131731\n",
            "BTC/USDT â€” Epoch 5: Train Loss=1068564.566578, Val Loss=2632882.278365\n",
            "BTC/USDT â€” Epoch 6: Train Loss=1053053.059962, Val Loss=2494401.866827\n",
            "BTC/USDT â€” Epoch 7: Train Loss=1005188.678827, Val Loss=2846999.941827\n",
            "BTC/USDT â€” Epoch 8: Train Loss=954948.166444, Val Loss=3056637.936058\n",
            "BTC/USDT â€” Epoch 9: Train Loss=907884.460667, Val Loss=3149393.535096\n",
            "BTC/USDT â€” Epoch 10: Train Loss=878660.124687, Val Loss=3496322.039904\n",
            "\n",
            "--- ĞĞ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ½Ğ° Ğ¼Ğ¾Ğ½ĞµÑ‚Ğµ ETH/USDT ---\n",
            "ETH/USDT â€” Epoch 1: Train Loss=21538.821582, Val Loss=23578.647908\n",
            "ETH/USDT â€” Epoch 2: Train Loss=7587.255018, Val Loss=16117.168883\n",
            "ETH/USDT â€” Epoch 3: Train Loss=6474.592466, Val Loss=14045.897314\n",
            "ETH/USDT â€” Epoch 4: Train Loss=6155.942264, Val Loss=14311.558827\n",
            "ETH/USDT â€” Epoch 5: Train Loss=5881.903487, Val Loss=11317.921802\n",
            "ETH/USDT â€” Epoch 6: Train Loss=5908.953198, Val Loss=9107.449873\n",
            "ETH/USDT â€” Epoch 7: Train Loss=5667.628136, Val Loss=9772.453906\n",
            "ETH/USDT â€” Epoch 8: Train Loss=5602.887681, Val Loss=10270.576703\n",
            "ETH/USDT â€” Epoch 9: Train Loss=5556.415113, Val Loss=9584.749499\n",
            "ETH/USDT â€” Epoch 10: Train Loss=5175.032070, Val Loss=10634.243724\n",
            "\n",
            "--- ĞĞ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ½Ğ° Ğ¼Ğ¾Ğ½ĞµÑ‚Ğµ TRX/USDT ---\n",
            "TRX/USDT â€” Epoch 1: Train Loss=54.261175, Val Loss=1267.965958\n",
            "TRX/USDT â€” Epoch 2: Train Loss=14.947591, Val Loss=1041.916147\n",
            "TRX/USDT â€” Epoch 3: Train Loss=6.944231, Val Loss=771.546172\n",
            "TRX/USDT â€” Epoch 4: Train Loss=2.925482, Val Loss=540.756188\n",
            "TRX/USDT â€” Epoch 5: Train Loss=1.210568, Val Loss=437.733230\n",
            "TRX/USDT â€” Epoch 6: Train Loss=0.700370, Val Loss=363.329903\n",
            "TRX/USDT â€” Epoch 7: Train Loss=0.448796, Val Loss=370.679353\n",
            "TRX/USDT â€” Epoch 8: Train Loss=0.289439, Val Loss=308.774993\n",
            "TRX/USDT â€” Epoch 9: Train Loss=0.207018, Val Loss=248.974970\n",
            "TRX/USDT â€” Epoch 10: Train Loss=0.121559, Val Loss=219.959081\n",
            "\n",
            "--- ĞĞ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ½Ğ° Ğ¼Ğ¾Ğ½ĞµÑ‚Ğµ XRP/USDT ---\n",
            "XRP/USDT â€” Epoch 1: Train Loss=0.130691, Val Loss=0.036311\n",
            "XRP/USDT â€” Epoch 2: Train Loss=0.063608, Val Loss=0.006699\n",
            "XRP/USDT â€” Epoch 3: Train Loss=0.052341, Val Loss=0.002802\n",
            "XRP/USDT â€” Epoch 4: Train Loss=0.037868, Val Loss=0.087130\n",
            "XRP/USDT â€” Epoch 5: Train Loss=0.036646, Val Loss=0.139573\n",
            "XRP/USDT â€” Epoch 6: Train Loss=0.028669, Val Loss=0.024074\n",
            "XRP/USDT â€” Epoch 7: Train Loss=0.027465, Val Loss=0.008567\n",
            "XRP/USDT â€” Epoch 8: Train Loss=0.025253, Val Loss=0.001905\n",
            "XRP/USDT â€” Epoch 9: Train Loss=0.022633, Val Loss=0.002982\n",
            "XRP/USDT â€” Epoch 10: Train Loss=0.010351, Val Loss=0.004905\n",
            "\n",
            "--- ĞĞ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ½Ğ° Ğ¼Ğ¾Ğ½ĞµÑ‚Ğµ SOL/USDT ---\n",
            "SOL/USDT â€” Epoch 1: Train Loss=21.829543, Val Loss=59.025813\n",
            "SOL/USDT â€” Epoch 2: Train Loss=19.158635, Val Loss=62.168781\n",
            "SOL/USDT â€” Epoch 3: Train Loss=18.011224, Val Loss=147.377595\n",
            "SOL/USDT â€” Epoch 4: Train Loss=16.081102, Val Loss=213.664656\n",
            "SOL/USDT â€” Epoch 5: Train Loss=16.558155, Val Loss=300.914738\n",
            "SOL/USDT â€” Epoch 6: Train Loss=14.436984, Val Loss=269.883265\n",
            "SOL/USDT â€” Epoch 7: Train Loss=13.432105, Val Loss=242.249878\n",
            "SOL/USDT â€” Epoch 8: Train Loss=12.663884, Val Loss=358.857236\n",
            "SOL/USDT â€” Epoch 9: Train Loss=12.456376, Val Loss=238.471824\n",
            "SOL/USDT â€” Epoch 10: Train Loss=11.426809, Val Loss=173.836080\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = {}\n",
        "\n",
        "for symbol, data in split_data.items():\n",
        "    print(f\"\\n=== Ğ¢ĞµÑÑ‚ Ğ½Ğ° {symbol} ===\")\n",
        "    X_test, y_test, start_prices = data['X_test'], data['y_test'], data['start_prices']\n",
        "\n",
        "    test_loader = torch.utils.data.DataLoader(\n",
        "        torch.utils.data.TensorDataset(\n",
        "            torch.tensor(X_test, dtype=torch.float32),\n",
        "            torch.tensor(y_test, dtype=torch.float32)\n",
        "        ),\n",
        "        batch_size=32\n",
        "    )\n",
        "\n",
        "    all_preds, all_truths = [], []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for xb, yb in test_loader:\n",
        "            xb = xb.to(device)\n",
        "            preds = model(xb).cpu().numpy()\n",
        "            all_preds.append(preds)\n",
        "            all_truths.append(yb.numpy())\n",
        "\n",
        "    y_pred = np.vstack(all_preds)\n",
        "    y_true = np.vstack(all_truths)\n",
        "\n",
        "    # Ğ’Ğ¾ÑÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ğµ Ğ¿Ñ€ĞµĞ´ÑĞºĞ°Ğ·Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¸ Ñ€ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ñ… Ñ†ĞµĞ½\n",
        "    pred_price = start_prices + y_pred[:, -1]\n",
        "    true_price = start_prices + y_true[:, -1]\n",
        "\n",
        "    returns = pred_price - start_prices\n",
        "    real_returns = true_price - start_prices\n",
        "    correct_direction = np.sign(returns) == np.sign(real_returns)\n",
        "\n",
        "    da = np.mean(correct_direction)\n",
        "    hit = np.mean((np.abs(returns) > 0) & correct_direction)\n",
        "    mean_ret = returns.mean()\n",
        "    std_ret = returns.std()\n",
        "    downside = np.std(returns[returns < 0]) if np.any(returns < 0) else 1.0\n",
        "    sharpe = mean_ret / (std_ret + 1e-8)\n",
        "    sortino = mean_ret / (downside + 1e-8)\n",
        "\n",
        "    equity = np.cumsum(returns)\n",
        "    mdd = np.max(np.maximum.accumulate(equity) - equity)\n",
        "\n",
        "    results[symbol] = {\n",
        "        \"DA\": da, \"Hit\": hit, \"Mean Return\": mean_ret,\n",
        "        \"Sharpe\": sharpe, \"Sortino\": sortino, \"MDD\": mdd\n",
        "    }\n",
        "\n",
        "# ĞŸĞµÑ‡Ğ°Ñ‚ÑŒ Ğ¸Ñ‚Ğ¾Ğ³Ğ¾Ğ²\n",
        "print(\"\\nğŸ“Š ĞœĞµÑ‚Ñ€Ğ¸ĞºĞ¸ Ğ¿Ğ¾ Ğ¼Ğ¾Ğ½ĞµÑ‚Ğ°Ğ¼:\")\n",
        "for sym, r in results.items():\n",
        "    print(f\"{sym:10} | DA: {r['DA']:.3f} | Hit: {r['Hit']:.3f} | Return: {r['Mean Return']:.2f} | Sharpe: {r['Sharpe']:.2f} | Sortino: {r['Sortino']:.2f} | MDD: {r['MDD']:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V5xKTxZ9zZmV",
        "outputId": "0a6ac172-4fc6-4046-b8a1-641206243529"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Ğ¢ĞµÑÑ‚ Ğ½Ğ° BTC/USDT ===\n",
            "\n",
            "=== Ğ¢ĞµÑÑ‚ Ğ½Ğ° ETH/USDT ===\n",
            "\n",
            "=== Ğ¢ĞµÑÑ‚ Ğ½Ğ° TRX/USDT ===\n",
            "\n",
            "=== Ğ¢ĞµÑÑ‚ Ğ½Ğ° XRP/USDT ===\n",
            "\n",
            "=== Ğ¢ĞµÑÑ‚ Ğ½Ğ° SOL/USDT ===\n",
            "\n",
            "ğŸ“Š ĞœĞµÑ‚Ñ€Ğ¸ĞºĞ¸ Ğ¿Ğ¾ Ğ¼Ğ¾Ğ½ĞµÑ‚Ğ°Ğ¼:\n",
            "BTC/USDT   | DA: 0.479 | Hit: 0.479 | Return: -8.88 | Sharpe: -0.51 | Sortino: -0.84 | MDD: 50330.96\n",
            "ETH/USDT   | DA: 0.502 | Hit: 0.502 | Return: -3.56 | Sharpe: -0.23 | Sortino: -0.26 | MDD: 23657.51\n",
            "TRX/USDT   | DA: 0.468 | Hit: 0.468 | Return: -2.61 | Sharpe: -0.09 | Sortino: -0.14 | MDD: 32955.37\n",
            "XRP/USDT   | DA: 0.514 | Hit: 0.514 | Return: 4.69 | Sharpe: 0.18 | Sortino: 0.40 | MDD: 12654.66\n",
            "SOL/USDT   | DA: 0.522 | Hit: 0.522 | Return: -8.76 | Sharpe: -0.51 | Sortino: -0.58 | MDD: 36176.71\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7kpfbPPXuMPO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WtFyiVkJ5B1Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Trash"
      ],
      "metadata": {
        "id": "P1npE_Io5Nt_"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "m3BydyPV5By2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NB90pRsF5Bwe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = MultiStepHybridModel(input_dim=7).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "for symbol, df in data.items():\n",
        "    print(f\"\\n--- ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° Ğ¼Ğ¾Ğ½ĞµÑ‚Ñ‹: {symbol} ---\")\n",
        "    df_prepared, feature_cols = prepare_dataframe(df)\n",
        "    X, y = create_multistep_dataset(df_prepared, feature_cols)\n",
        "\n",
        "    if len(X) == 0:\n",
        "        print(\"ĞŸÑ€Ğ¾Ğ¿ÑƒÑ‰ĞµĞ½Ğ¾: Ğ½ĞµĞ´Ğ¾ÑÑ‚Ğ°Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ….\")\n",
        "        continue\n",
        "\n",
        "    dataset = torch.utils.data.TensorDataset(torch.tensor(X, dtype=torch.float32), torch.tensor(y, dtype=torch.float32))\n",
        "    loader = torch.utils.data.DataLoader(dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "    for epoch in range(30):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        for xb, yb in loader:\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            preds = model(xb)\n",
        "            loss = criterion(preds, yb)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "        print(f\"{symbol} â€” Epoch {epoch+1}: Loss = {total_loss/len(loader):.6f}\")\n"
      ],
      "metadata": {
        "id": "U6x3l8zkRV6J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# === 1. Ğ Ğ°Ğ·Ğ±Ğ¸Ğ²Ğ°ĞµĞ¼ Ğ²Ñ‹Ğ±Ğ¾Ñ€ĞºÑƒ ===\n",
        "X_train_full, X_test, y_train_full, y_test, id_train_full, id_test = train_test_split(\n",
        "    X, y, coin_ids, test_size=0.1, random_state=42\n",
        ")\n",
        "\n",
        "X_train, X_val, y_train, y_val, id_train, id_val = train_test_split(\n",
        "    X_train_full, y_train_full, id_train_full, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# === 2. Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‘Ğ¼ DataLoader'Ñ‹ ===\n",
        "train_loader = make_dataloader(X_train, y_train, id_train, batch_size=32, shuffle=False)\n",
        "val_loader = make_dataloader(X_val, y_val, id_val, batch_size=32, shuffle=False)\n",
        "test_loader = make_dataloader(X_test, y_test, id_test, batch_size=32, shuffle=False)\n",
        "\n",
        "# === 3. ĞĞ±ÑŠÑĞ²Ğ»ÑĞµĞ¼ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ ===\n",
        "num_coins = len(set(coin_ids))  # ÑƒĞ½Ğ¸ĞºĞ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ¼Ğ¾Ğ½ĞµÑ‚\n",
        "input_dim = X.shape[-1]\n",
        "horizon = y.shape[-1]\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "model = MultiStepHybridModel(\n",
        "    input_dim=input_dim,\n",
        "    num_coins=num_coins,\n",
        "    output_horizon=horizon\n",
        ").to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "# === 4. ĞĞ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ ===\n",
        "num_epochs = 18\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for xb, yb, coin_id in train_loader:\n",
        "        xb, yb, coin_id = xb.to(device), yb.to(device), coin_id.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        preds = model(xb, coin_id)\n",
        "        loss = criterion(preds, yb)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    val_loss = 0\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for xb, yb, coin_id in val_loader:\n",
        "            xb, yb, coin_id = xb.to(device), yb.to(device), coin_id.to(device)\n",
        "            preds = model(xb, coin_id)\n",
        "            val_loss += criterion(preds, yb).item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs} â€” Train Loss: {total_loss/len(train_loader):.6f}, Val Loss: {val_loss/len(val_loader):.6f}\")\n"
      ],
      "metadata": {
        "id": "nTSkwGa0ZAfj",
        "outputId": "1a43277d-11da-41a5-d249-03bf0c2ebfa0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n",
            "Epoch 1/18 â€” Train Loss: 58925220.801969, Val Loss: 34120494.982131\n",
            "Epoch 2/18 â€” Train Loss: 13407841.820598, Val Loss: 1194914.618652\n",
            "Epoch 3/18 â€” Train Loss: 2143704.108968, Val Loss: 743696.980838\n",
            "Epoch 4/18 â€” Train Loss: 1028531.441911, Val Loss: 628343.920961\n",
            "Epoch 5/18 â€” Train Loss: 923688.433078, Val Loss: 691504.022469\n",
            "Epoch 6/18 â€” Train Loss: 864325.147131, Val Loss: 538008.668185\n",
            "Epoch 7/18 â€” Train Loss: 774295.645730, Val Loss: 577735.926757\n",
            "Epoch 8/18 â€” Train Loss: 1532728.193121, Val Loss: 8479673.303228\n",
            "Epoch 9/18 â€” Train Loss: 797430.474596, Val Loss: 556947.170496\n",
            "Epoch 10/18 â€” Train Loss: 742038.252574, Val Loss: 659708.979397\n",
            "Epoch 11/18 â€” Train Loss: 28704460.651206, Val Loss: 33412117.274444\n",
            "Epoch 12/18 â€” Train Loss: 37709343.624332, Val Loss: 31424165.814038\n",
            "Epoch 13/18 â€” Train Loss: 29235009.416161, Val Loss: 15730771.954231\n",
            "Epoch 14/18 â€” Train Loss: 32303415.410448, Val Loss: 2859434.005984\n",
            "Epoch 15/18 â€” Train Loss: 14006464.008978, Val Loss: 1800245.593876\n",
            "Epoch 16/18 â€” Train Loss: 2066834.875557, Val Loss: 984277.343279\n",
            "Epoch 17/18 â€” Train Loss: 1436215.245226, Val Loss: 1110687.273443\n",
            "Epoch 18/18 â€” Train Loss: 2650502.629808, Val Loss: 9070231.811246\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(y_true, y_pred, horizon_step=47):\n",
        "    pred = y_pred[:, horizon_step]\n",
        "    real = y_true[:, horizon_step]\n",
        "    start_price = y_true[:, 0]\n",
        "\n",
        "    real_direction = np.sign(real - start_price)\n",
        "    pred_direction = np.sign(pred - start_price)\n",
        "    directional_accuracy = np.mean(real_direction == pred_direction)\n",
        "\n",
        "    hits = (pred > start_price) & (real > start_price)\n",
        "    hit_ratio = hits.sum() / ((pred > start_price).sum() + 1e-8)\n",
        "\n",
        "    model_returns = np.where(pred > start_price, real - start_price, 0)\n",
        "\n",
        "    mean_return = np.mean(model_returns)\n",
        "    std_return = np.std(model_returns)\n",
        "    sharpe_ratio = mean_return / (std_return + 1e-8)\n",
        "\n",
        "    downside_std = np.std(model_returns[model_returns < 0]) + 1e-8\n",
        "    sortino_ratio = mean_return / downside_std\n",
        "\n",
        "    cumulative = np.cumsum(model_returns)\n",
        "    peak = np.maximum.accumulate(cumulative)\n",
        "    drawdown = peak - cumulative\n",
        "    max_drawdown = np.max(drawdown)\n",
        "\n",
        "    return {\n",
        "        \"Directional Accuracy\": directional_accuracy,\n",
        "        \"Hit Ratio\": hit_ratio,\n",
        "        \"Mean Return ($)\": mean_return,\n",
        "        \"Sharpe Ratio\": sharpe_ratio,\n",
        "        \"Sortino Ratio\": sortino_ratio,\n",
        "        \"Max Drawdown ($)\": max_drawdown\n",
        "    }"
      ],
      "metadata": {
        "id": "W_vETRhcBVn0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "U8iWaHBof-hX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "all_preds, all_truths = [], []\n",
        "with torch.no_grad():\n",
        "    for xb, yb, coin_id in test_loader:\n",
        "        xb = xb.to(device)\n",
        "        coin_id = coin_id.to(device)\n",
        "        preds = model(xb, coin_id).cpu().numpy()\n",
        "        all_preds.append(preds)\n",
        "        all_truths.append(yb.numpy())\n",
        "\n",
        "y_pred_test = np.vstack(all_preds)\n",
        "y_true_test = np.vstack(all_truths)\n",
        "\n",
        "# Ğ Ğ°ÑÑ‡ĞµÑ‚ Ğ¼ĞµÑ‚Ñ€Ğ¸Ğº\n",
        "metrics_result = evaluate_model(y_true_test, y_pred_test, horizon_step=47)\n",
        "metrics_result"
      ],
      "metadata": {
        "id": "SpMZ9NfJZAZo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a82bcdd-10fd-407d-bd8f-9b4cb32ec436"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Directional Accuracy': np.float64(0.4982740962712893),\n",
              " 'Hit Ratio': np.float64(0.536305147058002),\n",
              " 'Mean Return ($)': np.float32(11.374677),\n",
              " 'Sharpe Ratio': np.float32(0.036527734),\n",
              " 'Sortino Ratio': np.float32(0.023196382),\n",
              " 'Max Drawdown ($)': np.float32(29290.469)}"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Qd2gBcYnZAXD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MAasSDdohWMd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3lWxnBSuhWJn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}